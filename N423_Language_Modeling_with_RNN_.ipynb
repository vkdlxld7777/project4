{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_eOv4kAYb0Z"
      },
      "source": [
        "<img align=\"right\" src=\"https://ds-cs-images.s3.ap-northeast-2.amazonaws.com/Codestates_Fulllogo_Color.png\" width=100>\n",
        "\n",
        "## ***DATA SCIENCE / SECTION 4 / SPRINT 2 / NOTE 3***\n",
        "\n",
        "---\n",
        "\n",
        "# 언어 모델과 RNN(Recurrent Neural Network, 순환 신경망)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NabC-Q8-hiu7",
        "outputId": "656654aa-29c3-433d-a4c3-ccd9bbec4b6f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "123"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 더 알아보기 : 파이썬의 딕셔너리도 비슷한 형태로 작동합니다.\n",
        "# Query('a')를 던지면 딕셔너리에서 동일한 Key('a')를 찾은 뒤 Value(123)을 반환합니다.\n",
        "\n",
        "dict1 = {'a':123, 'b':425, 'c':236, 'd':945}\n",
        "dict1['a']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOAShST2e8Ik"
      },
      "source": [
        "### RNN(LSTM) with Attention 코드 실습\n",
        "\n",
        "`Tensorflow` 튜토리얼 코드를 사용하여 Attention이 어떻게 적용되는 지 알아보도록 하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "pYnEXYKGewLQ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zq5-fp4gfKxz",
        "outputId": "c4495491-8434-455a-b8df-31e7b5510444"
      },
      "outputs": [],
      "source": [
        "# 데이터셋을 다운로드합니다.\n",
        "path_to_zip = tf.keras.utils.get_file(\n",
        "    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
        "    extract=True)\n",
        "\n",
        "path_to_file = os.path.dirname(path_to_zip)+\"/spa-eng/spa.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "NqxC2SgsfPCp"
      },
      "outputs": [],
      "source": [
        "# 유니코드 파일을 아스키코드로 변환하는 함수입니다.\n",
        "def unicode_to_ascii(s):\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "                 if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "  w = unicode_to_ascii(w.lower().strip())\n",
        "\n",
        "  # creating a space between a word and the punctuation following it\n",
        "  # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "  # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
        "  w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "  w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "  w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "\n",
        "  w = w.strip()\n",
        "\n",
        "  # adding a start and an end token to the sentence\n",
        "  # so that the model know when to start and stop predicting.\n",
        "  w = '<start> ' + w + ' <end>'\n",
        "  return w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYpqyskDfQqi",
        "outputId": "2abe4f33-fbef-46a0-8f55-b5d40f7807e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<start> may i borrow this book ? <end>\n",
            "b'<start> \\xc2\\xbf puedo tomar prestado este libro ? <end>'\n"
          ]
        }
      ],
      "source": [
        "en_sentence = u\"May I borrow this book?\"\n",
        "sp_sentence = u\"¿Puedo tomar prestado este libro?\"\n",
        "print(preprocess_sentence(en_sentence))\n",
        "print(preprocess_sentence(sp_sentence).encode('utf-8'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "7iSyCfNrfSvT"
      },
      "outputs": [],
      "source": [
        "# 1. Remove the accents\n",
        "# 2. Clean the sentences\n",
        "# 3. Return word pairs in the format: [ENGLISH, SPANISH]\n",
        "def create_dataset(path, num_examples):\n",
        "  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "  \n",
        "  word_pairs = [[preprocess_sentence(w) for w in line.split('\\t')]\n",
        "                for line in lines[:num_examples]]\n",
        "\n",
        "\n",
        "  return zip(*word_pairs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66wKsoJYfT5p",
        "outputId": "1db2c661-02f7-4e72-e600-60bf8503c004"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<start> if you want to sound like a native speaker , you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo . <end>\n",
            "<start> si quieres sonar como un hablante nativo , debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un musico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado . <end>\n"
          ]
        }
      ],
      "source": [
        "en, sp = create_dataset(path_to_file, None)\n",
        "print(en[-1])\n",
        "print(sp[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "gEBx2J0OfUUu"
      },
      "outputs": [],
      "source": [
        "def tokenize(lang):\n",
        "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "  lang_tokenizer.fit_on_texts(lang)\n",
        "\n",
        "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                         padding='post')\n",
        "\n",
        "  return tensor, lang_tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "xOjGqWpsfVmK"
      },
      "outputs": [],
      "source": [
        "# 2개 언어이기 때문에, tokenizer가 각각의 언어별로 따로 필요합니다.\n",
        "def load_dataset(path, num_examples=None):\n",
        "  # creating cleaned input, output pairs\n",
        "  targ_lang, inp_lang = create_dataset(path, num_examples)\n",
        "  \n",
        "  input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
        "  target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
        "\n",
        "  return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "JFJWIindfXJ5"
      },
      "outputs": [],
      "source": [
        "# load할 dataset의 개수를 30000으로 설정\n",
        "num_examples = 30000\n",
        "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n",
        "\n",
        "# target과 input의 최대 길이 구하기(문장 최대 길이)\n",
        "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<keras_preprocessing.text.Tokenizer at 0x19bb30e18e0>"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "targ_lang"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6SFHicNfYa1",
        "outputId": "f439cdcb-0d93-407d-e23b-e6ab0a4dffc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "24000 24000 6000 6000\n"
          ]
        }
      ],
      "source": [
        "# 8:2 비율로 train-test split 진행\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "# 데이터 개수 뽑아보기\n",
        "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWEEaYHlfalW"
      },
      "source": [
        "- 구조와 관련된 파라미터 설정하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "cc3UtRN7fiI-"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang.word_index)+1\n",
        "vocab_tar_size = len(targ_lang.word_index)+1\n",
        "\n",
        "# tf.data.Dataset -> 텐서플로우에서 제공하는 Dataset 클래스입니다.\n",
        "# Dataset 클래스는 배치 구성, 데이터셋 셔플, 윈도우 구현, 변환 함수 적용 등 다양한 기능을 제공합니다.\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(64, 16), dtype=int32, numpy=\n",
              " array([[   1,   10,    4, ...,    0,    0,    0],\n",
              "        [   1,  780,  812, ...,    0,    0,    0],\n",
              "        [   1,    8,  146, ...,    0,    0,    0],\n",
              "        ...,\n",
              "        [   1,   67, 8451, ...,    0,    0,    0],\n",
              "        [   1,   12,  896, ...,    0,    0,    0],\n",
              "        [   1,    6,   11, ...,    0,    0,    0]])>,\n",
              " <tf.Tensor: shape=(64, 11), dtype=int32, numpy=\n",
              " array([[   1,    5, 1456, 3811,    3,    2,    0,    0,    0,    0,    0],\n",
              "        [   1,   16,  108,   36,    3,    2,    0,    0,    0,    0,    0],\n",
              "        [   1,    4,   87,   12, 1022,    3,    2,    0,    0,    0,    0],\n",
              "        [   1,   28,  230,   81,    3,    2,    0,    0,    0,    0,    0],\n",
              "        [   1,   71,    8,   27,    7,    2,    0,    0,    0,    0,    0],\n",
              "        [   1,    4,   76, 2091,    3,    2,    0,    0,    0,    0,    0],\n",
              "        [   1,   14, 4322,   55,   13,  642,    3,    2,    0,    0,    0],\n",
              "        [   1,   10,  169,   65,  160,    5,    3,    2,    0,    0,    0],\n",
              "        [   1,   16,  230,   82,    3,    2,    0,    0,    0,    0,    0],\n",
              "        [   1, 1135,   49,    4,   42,   21,  278,    3,    2,    0,    0],\n",
              "        [   1,    4,  234,    6,  251,   17,    3,    2,    0,    0,    0],\n",
              "        [   1,   16,   38,   40,   57,    3,    2,    0,    0,    0,    0],\n",
              "        [   1,    5,  118,   91,  448,    3,    2,    0,    0,    0,    0],\n",
              "        [   1,   10,  478,    3,    2,    0,    0,    0,    0,    0,    0],\n",
              "        [   1,    4,   29,  100,   13,  467,    3,    2,    0,    0,    0],\n",
              "        [   1,    5,  118,   91,   15,   93,    3,    2,    0,    0,    0],\n",
              "        [   1,    5,  274,  510,  101,    3,    2,    0,    0,    0,    0],\n",
              "        [   1, 1454,    8, 1844,    3,    2,    0,    0,    0,    0,    0],\n",
              "        [   1,    4,   30,   12, 1800,  318,    3,    2,    0,    0,    0],\n",
              "        [   1,    8,   10,   97,    6,   63,    7,    2,    0,    0,    0],\n",
              "        [   1,    4,   47,   15,   56,    6,    3,    2,    0,    0,    0],\n",
              "        [   1,    4,   26,  483,   57,    3,    2,    0,    0,    0,    0],\n",
              "        [   1, 4063,    8,  150,  469,    3,    2,    0,    0,    0,    0],\n",
              "        [   1,    5,    8, 3640,    3,    2,    0,    0,    0,    0,    0],\n",
              "        [   1,   71,   25,    4,  272, 1481,    7,    2,    0,    0,    0],\n",
              "        [   1,   64,   74,   37,    2,    0,    0,    0,    0,    0,    0],\n",
              "        [   1,   70,   29,    9,  387,    3,    2,    0,    0,    0,    0],\n",
              "        [   1,    5,   26,  571,    3,    2,    0,    0,    0,    0,    0],\n",
              "        [   1,   16,   23, 2057,    3,    2,    0,    0,    0,    0,    0],\n",
              "        [   1,    6,   24,  287,    3,    2,    0,    0,    0,    0,    0],\n",
              "        [   1,   88,   10,   50,    3,    2,    0,    0,    0,    0,    0],\n",
              "        [   1,   53,  197,    3,    2,    0,    0,    0,    0,    0,    0],\n",
              "        [   1,    4,   63,   15,  495,  115,    3,    2,    0,    0,    0],\n",
              "        [   1,   21,  168,    8,   44,    9, 2374,    3,    2,    0,    0],\n",
              "        [   1,   27, 1110,   15,   36,    3,    2,    0,    0,    0,    0],\n",
              "        [   1,    6,   38,  106,  202,   10,    3,    2,    0,    0,    0],\n",
              "        [   1,    4,  700,    6,    3,    2,    0,    0,    0,    0,    0],\n",
              "        [   1,    4,   22,  221,   20,    3,    2,    0,    0,    0,    0],\n",
              "        [   1,   27,   87,   12,  272,  687,    3,    2,    0,    0,    0],\n",
              "        [   1,    9,  153,    8,   55, 2128,    3,    2,    0,    0,    0],\n",
              "        [   1,   10,   26,    9, 2586,    3,    2,    0,    0,    0,    0],\n",
              "        [   1,   24,    6,  457,  225,    7,    2,    0,    0,    0,    0],\n",
              "        [   1,   32,   11,  129,   44,    7,    2,    0,    0,    0,    0],\n",
              "        [   1,   16,  636,    9,  394,    3,    2,    0,    0,    0,    0],\n",
              "        [   1,   58,   49,  132,    9,  434,    3,    2,    0,    0,    0],\n",
              "        [   1,    4,   47,   84,    3,    2,    0,    0,    0,    0,    0],\n",
              "        [   1,   14,  175,   14,   26,  626,    3,    2,    0,    0,    0],\n",
              "        [   1,    4,   63,    9,  438,  471,    3,    2,    0,    0,    0],\n",
              "        [   1,   29,    9,  387,    3,    2,    0,    0,    0,    0,    0],\n",
              "        [   1,   27, 1460,   21,  471,    3,    2,    0,    0,    0,    0],\n",
              "        [   1,   46,   11, 2200,  187,    3,    2,    0,    0,    0,    0],\n",
              "        [   1,    4,   18,   48,  823,    3,    2,    0,    0,    0,    0],\n",
              "        [   1,    4,   18,  103,   50,    3,    2,    0,    0,    0,    0],\n",
              "        [   1,   82,   24,    6,   85,  296,    7,    2,    0,    0,    0],\n",
              "        [   1,   19,   38,   22,    3,    2,    0,    0,    0,    0,    0],\n",
              "        [   1,   82,   22,    6,  171,    7,    2,    0,    0,    0,    0],\n",
              "        [   1,   56,  120,    3,    2,    0,    0,    0,    0,    0,    0],\n",
              "        [   1,   25,    6,   73,   17,    7,    2,    0,    0,    0,    0],\n",
              "        [   1,    4,  321,   44,   13, 2218,    3,    2,    0,    0,    0],\n",
              "        [   1,    5,  331,   17,    9,  773,    3,    2,    0,    0,    0],\n",
              "        [   1,   71,   22,    6,   47,   10,    7,    2,    0,    0,    0],\n",
              "        [   1,   20,  501,   76,  437,    3,    2,    0,    0,    0,    0],\n",
              "        [   1,  537,   15,   72,    6,   49,    5,    3,    2,    0,    0],\n",
              "        [   1,   32,  478,   39,    7,    2,    0,    0,    0,    0,    0]])>)"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "next(iter(dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpvSXgBBfi6o",
        "outputId": "0a7660e2-48bf-415c-8afd-a92824de2608"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(TensorShape([64, 16]), TensorShape([64, 11]))"
            ]
          },
          "execution_count": 28,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 첫 번째 배치 뽑아보기\n",
        "# input_batch의 경우, 총 64개 데이터로 이루어져 있고, 1개 문장이 16개 단어로 이루어져 있습니다.\n",
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZBV4UUBfgkr"
      },
      "source": [
        "- 인코더 구현하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aE3-rfGWfm1k"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    # |x| = (batch_sz, seq_len)\n",
        "    x = self.embedding(x) # |x| = (batch_sz, seq_len, embedding_dim)\n",
        "    output, state = self.gru(x, initial_state=hidden)\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehWNiQ_ffokz",
        "outputId": "c99a96ce-368c-42f1-aedf-fcb3f42826df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (64, 16, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
          ]
        }
      ],
      "source": [
        "# sample input을 통해 Encoder 레이어 결과값의 shape을 확인해보겠습니다\n",
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "# sample input\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "print('Encoder output shape: (batch size, sequence length, units)', sample_output.shape)\n",
        "print('Encoder Hidden state shape: (batch size, units)', sample_hidden.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKG3Y_BafqBJ"
      },
      "outputs": [],
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    # query hidden state shape == (batch_size, hidden size)\n",
        "    # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # values shape == (batch_size, max_len, hidden size)\n",
        "    # we are doing this to broadcast addition along the time axis to calculate the score\n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # score shape == (batch_size, max_length, 1)\n",
        "    # we get 1 at the last axis because we are applying score to self.V\n",
        "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(query_with_time_axis) + self.W2(values)))\n",
        "    # W1(query_with_time_axis) == (batch_size, 1, units)\n",
        "    # W2(values) == (batch_size, max_len, units)\n",
        "    # W1(query_with_time_axis) + W2(values) == (batch_size, max_len, units)\n",
        "    # V(tf.nn.tanh(W1(query_with_time_axis) + W2(values))) == (batch_size, max_len, 1)\n",
        "\n",
        "    attention_weights = tf.nn.softmax(score, axis=1) # attention_weights == (batch_size, max_length, 1)\n",
        "\n",
        "    context_vector = attention_weights * values # context_vector == (batch_size, max_len, hidden_size)\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1) # context_vector == (batch_size, hidden_size)\n",
        "\n",
        "    return context_vector, attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZuX1KCdfr8h",
        "outputId": "45355c4b-542c-4a9c-e05f-9b4c752f9c2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attention result shape: (batch size, units) (64, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (64, 16, 1)\n"
          ]
        }
      ],
      "source": [
        "attention_layer = BahdanauAttention(10)\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "print(\"Attention result shape: (batch size, units)\", attention_result.shape)\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1)\", attention_weights.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjbGgc5Efuor"
      },
      "source": [
        "- **디코더 구현**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6l1Zd0Nkft6G"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    # used for attention\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    # x == (batch_size, 1)\n",
        "    # hidden == (batch_size, hidden_size)\n",
        "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "    # context_vector == (batch_size, hidden_size)\n",
        "    # attention_weights == (batch_size, max_length, 1)\n",
        "\n",
        "    x = self.embedding(x) # x == (batch_size, 1, embedding_dim)\n",
        "\n",
        "    # tf.expand_dims(context_vector, 1) == (batch_size, 1, hidden_size)\n",
        "    # tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1) == (batch_size, 1, embedding_dim+hidden_size)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    # passing the concatenated vector to the GRU\n",
        "    # output == (batch_size, 1, hidden_size)\n",
        "    # state == (batch_size, hidden_size)\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    \n",
        "    output = tf.reshape(output, (-1, output.shape[2])) # output  == (batch_size * 1, hidden_size)\n",
        "\n",
        "    x = self.fc(output) # x == (batch_size, vocab)\n",
        "\n",
        "    return x, state, attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GK7-WsOfx4k",
        "outputId": "6befb313-94ca-4612-c8f2-4889253a3d00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (64, 4935)\n"
          ]
        }
      ],
      "source": [
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
        "                                      sample_hidden, sample_output)\n",
        "\n",
        "print('Decoder output shape: (batch_size, vocab size)', sample_decoder_output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ABDicArafzt_"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,\n",
        "                                                            reduction='none')\n",
        "\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfYvKnhsmnaH"
      },
      "source": [
        "Teacher Forcing\n",
        "- seq2seq에서 decoder의 예측값이 아닌 실제 정답인 target을 다음 타임 스텝의 입력으로 넣어주는 방법을 Teacher Forcing이라고 합니다.\n",
        "- 장점\n",
        "  - 만약 decoder가 엉뚱한 대답을 내놓더라도, 학습 시 실제 정답을 넣어주기 때문에 seq2seq 학습에 안정성을 더해줍니다.\n",
        "- 단점\n",
        "  - 실제 학습과 추론 코드를 각각 구성해야 합니다.\n",
        "  - 학습과 추론 사이의 괴리가 존재합니다.\n",
        "\n",
        ">❗️  Teacher forcing은 지금 반드시 알아야 하는 개념이 아닙니다. N424에서 다룰 Transformer에서는 더이상 사용되지 않는 방법론이기도 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTeGGZS1f2M6"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "    # Teacher forcing - feeding the target as the next input\n",
        "    for t in range(1, targ.shape[1]):\n",
        "      # passing enc_output to the decoder\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "      # using teacher forcing\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20YBdgsYf5gr",
        "outputId": "beadcd4c-60e7-41b7-8e43-9b925a03af86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 4.6026\n",
            "Epoch 1 Batch 100 Loss 2.1524\n",
            "Epoch 1 Batch 200 Loss 1.8952\n",
            "Epoch 1 Batch 300 Loss 1.6539\n",
            "Epoch 1 Loss 2.0383\n",
            "Time taken for 1 epoch 1016.7628138065338 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 1.5593\n",
            "Epoch 2 Batch 100 Loss 1.4487\n",
            "Epoch 2 Batch 200 Loss 1.2338\n",
            "Epoch 2 Batch 300 Loss 1.3027\n",
            "Epoch 2 Loss 1.3807\n",
            "Time taken for 1 epoch 992.9955353736877 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 1.0330\n",
            "Epoch 3 Batch 100 Loss 1.0200\n",
            "Epoch 3 Batch 200 Loss 0.8721\n",
            "Epoch 3 Batch 300 Loss 0.9157\n",
            "Epoch 3 Loss 0.9653\n",
            "Time taken for 1 epoch 989.1491215229034 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 0.6319\n",
            "Epoch 4 Batch 100 Loss 0.6260\n",
            "Epoch 4 Batch 200 Loss 0.5699\n",
            "Epoch 4 Batch 300 Loss 0.7347\n",
            "Epoch 4 Loss 0.6478\n",
            "Time taken for 1 epoch 986.2824234962463 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.4384\n",
            "Epoch 5 Batch 100 Loss 0.3671\n",
            "Epoch 5 Batch 200 Loss 0.4387\n",
            "Epoch 5 Batch 300 Loss 0.4493\n",
            "Epoch 5 Loss 0.4406\n",
            "Time taken for 1 epoch 998.4929230213165 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.2667\n",
            "Epoch 6 Batch 100 Loss 0.2406\n",
            "Epoch 6 Batch 200 Loss 0.2759\n",
            "Epoch 6 Batch 300 Loss 0.3238\n",
            "Epoch 6 Loss 0.3082\n",
            "Time taken for 1 epoch 976.1749527454376 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.2104\n",
            "Epoch 7 Batch 100 Loss 0.2372\n",
            "Epoch 7 Batch 200 Loss 0.2571\n",
            "Epoch 7 Batch 300 Loss 0.2070\n",
            "Epoch 7 Loss 0.2207\n",
            "Time taken for 1 epoch 1002.5251026153564 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.1459\n",
            "Epoch 8 Batch 100 Loss 0.1691\n",
            "Epoch 8 Batch 200 Loss 0.2185\n",
            "Epoch 8 Batch 300 Loss 0.1537\n",
            "Epoch 8 Loss 0.1652\n",
            "Time taken for 1 epoch 1005.3521428108215 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.1419\n",
            "Epoch 9 Batch 100 Loss 0.1146\n",
            "Epoch 9 Batch 200 Loss 0.0952\n",
            "Epoch 9 Batch 300 Loss 0.1238\n",
            "Epoch 9 Loss 0.1262\n",
            "Time taken for 1 epoch 985.0161681175232 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.0667\n",
            "Epoch 10 Batch 100 Loss 0.0909\n",
            "Epoch 10 Batch 200 Loss 0.1094\n",
            "Epoch 10 Batch 300 Loss 0.1214\n",
            "Epoch 10 Loss 0.1024\n",
            "Time taken for 1 epoch 987.7415053844452 sec\n",
            "\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                   batch,\n",
        "                                                   batch_loss.numpy()))\n",
        "      \n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0EujLQZf8NJ"
      },
      "outputs": [],
      "source": [
        "def evaluate(sentence):\n",
        "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_length_inp,\n",
        "                                                         padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "  result = ''\n",
        "\n",
        "  hidden = [tf.zeros((1, units))]\n",
        "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "  for t in range(max_length_targ):\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                         dec_hidden,\n",
        "                                                         enc_out)\n",
        "\n",
        "    # storing the attention weights to plot later on\n",
        "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "    attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "    result += targ_lang.index_word[predicted_id] + ' '\n",
        "\n",
        "    if targ_lang.index_word[predicted_id] == '<end>':\n",
        "      return result, sentence, attention_plot\n",
        "\n",
        "    # the predicted ID is fed back into the model\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "  return result, sentence, attention_plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIGrhbkrf-_u"
      },
      "outputs": [],
      "source": [
        "# function for plotting the attention weights\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "  fig = plt.figure(figsize=(10,10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "  ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnamxQ1sgAkK"
      },
      "outputs": [],
      "source": [
        "def translate(sentence):\n",
        "  result, sentence, attention_plot = evaluate(sentence)\n",
        "\n",
        "  print('Input: %s' % (sentence))\n",
        "  print('Predicted translation: {}'.format(result))\n",
        "\n",
        "  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "nZ6MY4FtgDe7",
        "outputId": "6935584e-d2ef-4ec5-cad5-4d23fb00e20f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: <start> hace mucho frio aqui . <end>\n",
            "Predicted translation: it s very cold here . <end> \n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light",
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "translate(u'hace mucho frio aqui.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "6V6aKQ4BgFq3",
        "outputId": "039f0a1b-a008-4521-f5f3-ad8f71bc5732"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: <start> esta es mi vida . <end>\n",
            "Predicted translation: this is my life . <end> \n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light",
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "translate(u'esta es mi vida.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyVjn9UeaH0h"
      },
      "source": [
        "## Review"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zAIH2w0YzRe"
      },
      "source": [
        "- 언어 모델 (Language Model)\n",
        "    - 통계 기반의 언어 모델(Statistical Language Model)\n",
        "    - 신경망 언어 모델(Neural Network Language Model) \n",
        "\n",
        "- 순환 신경망 (Recurrent Neural Network, RNN)\n",
        "    - RNN의 구조\n",
        "    - RNN의 장점과 단점\n",
        "        - 기울기 소실(Gradient Vanishing)\n",
        "\n",
        "- LSTM & GRU\n",
        "    - LSTM\n",
        "        - Cell state\n",
        "    - GRU\n",
        "\n",
        "- Attention\n",
        "    - Attention\n",
        "        - 장기 의존성(Long-term Dependency)\n",
        "    - Query, Key, Vector\n",
        "        - 어떤 벡터가 각 요소에 해당될까요?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "x_eOv4kAYb0Z",
        "aSdN5u4fJ6ol",
        "gAS2HDrvZKE-",
        "bzJSMs2CSkj4"
      ],
      "name": "N423_Language_Modeling_with_RNN_.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "33e4e08a7b7fa754f13c5b267cb1063e8854a8078d9e75eb423594d4bff0091a"
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('tensor')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
