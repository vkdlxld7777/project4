Non-localNeuralNetworks
XiaolongWang
1,2

RossGirshick
2
AbhinavGupta
1
KaimingHe
2
1
Carnegie MellonUniversity
2
FacebookAIResearch
Abstract
Bothconvolutionalandrecurrentoperationsarebuilding
blocksthatprocessonelocalneighborhoodatatime.In

thispaper, wepresentnon-local operationsasageneric

familyofbuildingblocksforcapturing long-rangedepen-
dencies.Inspiredbytheclassicalnon-localmeansmethod
[
4
]incomputervision,ournon-localoperationcomputes
theresponseatapositionasaweightedsumofthefeatures
atallpositions.Thisbuildingblockcanbepluggedinto

manycomputervisionarchitectures.Onthetaskofvideo
classication,evenwithoutanybellsandwhistles,our non-
localmodelscancompeteoroutperformcurrentcompetition
winnerson bothKineticsandCharades datasets.Instatic
imagerecognition,ournon-localmodelsimproveobjectde-
tection/segmentationand poseestimationontheCOCOsuite
oftasks.Codewillbemadeavailable.

1.Introduction
Capturing
long-range
dependenciesisofcentralimpor-
tanceindeepneuralnetworks.Forsequentialdata(
e.g
.,
inspeech,language),
recurrent
operations[
38
,
23
]arethe
dominantsolutiontolong-rangedependencymodeling.For
imagedata,long-distancedependenciesaremodeledbythe
largereceptive elds formedbydeepstacksof
convolutional
operations[
14
,
30
].
Convolutionalandrecurrentoperationsbothprocessa
local
neighborhood,eitherinspaceortime;thuslong-range
dependenciescanonlybecapturedwhen theseoperations

areappliedrepeatedly,propagatingsignalsprogressively

throughthedata.Repeatinglocaloperationshasseveral
limitations.First,itiscomputationallyinefcient.Second,
itcausesoptimizationdifcultiesthatneedtobecarefully

addressed[
23
,
21
].Finally,these challengesmakemulti-
hopdependencymodeling,
e.g
.,whenmessagesneedtobe
deliveredbackandforthbetweendistantpositions,difcult.
Inthispaper,wepresent
non-local
operationsasanef-
cient,simple,andgeneric componentforcapturinglong-

rangedependencieswithdeepneuralnetworks.Our pro-
posednon-localoperationisageneralizationoftheclassical
non-localmeanoperation[
4
]incomputervision.Intuitively,
anon-localoperationcomputestheresponseataposition

WorkdoneduringaninternshipatFacebookAIResearch.
Figure1.Aspacetime
non-local
operationinournetworktrained
forvideoclassicationinKinetics.Aposition
x
i
'sresponseis
computedbytheweightedaverageofthefeaturesof
all
positions
x
j
(onlythehighestweightedonesareshownhere).Inthisexample
computedbyourmodel,notehowitrelatestheballintherstframe
totheballinthelasttwoframes. MoreexamplesareinFigure
3
.
asaweightedsumofthefeaturesat
allpositions
inthein-
putfeaturemaps(Figure
1
). Thesetofpositionscanbein
space,time,orspacetime,implying thatouroperationsare
applicablefor image,sequence,andvideoproblems.
Thereareseveraladvantagesofusingnon-localopera-
tions:(a)Incontrasttothe progressivebehaviorofrecurrent
andconvolutionaloperations,non-localoperationscapture
long-rangedependenciesdirectlybycomputinginteractions
betweenanytwopositions,regardlessoftheirpositionaldis-
tance;(b)Asweshowinexperiments,non-localoperations
areefcientandachieve theirbestresultsevenwithonly

afewlayers(
e.g
.,5);(c)Finally,ournon-localoperations
maintainthevariableinputsizesandcanbeeasilycombined
withotheroperations(
e.g
.,convolutionsaswewilluse).
Weshowcasetheeffectivenessofnon-localoperations in
theapplicationofvideoclassication.Invideos,long-range
interactionsoccurbetweendistantpixelsin spaceaswellas
time.Asinglenon-localblock,whichisourbasicunit,can
directlycapturethesespacetimedependenciesinafeedfor-
wardfashion.Withafewnon-localblocks,ourarchitecures
called
non-localneuralnetworks
aremoreaccurateforvideo
classicationthan2Dand 3Dconvolutionalnetworks[
48
]
(includingtheinatedvariant [
7
]). Inaddition,non-local
neural networksaremorecomputationally economicalthan
their3Dconvolutionalcounterparts.Comprehensiveabla-
tionstudiesarepresentedontheKinetics[
27
]andCharades
[
44
]datasets.
UsingRGBonlyandwithoutanybellsand
whistles
(
e.g
.,opticalow,multi-scaletesting),ourmethod
achievesresultsonparwith orbetterthanthelatestcompeti-
tionswinnersonbothdatasets.
1
7794

To demonstratethegeneralityofnon-localoperations,
wefurtherpresentobjectdetection/segmentationandpose
estimationexperimentsontheCOCOdataset[
33
].Ontopof
thestrongMaskR-CNNbaseline[
19
],ournon-localblocks
canincreaseaccuracyonallthree tasksatasmallextra

computationalcost.Togetherwiththeevidenceonvideos,
theseimageexperimentsshowthatnon-localoperationsare
generallyusefulandcanbecomeabasicbuildingblockin
designingdeepneuralnetworks.

2.RelatedWork

Non-localimageprocessing.
Non-localmeans[
4
]isaclas-
sicallteringalgorithmthat computesaweightedmeanof
allpixelsinanimage.Itallowsdistantpixelstocontributeto
thelteredresponseatalocationbasedonpatchappearance
similarity.This non-locallteringideawaslaterdeveloped
intoBM3D(block-matching3D)[
10
],whichperformslter-
ingonagroupofsimilar,butnon-local,patches.BM3Dis
asolidimagedenoisingbaselineevencomparedwithdeep
neuralnetworks[
5
].Blockmatchingwasusedwithneural
networksforimagedenoising [
6
,
31
].Non-localmatch-
ingisalsotheessenceofsuccessfultexturesynthesis[
12
],
super-resolution [
16
],andinpainting[
1
] algorithms.
Graphical models.
Long-rangedependenciescanbemod-
eledbygraphicalmodelssuchasconditionalrandomelds
(CRF)[
29
,
28
].Inthecontextofdeepneuralnetworks,a
CRFcanbeexploitedtopost-processsemanticsegmenta-

tionpredictionsofanetwork[
9
].Theiterativemean-eld
inferenceofCRFcanbeturnedintoarecurrentnetwork

andtrained[
56
,
42
,
8
,
18
,
34
].Incontrast,ourmethodisa
simplerfeedforwardblockforcomputingnon-localltering.
Unlikethesemethodsthat weredevelopedforsegmentation,
ourgeneral-purposecomponentisappliedfor classication
anddetection.Thesemethods andoursarealsorelatedtoa
moreabstractmodelcalledgraphneuralnetworks[
41
].
Feedforward modelingforsequences.
Recentlythere
emergedatrendofusing feedforward(
i.e
.,non-recurrent)
networksformodelingsequencesinspeechandlanguage

[36
,
54
,
15
].Inthesemethods,long-termdependencies
arecapturedbythelargereceptiveeldscontributedby
verydeep1-Dconvolutions.Thesefeedforwardmodelsare
amenabletoparallelizedimplementationsandcanbemore
efcientthanwidelyusedrecurrentmodels.

Self-attention.Ourworkisrelatedtotherecent
self-
attention
[
49
]methodformachinetranslation.Aself-
attentionmodulecomputestheresponseatapositionin

asequence (
e.g
.,asentence)byattendingtoallpositions
andtakingtheirweightedaverageinanembeddingspace.
Aswewilldiscussinthenext,self-attentioncanbeviewed
asaform ofthenon-localmean[
4
],andinthissenseour
workbridgesself-attentionformachinetranslationtothe
moregeneral classofnon-locallteringoperationsthat are
applicabletoimage andvideoproblemsincomputervision.
Interactionnetworks.
InteractionNetworks
(IN)[
2
,
52
]
wereproposedrecentlyformodelingphysical systems.They
operateon graphsofobjectsinvolvedinpairwiseinteractions.
Hoshen[
24
]presentedthemoreefcientVertexAttention
IN(VAIN)inthecontextofmulti-agentpredictivemodeling.
Anothervariant,namedRelationNetworks[
40
],computesa
function onthefeature embeddingsatall pairsofpositions
initsinput.Ourmethodalsoprocessesallpairs,aswewill
explain(
f
(
x
i
;
x
j
)
inEq.(
1
)).Whileournon-localnetworks
areconnectedtotheseapproaches,ourexperimentsindicate
thatthe
non-locality
ofthemodel,whichisorthogonalto
theideasofattention/interaction/relation(
e.g
.,anetwork
canattendtoalocalregion),isthekeytotheirempirical
success.Non-localmodeling,along-timecrucialelementof
imageprocessing(
e.g
.,[
12
,
4
]),hasbeenlargelyoverlooked
inrecentneuralnetworksforcomputervision.

Videoclassicationarchitectures.
Anaturalsolutionto
videoclassicationistocombinethesuccessofCNNsfor
imagesandRNNsforsequences[
55
,
11
].Incontrast,feed-
forwardmodelsareachievedby3Dconvolutions(C3D)

[26
,
48
]inspacetime,andthe3Dlterscanbeformedby
ﬁinatingﬂ[
13
,
7
]pre-trained2Dlters.Inadditiontoend-
to-endmodelingonrawvideoinputs,ithasbeenfoundthat
opticalow[
45
]andtrajectories[
50
,
51
]canbehelpful.
Bothowandtrajectoriesareoff-the-shelfmodulesthat

mayndlong-range,non-local dependency. Asystematic
comparisonofvideoarchitecturescanbefoundin[
7
].
3.Non-localNeuralNetworks
Werstgiveageneraldenitionofnon-localoperations
andthenwe provideseveralspecicinstantiationsofit.

3.1.Formulation
Followingthenon-localmeanoperation[
4
],wedenea
genericnon-localoperationindeepneuralnetworksas:
y
i
=
1
C
(
x
)
X
8
j
f
(
x
i
;
x
j
)
g 
(
x
j
)
:
(1)
Here
i
istheindexofan outputposition(inspace, time,or
spacetime)whoseresponseistobecomputedand
j
isthe
indexthatenumeratesallpossiblepositions.
x
istheinput
signal(image,sequence,video;oftentheirfeatures)and
y
istheoutputsignalofthesamesizeas
x
.Apairwisefunc-
tion
f
computesascalar(representingrelationship suchas
afnity)between
i
andall
j
.Theunaryfunction
g 
computes
arepresentationoftheinputsignalattheposition
j
.The
responseisnormalizedbyafactor
C
(
x
)
.
Thenon-localbehaviorinEq.(
1
)isduetothefactthat
allpositions(
8
j
)areconsideredintheoperation.Asa
comparison,aconvolutionaloperationsumsuptheweighted
inputina
local
neighborhood(
e.g
.,
i

1

j

i
+1
ina
1Dcasewithkernelsize3),andarecurrentoperationattime
7795

i
isoftenbasedonlyonthecurrent and thelatesttimesteps
(
e.g
.,
j
=
i
or
i

1
).
Thenon-localoperationisalsodifferentfromafully-
connected(
fc
)layer.Eq.(
1
)computesresponsesbasedon
relationshipsbetweendifferentlocations,whereas
fc
uses
learnedweights.Inotherwords,therelationshipbetween
x
j
and
x
i
isnotafunctionoftheinputdatain
fc
,unlikeinnon-
locallayers.Furthermore,ourformulationinEq.(
1
)supports
inputsof
variable
sizes,andmaintainsthecorresponding
sizeintheoutput.Onthecontrary,an
fc
layerrequiresa
xed-sizeinput/outputandlosespositionalcorrespondence
(
e.g
.,thatfrom
x
i
to
y
i
attheposition
i
).
Anon-localoperationisaexiblebuildingblockandcan
beeasilyusedtogetherwithconvolutional/recurrentlayers.
Itcanbeaddedintotheearlierpartofdeepneuralnetworks,
unlike
fc
layersthatareoftenusedin theend.Thisallowsus
tobuildaricherhierarchythatcombinesbothnon-localand
localinformation.

3.2.Instantiations
Nextwedescribeseveralversionsof
f
and
g 
.Interest-
ingly,wewillshowbyexperiments(Table
2a
)thatournon-
localmodelsarenotsensitivetothesechoices, indicating
thatthegenericnon-localbehavioristhemainreasonforthe
observedimprovements.
Forsimplicity,weonlyconsider
g 
intheformofalinear
embedding:
g 
(
x
j
)=
W
g
x
j
,where
W
g
isaweightmatrix
to be learned.Thisisimplementedas,
e.g
.,1

1convolution
inspace or1

1

1convolutioninspacetime.
Nextwediscusschoicesforthepairwisefunction
f
.
Gaussian.
Followingthenon-localmean[
4
]andbilateral
lters[
47
],a naturalchoiceof
f
istheGaussianfunction.In
thispaper weconsider:
f
(
x
i
;
x
j
)=
e
x
T

i
x
j
:
(2)
Here
x
T

i
x
j
isdot-product similarity.Euclideandistanceas
usedin[
4
,
47
]isalsoapplicable, butdotproductismore
implementation-friendlyinmoderndeeplearning platforms.
Thenormalizationfactorissetas
C
(
x
)=
P
8
j
f
(
x
i
;
x
j
)
.
EmbeddedGaussian.
A simpleextensionoftheGaussian
functionistocomputesimilarityinanembeddingspace.In
thispaper weconsider:
f
(
x
i
;
x
j
)=
e

(
x
i
)
T
˚
(
x
j
)
:
(3)
Here

(
x
i
)=
W

x
i
and
˚
(
x
j
)=
W
˚
x
j
aretwoembed-
dings.Asabove,weset
C
(
x
)=
P
8
j
f
(
x
i
;
x
j
)
.
Wenotethat
theself-attentionmodule[
49
]recentlypre-
sentedformachinetranslationisaspecialcaseofnon-local
operationsintheembeddedGaussianversion.
Thiscanbe
seenfromthefactthatforagiven
i
,
1
C
(
x
)
f
(
x
i
;
x
j
)
becomes
the
softmax
computationalongthedimension
j
.So wehave
§
: 1×1×1
´
: 1×1×1
g
: 1×1×1
1×1×1
softmax
z
T×H×W×1024
T×H×W×512T×H×W×512T×H×W×512
THW×512512×THW
THW×THW
THW×512
THW×512
T×H×W×512
T×H×W×1024
x
Figure 2.Aspacetime
non-localblock
.Thefeaturemapsare
shownastheshapeoftheirtensors,
e.g
.,
T

H

W

1024
for
1024channels(properreshapingisperformedwhennoted).ﬁ


ﬂ
denotesmatrixmultiplication,andﬁ

ﬂdenoteselement-wisesum.
Thesoftmaxoperationisperformedoneachrow.Theblueboxesde-
note1

1

1convolutions.HereweshowtheembeddedGaussian
version,withabottleneckof512channels.ThevanillaGaussian

versioncanbedonebyremoving

and
˚
,andthedot-product
versioncanbedonebyreplacingsoftmaxwithscalingby
1
=N
.
y
=
softmax
(
x
T
W
T

W
˚
x
)
g 
(
x
)
,whichistheself-attention
formin[
49
].Assuch,ourworkprovidesinsightbyrelating
thisrecentself-attentionmodeltotheclassiccomputervision
method ofnon-localmeans[
4
],and extendsthesequential
self-attentionnetworkin [
49
]toagenericspace/spacetime
non-localnetworkforimage/videorecognitionincomputer
vision.
Despitetherelationto[
49
],weshowthattheattentional
behavior(dueto softmax)is
not
essentialin theapplications
westudy.Toshow this,wedescribetwoalternativeversions
ofnon-localoperationsnext.

Dotproduct.
f
can bedenedasadot-productsimilarity:
f
(
x
i
;
x
j
)=

(
x
i
)
T
˚
(
x
j
)
:
(4)
Hereweadopttheembeddedversion.Inthiscase,wesetthe

normalizationfactoras
C
(
x
)=
N
,where
N
is thenumberof
positionsin
x
,ratherthanthesumof
f
,becauseitsimplies
gradientcomputation.Anormalizationlikethisisnecessary
because theinputcan havevariablesize.
Themaindifferencebetweenthedotproductandembed-
dedGaussianversionsisthepresenceofsoftmax,which
playstheroleofanactivationfunction.

Concatenation.Concatenationisusedbythepairwisefunc-
tionin RelationNetworks[
40
]forvisualreasoning.Wealso
evaluateaconcatenationformof
f
:
f
(
x
i
;
x
j
)=
ReLU
(
w
T
f
[

(
x
i
)
;˚
(
x
j
)])
:
(5)
Here
[

;

]
denotesconcatenationand
w
f
isa weightvector
thatprojectstheconcatenatedvectortoascalar.Asabove,
we set
C
(
x
)=
N
.Inthiscase,weadoptReLU[
35
]in
f
.
7796

Theaboveseveralvariantsdemonstratetheexibility
ofourgenericnon-localoperation.Webelievealternative
versionsarepossible andmayimproveresults.
3.3.Block
Wewrapthenon-localoperationinEq.(
1
)intoanon-local
blockthatcanbeincorporatedinto manyexistingarchitec-
tures.Wedeneanon-localblockas:
z
i
=
W
z
y
i
+
x
i
;
(6)
where
y
i
is giveninEq.(
1
)andﬁ
+
x
i
ﬂdenotesaresidual
connection [
21
].Theresidual connection allowsustoinsert
anewnon-localblockintoanypre-trainedmodel, without
breakingitsinitialbehavior(
e.g
.,if
W
z
isinitializedaszero).
Anexamplenon-localblockisillustrated inFigure
2
.The
pairwisecomputationinEq.(
2
),(
3
),or(
4
)canbesimply
done bymatrixmultiplicationasshowninFigure
2
;the
concatenationversionin(
5
)isstraightforward.
Thepairwisecomputationofanon-localblockis
lightweightwhenitisusedinhigh-level,sub-sampledfea-

ture maps.Forexample,typicalvaluesinFigure
2
are
T
=4
,
H
=
W
=14
or
7
.Thepairwisecomputation
asdonebymatrixmultiplication iscomparabletoatypical
convolutionallayerinstandardnetworks.Wefurtheradopt
thefollowingimplementationsthatmakeitmoreefcient.

ImplementationofNon-localBlocks.
We setthenumber
ofchannelsrepresentedby
W
g
,
W

,and
W
˚
tobehalfof
thenumberofchannelsin
x
.Thisfollowsthebottleneck
designof[
21
]and reducesthecomputationofablockby
aboutahalf.Theweightmatrix
W
z
inEq.(
6
)computesa
position-wiseembeddingon
y
i
,matchingthenumberof
channelstothatof
x
.SeeFigure
2
.
Asubsampling trickcanbe usedtofurtherre-
ducecomputation.WemodifyEq.(
1
)as:
y
i
=
1
C
(
^x
)
P
8
j
f
(
x
i
;
^x
j
)
g 
(
^x
j
)
,where
^x
isasubsampledversion
of
x
(
e.g
.,bypooling).Weperformthisinthespatialdo-
main,whichcanreduce theamountofpairwisecomputation
by1/4.Thistrickdoesnotalterthenon-local behavior,but
onlymakesthecomputationsparser.Thiscanbedoneby
addingamaxpoolinglayerafter
˚
and
g 
inFigure
2
.
Weusetheseefcientmodicationsforallnon-local
blocksstudiedinthispaper.

4.VideoClassicationModels
Tounderstandthebehaviorofnon-localnetworks,we
conductcomprehensiveablationexperimentsonvideo clas-
sicationtasks.First wedescribeourbaselinenetworkarchi-

tecturesfor thistask,andthenextendtheminto3DConvNets
[
48
,
7
] andourproposednon-localnets.
2DConvNetbaseline(C2D).
Toisolatethetemporalef-
fects ofour non-localnets
vs
.3DConvNets,weconstruct
layer
outputsize
conv
1
7

7,64,stride2, 2, 2
16

112

112
pool
1
3

3

3max,stride2, 2, 2
8

56

56
res
2
2

4
1

1, 64
3

3, 64
1

1, 256
3

5

3
8

56

56
pool
2
3

1

1max,stride2, 1, 1
4

56

56
res
3
2

4
1

1, 128
3

3, 128
1

1, 512
3

5

4
4

28

28
res
4
2

4
1

1, 256
3

3, 256
1

1, 1024
3

5

6
4

14

14
res
5
2

4
1

1, 512
3

3, 512
1

1, 2048
3

5

3
4

7

7
globalaveragepool,fc
1

1

1
Table1.Our
baseline
ResNet-50C2Dmodelforvideo.Thedi-
mensions of 3D outputmapsandlterkernelsare inT

H

W(2D
kernelsinH

W),withthenumberofchannelsfollowing.The
inputis32

224

224.Residualblocksareshowninbrackets.
asimple2Dbaselinearchitectureinwhichthetemporal
dimensionistriviallyaddressed(
i.e
.,onlybypooling).
Table
1
showsourC2DbaselineunderaResNet-50back-
bone.Theinputvideoclip has 32frameseachwith224

224
pixels.AllconvolutionsinTable
1
areinessence2Dker-
nelsthatprocessthe inputframe-by-frame(implementedas
1

k

k
kernels).Thismodel canbedirectlyinitializedfrom
theResNet weightspre-trainedonImageNet.A ResNet-101
counterpartisbuiltinthesameway.
Theonly operationinvolvingthe temporaldomainare
thepoolinglayers.Inotherwords,thisbaselinesimply
aggregatestemporalinformation.

Inated3DConvNet(I3D).
Asdonein[
13
,
7
],onecan
turntheC2DmodelinTable
1
intoa3Dconvolutional
counterpartbyﬁinatingﬂthekernels.Forexample,a2D
k

k
kernelcanbeinatedasa3D
t

k

k
kernelthatspans
t
frames.Thiskernel canbeinitializedfrom2Dmodels(pre-
trainedonImageNet):eachofthe
t
planes inthe
t

k

k
kernel isinitializedbythepre-trained
k

k
weights, rescaled
by
1
=t
.Ifavideoconsistsofasinglestaticframerepeated
in time,thisinitializationproducesthesameresultsasthe
2Dpre-trainedmodelrunonastaticframe.
Westudytwocasesofinations:weeitherinatethe
3

3kernelinaresidualblockto3

3

3(similarto[
7
]),or
therst1

1kernelinaresidualblockto3

1

1(similarto
[
13
]).WedenotetheseasI3D
3

3

3
andI3D
3

1

1
.As3D
convolutionsarecomputationallyintensive,weonlyinate
onekernelforevery 2residualblocks;inatingmorelayers
showsdiminishingreturn.Weinateconv
1
to5

7

7.
Theauthorsof[
7
]haveshownthatI3Dmodelsaremore
accuratethantheirCNN+LSTMcounterparts.

Non-localnetwork.
Weinsertnon-localblocksintoC2Dor
I3Dtoturntheminto non-localnets.We investigateadding
1,5,or10non-localblocks;theimplementationdetailsare
describedinthenextsectionincontext.
7797

Figure3.Examplesofthe behaviorofanon-localblockinres
3
computedbya5-blocknon-localmodeltrainedonKinetics.Theseexamples
are fromheld-outvalidationvideos.Thestartingpointofarrowsrepresentsone
x
i
,andtheending pointsrepresent
x
j
.The 20highest
weighted arrowsforeach
x
i
arevisualized.The4framesarefroma32-frameinput,shownwithastrideof8frames.Thesevisualizations
showhowthemodelnds relatedcluestosupportits prediction.

4.1.ImplementationDetails

Training.
Ourmodelsarepre-trainedonImageNet[
39
].
Unless specied,wene-tuneourmodelsusing32-frame
inputclips.Theseclipsareformedbyrandomlycroppingout

64 consecutiveframesfromtheoriginalfull-lengthvideoand

thendroppingeveryotherframe.Thespatialsizeis 224

224
pixels,randomlycroppedfromascaledvideowhose shorter
sideisrandomlysampledin
[256
;
320]
pixels,following[
46
].
Wetrainonan8-GPUmachineandeachGPUhas8clipsina
mini-batch(sointotalwithamini-batchsizeof64 clips).We
trainourmodelsfor400kiterationsintotal,startingwitha
learningrate of0.01andreducingitbyafactorof10atevery
150kiterations(seealsoFigure
4
).Weuseamomentum
of0.9andaweight decayof0.0001.Weadoptdropout

[22
]aftertheglobalpoolinglayer,withadropoutratioof
0.5. Wene-tuneourmodelswithBatchNorm(BN)[
25
]
enabledwhen itisapplied.Thisisincontrasttocommon
practice[
21
]ofne-tuningResNets,where BNwasfrozen.
WehavefoundthatenablingBNinourapplicationreduces
overtting.
Weadoptthemethodin[
20
]toinitializetheweightlayers
introducedinthenon-localblocks.WeaddaBNlayerright
after thelast1

1

1layer thatrepresents
W
z
; wedonotadd
BNtootherlayersinanon-localblock.Thescaleparameter
ofthisBNlayerisinitializedaszero,following[
17
].This
ensuresthat theinitialstateoftheentirenon-localblockisan
identitymapping,soitcanbeinsertedintoanypre-trained
networkswhilemaintainingitsinitialbehavior.

Inference.
Following[
46
]weperformspatiallyfully-
convolutionalinferenceonvideoswhoseshorterside is
rescaledto 256. Forthetemporaldomain,inourpracticewe

sample10clipsevenlyfroma full-length videoandcompute

thesoftmaxscoresonthemindividually.Thenalprediction
istheaveragedsoftmaxscoresofallclips.

5.ExperimentsonVideoClassication
Weperformcomprehensivestudiesonthechallenging
Kineticsdataset[
27
].We alsoreportresultsontheCharades
dataset[
44
] toshowthegeneralityofourmodels.
5.1.ExperimentsonKinetics
Kinetics[
27
]contains
˘
246ktrainingvideosand20k
validationvideos.Itisaclassicationtaskinvolving 400
humanactioncategories.Wetrainallmodelsonthe training
setandtestonthevalidationset.
7798

model,R50
top-1 top-5
C2D baseline
71.8 89.7
Gaussian
72.5 90.2
Gaussian,embed
72.7
90.5
dot-product
72.9
90.3
concatenation
72.8
90.5
(a)
Instantiations
:1non-localblock
ofdifferenttypesis addedintotheC2D
baseline.AllentriesarewithResNet-
50.
model,R50
top-1top-5
baseline
71.889.7
res
2
72.790.3
res
3
72.9
90.4
res
4
72.7
90.5
res
5
72.390.1
(b)
Stages
:1non-localblockis
addedintodifferentstages.All
entriesarewithResNet-50.
model
top-1 top-5
R50
baseline
71.889.7
1-block
72.790.5
5-block
73.891.0
10-block
74.391.2
R101
baseline
73.191.0
1-block
74.391.3
5-block
75.191.7
10-block
75.1
91.6
(c)
Deepernon-localmodels
:we
compare1,5,and10non-localblocks
addedtotheC2D baseline.Weshow
ResNet-50(top)andResNet-101(bot-
tom) results.
model
top-1top-5
R50
baseline
71.8 89.7
space-only
72.9 90.8
time-only
73.1 90.5
spacetime
73.8 91.0
R101
baseline
73.1 91.0
space-only
74.4 91.3
time-only
74.4 90.5
spacetime
75.1 91.7
(d)
Space
vs
.time
vs
.spacetime
:we
comparenon-localoperationsapplied
alongspace,time,andspacetimedimen-
sionsrespectively.5non-localblocks
areused.
model,R101
params
FLOPs
top-1 top-5
C2D baseline
1

1

73.1 91.0
I3D
3
 
3
 
3
1.5

1.8

74.1 91.2
I3D
3
 
1
 
1
1.2

1.5

74.4 91.1
NLC2D,5-block
1.2

1.2

75.1 91.7
(e)
Non-local
vs
.3DConv
:A5-blocknon-localC2D
vs
.inated3DConvNet(I3D)[
7
].Allentriesarewith
ResNet-101.ThenumbersofparametersandFLOPsare
relative totheC2D baseline (43.2Mand34.2B).
model
top-1 top-5
R50
C2D baseline
71.8 89.7
I3D
73.3 90.7
NLI3D
74.9 91.6
R101
C2D baseline
73.1 91.0
I3D
74.4 91.1
NLI3D
76.0 92.1
(f)
Non-local3DConvNet
:5non-local
blocksareaddedontopof ourbestI3Dmod-
els.Theseresultsshowthatnon-localopera-
tionsarecomplementaryto3Dconvolutions.
model
top-1 top-5
R50
C2D baseline
73.8 91.2
I3D
74.9 91.7
NLI3D
76.5 92.6
R101
C2D baseline
75.3 91.8
I3D
76.4 92.7
NLI3D
77.7 93.3
(g)
Longerclips
:wene-tuneandtestthe
modelsinTable
2f
onthe128-frameclips.
Thegainsofournon-localoperationsarecon-
sistent.
Table2.
Ablations
onKineticsactionclassication.Weshowtop-1andtop-5classicationaccuracy(%).
050100150200250300350 400
iterations (K)
25
30
35
40
45
50
55
60
error (%)
C2D baseline (train)
C2D baseline (val)
NL C2D, 5-block (train)
NL C2D, 5-block (val)
Figure4.CurvesofthetrainingprocedureonKineticsforthe

ResNet-50C2Dbaseline(blue)
vs
.non-localC2Dwith5blocks
(red).Weshowthetop-1trainingerror(dash)andvalidationerror
(solid).Thevalidationerroriscomputedinthesamewayasthe
trainingerror(soitis1-cliptestingwiththesamerandomjittering
attrainingtime);thenalresultsareinTable
2c
(R50,5-block).
Figure
4
showsthecurvesofthetrainingprocedureofa
ResNet-50C2Dbaseline
vs
.anon-localC2Dwith5blocks
(moredetailsinthefollowing).Ournon-localC2Dmodel
isconsistentlybetter thantheC2Dbaseline
throughoutthe
trainingprocedure
,inbothtrainingandvalidationerror.
Figure
1
andFigure
3
visualizeseveralexamplesofthe
behaviorof anon-localblockcomputedbyourmodels.Our
networkcanlearntond meaningfulrelationalclues regard-
lessofthedistanceinspace andtime.
Table
2
showstheablationresults,analyzedasfollows:
Instantiations.
Table
2a
comparesdifferenttypesofasin-
glenon-localblockaddedtotheC2Dbaseline(rightbefore
thelastresidualblockofres
4
).Evenaddingonenon-local
blockcan leadto
˘
1%improvementoverthebaseline.
Interestingly,the embeddedGaussian,dot-product, and
concatenationversionsperformsimilarly,uptosomerandom
variations(72.7to72.9). AsdiscussedinSec.
3.2
,thenon-
localoperationswithGaussiankernelsbecomesimilartothe
self-attentionmodule[
49
].However,ourexperimentsshow
thattheattentional(softmax)behaviorofthismoduleis
not
thekeytotheimprovementinourapplications;instead,itis
morelikelythatthenon-localbehaviorisimportant,and it
isinsensitivetotheinstantiations.
Intherestofthispaper,weusetheembeddedGaussian
versionbydefault.Thisversioniseasier tovisualizeasits
softmaxscoresareintherangeof
[0
;
1]
.
Whichstagetoaddnon-localblocks?
Table
2b
compares
asinglenon-localblockaddedtodifferentstagesofResNet.
Theblockisaddedtorightbeforethelastresidualblockofa
stage.Theimprovementofanon-localblockonres
2
,res
3
,or
res
4
issimilar,andonres
5
isslightlysmaller.Onepossible
explanation is thatres
5
hasasmallspatialsize(7

7)andit
isinsufcienttoprovideprecisespatialinformation. More
evidenceofanon-localblockexploitingspatialinformation
willbeinvestigatedinTable
2d
.
7799

model
backbone
modality
top-1valtop-5val
top-1testtop-5test avgtest
y
I3Din[
7
]
Inception
RGB
72.190.3
71.189.380.2
2-StreamI3Din[
7
]
Inception
RGB+ow
75.792.0
74.291.382.8
RGBbaseline in[
3
]
Inception-ResNet-v2
RGB
73.090.9
---
3-streamlatefusion[
3
]
Inception-ResNet-v2
RGB+ow+audio
74.991.6
---
3-streamLSTM[
3
]
Inception-ResNet-v2
RGB+ow+audio
77.193.2
---
3-streamSATT[
3
]
Inception-ResNet-v2
RGB+ow+audio
77.793.2
---
NLI3D[ours]
ResNet-50
RGB
76.592.6
---
ResNet-101
RGB
77.793.3
--
83.8
Table3.Comparisonswithstate-of-the-artresultsin
Kinetics
,reportedonthevalandtestsets.WeincludetheKinetics 2017 competition
winner'sresults[
3
],buttheirbestresultsexploitedaudiosignals(markedin
gray
)sowerenotvision-onlysolutions.
y
:ﬁavgﬂistheaverage
oftop-1andtop-5accuracy;individualtop-1ortop-5 numbersarenotavailablefromthe testserveratthetimeof submittingthismanuscript.
Goingdeeperwithnon-localblocks.
Table
2c
showsthe
resultsofmorenon-localblocks.We add1block(tores
4
),5
blocks(3tores
4
and2tores
3
,toeveryotherresidualblock),
and10blocks(toeveryresidualblockinres
3
andres
4
)in
ResNet-50;inResNet-101weaddthemtothecorresponding
residualblocks.Table
2c
showsthatmorenon-localblocks
ingeneralleadtobetterresults.Wearguethatmultiple
non-localblockscanperformlong-rangemulti-hopcommu-
nication.Messagescanbedeliveredbackandforthbetween
distantpositionsinspacetime, whichishardtodovialocal
models.
Itisnoteworthythattheimprovementofnon-localblocks
is
not
justbecausetheyadddepthtothebaselinemodel.
To seethis,wenotethatinTable
2c
thenon-local 5-block
ResNet-50modelhas73.8 accuracy,higherthanthedeeper
ResNet-101baseline's73.1.However,the5-blockResNet-
50hasonly
˘
70%parametersand
˘
80%FLOPsofthe
ResNet-101baseline,andisalso
shallower
.Thiscompari-
sonshowsthattheimprovementduetonon-localblocksis
complementarytogoingdeeperinstandardways.
Wehavealsotriedtoaddstandardresidualblocks,instead
ofnon-localblocks,tothebaselinemodels.Theaccuracy
isnotincreased. Thisagainshowsthattheimprovementof
non-localblocksisnotjustbecausetheyadddepth.

Non-localinspacetime.
Ourmethodcannaturallyhandle
spacetimesignals.Thisisaniceproperty:related objects

inavideocanpresentatdistantspaceandlong-termtime
interval,andtheirdependencycanbecapturedbyourmodel.
In Table
2d
westudytheeffectof non-localblocksapplied
alongspace,time,orspacetime.Forexample,inthespace-
onlyversion,thenon-localdependencyonlyhappenswithin
thesameframe:
i.e
.,inEq.(
1
)itonlysumsovertheindex
j
inthesameframeoftheindex
i
.Thetime-onlyversioncan
besetupsimilarly.Table
2d
showsthatboththespace-only
andtime-onlyversionsimproveoverthe C2Dbaseline,but
areinferiortothespacetimeversion.

Non-localnet
vs
.3DConvNet.
Table
2e
comparesour non-
localC2Dversionwiththeinated3DConvNets.Non-local
operations and3Dconvolutionscanbeseenastwowaysof
extendingC2Dtothetemporaldimensions.
Table
2e
alsocomparesthenumberofparametersand
FLOPs,relativetothebaseline.Ournon-localC2Dmodel
ismoreaccuratethantheI3Dcounterpart(
e.g
.,75.1
vs
.
74.4),whilehavingasmallernumberofFLOPs(1.2

vs
.
1.5

).Thiscomparisonshowsthatourmethodcanbemore
effectivethan3Dconvolutionswhenusedalone.

Non-local3DConvNet.
Despitetheabovecomparison,
non-local operationsand3Dconvolutionscanmodeldif-
ferentaspectsoftheproblem:3Dconvolutionscancapture
local dependency.Table
2f
showstheresultsofinserting5
non-localblocksintotheI3D
3

1

1
models.Thesenon-local
I3D(NLI3D)modelsimproveovertheirI3Dcounterparts
(+1.6pointaccuracy),showing thatnon-localoperationsand
3Dconvolutionsarecomplementary.

Longersequences.
Finallyweinvestigatethegenerality
ofourmodelsonlongerinputvideos.Weuseinputclips
consistingof128consecutiveframeswithoutsubsampling.
Thesequencesthroughoutalllayersin thenetworksarethus
4

longercomparedtothe32-framecounterparts.Tot
thismodelintomemory,wereducethemini-batchsizeto2
clipsperGPU. As aresultofusingsmallmini-batches,we
freezeallBNlayersinthiscase.Weinitializethismodel
fromthecorrespondingmodelstrainedwith32-frameinputs.
Wene-tuneon128-frameinputsusingthesamenumberof
iterationsasthe32-framecase(thoughthemini-batchsizeis
nowsmaller),startingwithalearningrateof0.0025.Other
implementationdetailsarethesameasbefore.
Table
2g
showstheresultsof128-frameclips.Comparing
withthe32-framecounterpartsinTable
2f
,allmodelshave
betterresultsonlongerinputs.WealsondthatourNLI3D

canmaintainitsgainovertheI3Dcounterparts,showingthat
ourmodelsworkwellonlongersequences.

Comparisonswith state-of-the-artresults.
Table
3
shows
theresultsfromtheI3Dauthors[
7
]andfromtheKinetics
2017competitionwinner[
3
].Wenotethatthesearecompar-
isonsofsystemswhichcandifferinmanyaspects.Never-
theless,ourmethodsurpassesalltheexistingRGBorRGB+

owbasedmethodsbyagood margin.
Without using optical
ow andwithoutanybellsandwhistles
,ourmethodisonpar
withtheheavilyengineeredresultsofthe2017competition

winner.
7800

model
modality
train/val
trainval/test
2-Stream[
43
]
RGB+ow
18.6-
2-Stream+LSTM[
43
]
RGB+ow
17.8-
Asyn-TF[
43
]
RGB+ow
22.4-
I3D[
7
]
RGB
32.934.4
I3D[ours]
RGB
35.537.2
NLI3D[ours]
RGB
37.539.5
Table4.ClassicationmAP(%)inthe
Charades
dataset[
44
],on
the
train/val
splitandthe
trainval/test
split.Ourresultsarebased
onResNet-101.OurNLI3Duses5non-localblocks.

5.2.ExperimentsonCharades
Charades[
44
]isavideodatasetwith
˘
8ktraining,
˘
1.8k
validation,and
˘
2ktesting videos.Itisamulti-labelclassi-
cationtaskwith157actioncategories.Weuseaper-category
sigmoidoutputtohandlethemulti-labelproperty.
Weinitializeourmodelspre-trainedonKinetics(128-
frame).Themini-batchsizeissetto1clip perGPU.Wetrain
ourmodelsfor200kiterations,startingfromalearningrate
of0.00125andreducingitby 10every75kiterations.Weuse

ajitteringstrategysimilartothatinKineticstodeterminethe
locationofthe224

224croppingwindow,butwerescale
thevideosuchthatthiscroppingwindowoutputs288

288
pixels,on whichwene-tuneournetwork.We testona
singlescaleof320pixels.
Table
4
showsthecomparisonswiththepreviousresults
onCharades.Theresultof[
7
]isthe2017competition
winnerinCharades,whichwasalsone-tunedfrommodels
pre-trainedinKinetics.OurI3Dbaselineishigherthan
previousresults.Asacontrolled comparison,ournon-local
netimprovesoverourI3Dbaselineby2.3%onthetestset.

6.Extension:ExperimentsonCOCO
Wealsoinvestigateourmodelsonstaticimagerecog-
nition. WeexperimentontheMaskR-CNNbaseline[
19
]
for COCO[
33
]objectdetection/segmentationandhuman
poseestimation(keypointdetection).Themodelsaretrained
onCOCO
train2017
(
i.e
.,
trainval35k
in2014)and
testedon
val2017
(
i.e
.,
minival
in2014).
Objectdetectionandinstancesegmentation.
Wemodify
theMaskR-CNNbackbonebyaddingonenon-localblock
(rightbeforethelastresidualblockofres
4
).Allmodels
arene-tunedfromImageNetpre-training.Weevaluateon
astandardbaselineofResNet-50/101 andahighbaseline

ofResNeXt-152(X152)[
53
]. Unliketheoriginalpaper
[
19
]thatadoptedstage-wisetrainingregardingRPN,weuse
animprovedimplementationwithend-to-endjointtraining
similarto[
37
],whichleadstohigherbaselinesthan[
19
].
Table
5
showstheboxandmaskAPonCOCO. Wesee
thatasinglenon-localblockimprovesallR50/101andX152
baselines,onallmetricsinvolvingdetectionandsegmenta-
tion.AP
box
isincreasedby
˘
1point inallcases(
e.g
.,+1.3
pointinR101).Ournon-localblockis
complementary
to
increasingthemodelcapacity,evenwhenthemodelisup-
method
AP
box
AP
box

50
AP
box

75
AP
mask
AP
mask

50
AP
mask

75
R50
baseline
38.059.6 41.0
34.6 56.4 36.5
+1NL
39.061.1 41.9
35.5 58.0 37.4
R101
baseline
39.561.4 42.9
36.0 58.1 38.3
+1NL
40.863.1 44.5
37.1 59.9 39.2
X152
baseline
44.166.4 48.4
39.7 63.2 42.2
+1NL
45.067.8 48.9
40.3 64.4 42.8
Table 5.Adding1non-localblocktoMaskR-CNNforCOCO
objectdetection
and
instancesegmentation
.Thebackboneis
ResNet-50/101orResNeXt-152[
53
],bothwithFPN[
32
].
model
AP
kp
AP
kp

50
AP
kp

75
R101baseline
65.1 86.8 70.4
NL,+4inhead
66.0 87.1 71.7
NL,+4inhead,+1inbackbone
66.5 87.3 72.8
Table6.Addingnon-localblockstoMaskR-CNNforCOCO
keypointdetection
.ThebackboneisResNet-101withFPN[
32
].
gradedfromR50/101toX152.Thiscomparisonsuggests
that
non-localdependencyhasnotbeensufcientlycaptured
byexistingmodelsdespiteincreaseddepth/capacity
.
Inaddition,theabovegainisataverysmallcost.The
singlenon-localblockonlyadds
<
5% computationto the
baselinemodel.Wealsohavetriedtousemorenon-local
blockstothebackbone,butfounddiminishingreturn.

Keypointdetection.
Nextweevaluatenon-localblocksin
MaskR-CNNforkeypointdetection.In[
19
],MaskR-CNN
usedastackof8convolutionallayersforpredictingthe
keypointsas1-hotmasks.Theselayersarelocaloperations
andmayoverlookthedependencyamongkeypointsacross
longdistance.Motivatedby this,weinsert4 non-localblocks
intothekeypointhead(afterevery2convolutionallayers).
Table
6
showstheresultsonCOCO.Onastrongbaseline
ofR101,adding4 non-localblockstothekeypointhead

leadstoa
˘
1pointincreaseofkeypointAP.Ifweaddone
extranon-localblocktothebackboneasdoneforobject
detection,weobserveanintotal1.4pointsincreaseofkey-
pointAPoverthebaseline.Inparticular,weseethatthe
strictercriterionofAP
75
isboostedby2.4points,suggesting
astrongerlocalizationperformance.

7.Conclusion
Wepresentedanewclassofneuralnetworkswhichcap-
turelong-rangedependenciesvianon-localoperations.Our
non-localblockscanbecombinedwithanyexistingarchi-

tectures.Weshowthesignicanceofnon-localmodeling

forthetasksofvideoclassication,objectdetectionand

segmentation,andposeestimation.Onalltasks,asimple

additionofnon-localblocksprovidessolidimprovement

overbaselines.Wehopenon-locallayerswillbecomean
importantcomponent offuturenetworkarchitectures.
Acknowledgement
:ThisworkwaspartiallysupportedbyONRMURI
N000141612007,Sloan,OkawaFellowshiptoAGandNVIDIAFellowship
toXW. Wewould alsoliketothankHaoqiFan,DuTran,HengWang,
GeorgiaGkioxariandPiotrDollarformanyhelpfuldiscussions.
7801

References
[1]
C.Barnes,E. Shechtman,A. Finkelstein,andD.B.Goldman.
Patchmatch:Arandomizedcorrespondencealgorithmfor
structuralimageediting.In
Proceedings ofSIGGRAPH, ACM
TransactionsonGraphics
, 2009.
2
[2]
P.Battaglia, R.Pascanu,M.Lai,D.J.Rezende,etal.In-

teractionnetworksforlearningaboutobjects,relationsand
physics.In
NeuralInformationProcessingSystems(NIPS)
,
2016.
2
[3]
Y.Bian,C.Gan,X.Liu,F.Li,X.Long,Y.Li,H.Qi, J.Zhou,
S.Wen,andY.Lin. Revisitingtheeffectivenessofoff-the-

shelftemporalmodelingapproachesforlarge-scalevideo
classication.
arXiv:1708.03805
, 2017.
7
[4]
A.Buades,B.Coll,andJ.-M.Morel.Anon-localalgorithm
forimagedenoising.In
ComputerVisionandPatternRecog-
nition(CVPR)
, 2005.
1
,
2
,
3
[5]
H.C.Burger,C.J.Schuler,andS.Harmeling.Imagede-
noising:CanplainneuralnetworkscompetewithBM3D?In
ComputerVision andPatternRecognition(CVPR)
, 2012.
2
[6]
H.C.Burger,C.J.Schuler,andS.Harmeling.Imagedenois-
ingwithmulti-layerperceptrons,part2:trainingtrade-offs
andanalysisoftheirmechanisms.
arXiv:1211.1552
,2012.
2
[7]
J.CarreiraandA.Zisserman.Quovadis, actionrecognition?
anewmodelandthekineticsdataset.In
ComputerVisionand
PatternRecognition(CVPR)
, 2017.
1
,
2
,
4
,
6
,
7
,
8
[8]
S.Chandra,N.Usunier, andI.Kokkinos.Denseandlow-rank
GaussianCRFsusingdeepembeddings.In
International
ConferenceonComputerVision (ICCV)
, 2017.
2
[9]
L.-C.Chen,G.Papandreou,I.Kokkinos,K.Murphy,andA.L.
Yuille.Semanticimagesegmentationwithdeepconvolutional
netsandfullyconnectedCRFs.
arXiv:1412.7062
, 2014.
2
[10]
K.Dabov,A.Foi,V.Katkovnik,andK.Egiazarian.Im-
agedenoisingbysparse3-dtransform-domaincollaborative
ltering.
TransactionsonImageProcessing (TIP)
, 2007.
2
[11]
J.Donahue,L.AnneHendricks,S. Guadarrama,

M.Rohrbach, S.Venugopalan,K.Saenko,andT.Darrell.

Long-termrecurrentconvolutionalnetworksforvisual
recognitionanddescription.In
ComputerVisionandPattern
Recognition(CVPR)
, 2015.
2
[12]
A.A.EfrosandT. K.Leung.Texturesynthesisbynon-

parametricsampling.In
InternationalConferenceonCom-
puterVision (ICCV)
, 1999.
2
[13]
C.Feichtenhofer,A.Pinz,andR.Wildes.Spatiotemporal

residualnetworksforvideoactionrecognition.In
Neural
InformationProcessingSystems(NIPS)
, 2016.
2
,
4
[14]
K.FukushimaandS.Miyake. Neocognitron:Aself-
organizingneuralnetworkmodelfora mechanismofvisual
patternrecognition.In
Competitionandcooperationinneural
nets
. Springer, 1982.
1
[15]
J.Gehring,M.Auli,D.Grangier,D.Yarats,andY.N.

Dauphin.Convolutionalsequencetosequencelearning.In
InternationalConferenceonMachineLearning(ICML)
,2017.
2
[16]
D.Glasner,S.Bagon,andM.Irani.Super-resolutionfroma
singleimage.In
ComputerVisionandPatternRecognition
(CVPR)
, 2009.
2
[17]
P.Goyal,P.Doll
´
ar, R.Girshick,P.Noordhuis, L.Wesolowski,
A.Kyrola,A.Tulloch,Y.Jia,andK.He.Accurate,largemini-
batchsgd:Trainingimagenetin1hour.
arXiv:1706.02677
,
2017.
5
[18]
A.Harley,K.Derpanis,andI.Kokkinos.Segmentation-
awareconvolutionalnetworksusinglocalattentionmasks.In
InternationalConferenceonComputerVision(ICCV)
,2017.
2
[19]
K.He,G.Gkioxari,P.Doll
´
ar,andR.Girshick.MaskR-CNN.
In
InternationalConferenceonComputerVision(ICCV)
,
2017.
2
,
8
[20]
K.He,X.Zhang,S.Ren,andJ.Sun.Delvingdeepinto
rectiers:Surpassinghuman-levelperformanceonimagenet
classication. In
InternationalConferenceonComputerVi-
sion(ICCV)
, 2015.
5
[21]
K.He,X.Zhang, S.Ren,andJ.Sun.Deepresiduallearn-

ingfor imagerecognition.In
ComputerVisionand Pattern
Recognition(CVPR)
, 2016.
1
,
4
,
5
[22]
G.E.Hinton,N.Srivastava,A.Krizhevsky, I.Sutskever, and
R.R.Salakhutdinov. Improvingneuralnetworksbyprevent-
ingco-adaptationoffeaturedetectors.
arXiv:1207.0580
,2012.
5
[23]
S.HochreiterandJ.Schmidhuber.Long short-termmemory.
Neuralcomputation
, 1997.
1
[24]
Y.Hoshen.Multi-agentpredictive modelingwithattentional
commnets.In
NeuralInformationProcessingSystems(NIPS)
,
2017.
2
[25]
S.IoffeandC.Szegedy.Batchnormalization:Accelerating
deepnetworktrainingbyreducinginternalcovariateshift.

InInternationalConferenceonMachineLearning(ICML)
,
2015.
5
[26]
S.Ji, W.Xu,M.Yang, andK.Yu.3dconvolutionalneural

networksforhumanactionrecognition.In
International
ConferenceonMachineLearning(ICML)
, 2010.
2
[27]
W.Kay,J.Carreira,K.Simonyan,B.Zhang,C.Hillier,S.Vi-
jayanarasimhan,F.Viola,T.Green, T.Back,P.Natsev,etal.
Thekineticshumanactionvideodataset.
arXiv:1705.06950
,
2017.
1
,
5
[28]
P.Kr
¨
ahenb
¨
uhlandV.Koltun.Efcientinferenceinfully
connectedcrfswithgaussianedgepotentials.In
NeuralInfor-
mationProcessing Systems(NIPS)
, 2011.
2
[29]
J.Lafferty,A.McCallum,andF.C.Pereira.Conditional
randomelds:Probabilisticmodelsforsegmentingandlabel-
ingsequencedata.In
InternationalConferenceonMachine
Learning(ICML)
, 2001.
2
[30]
Y.LeCun,B.Boser,J.S.Denker,D.Henderson,R.E.

Howard,W.Hubbard, andL.D.Jackel.Backpropagation
appliedtohandwrittenzipcoderecognition.
Neuralcomputa-
tion
, 1989.
1
[31]
S.Lefkimmiatis.Non-localcolor imagedenoisingwith
convolutionalneuralnetworks.In
ComputerVisionandPat-
ternRecognition(CVPR)
, 2017.
2
[32]
T.-Y.Lin,P.Doll
´
ar,R.Girshick,K.He,B.Hariharan,and
S.Belongie.Featurepyramidnetworksforobjectdetection.
In
ComputerVisionandPatternRecognition(CVPR)
,2017.
8
7802

[33]
T.-Y.Lin,M.Maire,S.Belongie,J.Hays,P.Perona,D.Ra-
manan,P.Doll
´
ar,andC.L.Zitnick.MicrosoftCOCO:Com-
monobjectsincontext.In
European ConferenceonComputer
Vision (ECCV)
. 2014.
2
,
8
[34]
S.Liu,S.DeMello,J.Gu,G.Zhong,M.-H.Yang,and
J.Kautz.Learningafnityviaspatialpropagationnetworks.
In
NeuralInformationProcessingSystems(NIPS)
, 2017.
2
[35]
V.NairandG.E.Hinton.Rectiedlinearunitsimprove
restrictedboltzmannmachines.In
International Conference
onMachineLearning(ICML)
, 2010.
3
[36]
A.Oord, S.Dieleman, H.Zen,K.Simonyan,

O.Vinyals,A.Graves,N.Kalchbrenner,A.Senior,
andK.Kavukcuoglu.Wavenet:Agenerativemodelforraw
audio.
arXiv:1609.03499
, 2016.
2
[37]
S.Ren,K.He,R.Girshick, andJ.Sun.FasterR-CNN:
Towardsreal-timeobjectdetectionwithregionproposalnet-
works.
TransactionsonPatternAnalysisandMachineIntelli-
gence(TPAMI)
, 2017.
8
[38]
D.E.Rumelhart,G.E.Hinton,andR.J.Williams.Learning
representationsbyback-propagatingerrors.
Nature
, 1986.
1
[39]
O.Russakovsky,J.Deng,H.Su,J.Krause,S.Satheesh,S.Ma,
Z.Huang,A.Karpathy,A.Khosla,M.Bernstein,A.C.Berg,
andL.Fei-Fei.ImageNetLargeScaleVisual Recognition
Challenge.
InternationalJournalofComputerVision(IJCV)
,
2015.
5
[40]
A.Santoro,D.Raposo,D.G.Barrett,M.Malinowski,R.Pas-
canu,P.Battaglia,andT.Lillicrap.Asimpleneuralnetwork
moduleforrelationalreasoning.In
NeuralInformationPro-
cessingSystems(NIPS)
, 2017.
2
,
3
[41]
F.Scarselli,M.Gori,A.C.Tsoi, M.Hagenbuchner,and

G.Monfardini.Thegraphneuralnetworkmodel.
IEEE
TransactionsonNeuralNetworks
, 2009.
2
[42]
A.G.Schwing andR.Urtasun.Fullyconnecteddeepstruc-
turednetworks.
arXivpreprintarXiv:1503.02351
, 2015.
2
[43]
G. A. Sigurdsson,S.Divvala,A.Farhadi,andA. Gupta.Asyn-
chronoustemporaleldsforactionrecognition.In
Computer
Vision andPatternRecognition(CVPR)
, 2017.
8
[44]
G.A.Sigurdsson,G.Varol,X.Wang,A.Farhadi,I.Laptev,
andA.Gupta.Hollywoodinhomes:Crowdsourcingdata
collectionfor activity understanding.In
European Conference
onComputerVision (ECCV)
, 2016.
1
,
5
,
8
[45]
K.SimonyanandA.Zisserman.Two-stream convolutional
networksforactionrecognitioninvideos.In
NeuralInforma-
tionProcessingSystems(NIPS)
, 2014.
2
[46]
K. SimonyanandA.Zisserman.Very deepconvolutional
networksforlarge-scaleimagerecognition.In
International
ConferenceonLearningRepresentations(ICLR)
, 2015.
5
[47]
C.TomasiandR.Manduchi.Bilaterallteringforgrayand
colorimages.In
InternationalConferenceonComputerVi-
sion(ICCV)
, 1998.
3
[48]
D.Tran,L.Bourdev,R.Fergus,L.Torresani,andM.Paluri.
Learningspatiotemporalfeatureswith3dconvolutionalnet-
works.In
InternationalConferenceonComputerVision
(ICCV)
, 2015.
1
,
2
,
4
[49]
A.Vaswani,N.Shazeer,N.Parmar,J.Uszkoreit,L.Jones,
A.N.Gomez,L.Kaiser,andI.Polosukhin.Attentionisall
youneed.In
NeuralInformationProcessingSystems(NIPS)
,
2017.
2
,
3
,
6
[50]
H.WangandC.Schmid.Actionrecognitionwithimproved
trajectories.In
InternationalConferenceonComputerVision
(ICCV)
, 2013.
2
[51]
L.Wang, Y.Qiao,andX.Tang.Actionrecognitionwith

trajectory-pooleddeep-convolutionaldescriptors.In
Com-
puterVision andPatternRecognition(CVPR)
, 2015.
2
[52]
N. Watters,A. Tacchetti,T.Weber,R.Pascanu,P.Battaglia,
andD.Zoran.Visualinteractionnetworks.In
NeuralInfor-
mationProcessing Systems(NIPS)
, 2017.
2
[53]
S.Xie,R.Girshick,P.Doll
´
ar,Z.Tu,andK.He.Aggre-
gatedresidualtransformationsfordeepneuralnetworks.In
ComputerVision andPatternRecognition(CVPR)
, 2017.
8
[54]
W.Xiong,J.Droppo,X.Huang,F.Seide,M.Seltzer,A.Stol-
cke,D.Yu,andG.Zweig.TheMicrosoft2016Conversational
SpeechRecognitionSystem.In
InternationalConferenceon
Acoustics,Speech,andSignalProcessing(ICASSP)
,2017.
2
[55]
J.Yue-HeiNg,M.Hausknecht,S.Vijayanarasimhan,

O.Vinyals,R.Monga,andG.Toderici. Beyondshortsnip-

pets:Deepnetworksforvideoclassication.In
Computer
Vision andPatternRecognition(CVPR)
, 2015.
2
[56]
S.Zheng,S.Jayasumana,B.Romera-Paredes,V.Vineet,

Z.Su,D.Du,C.Huang,andP.H.Torr.Conditionalran-

domeldsas recurrentneuralnetworks.In
International
ConferenceonComputerVision (ICCV)
, 2015.
2
7803

