FocalLossforDenseObjectDetection
Tsung-YiLinPriyaGoyalRossGirshickKaimingHePiotrDoll
Â´
ar
FacebookAIResearch(FAIR)
ËœËœËšË›ËœËšËËœËšË™ËœËšË†Ë‡
Ëœ
Ë‡
Ë›

Ë

Ëœ
ËœËš
Ë‡
Ë›

well-classiËœed
examples
well-classiËœed
examples
CE
(
p
t
)=

log(
p
t
)
FL
(
p
t
)=

(1

p
t
)

log(
p
t
)
Figure1.Weproposeanovelloss wetermthe
FocalLoss
that
addsafactor
(1

p
t
)

tothestandardcrossentropycriterion.
Setting
>
0
reducestherelativelossforwell-classiedexamples
(
p
t
>:
5
),puttingmorefocusonhard,misclassiedexamples.As
ourexperimentswilldemonstrate, theproposedfocallossenables

traininghighlyaccuratedenseobjectdetectorsinthe presenceof

vastnumbers ofeasybackgroundexamples.
Abstract
Thehighestaccuracyobjectdetectorstodate arebased
onatwo-stageapproachpopularizedbyR-CNN,wherea

classierisappliedtoa
sparse
setofcandidateobjectlo-
cations.Incontrast,one-stagedetectorsthatareapplied

overaregular,
dense
samplingof possibleobjectlocations
havethepotentialtobefasterand simpler,buthavetrailed

theaccuracyoftwo-stagedetectorsthusfar.Inthispaper,

weinvestigatewhythisisthecase.Wediscover thattheex-

tremeforeground-backgroundclassimbalanceencountered

duringtrainingofdensedetectorsisthecentralcause.We

propose toaddressthisclassimbalancebyreshapingthe

standardcrossentropylosssuchthatitdown-weightsthe

lossassignedtowell-classiedexamples.Ournovel
Focal
Loss
focusestrainingonasparsesetofhardexamplesand
preventsthevastnumberofeasynegativesfromoverwhelm-

ingthedetectorduringtraining.Toevaluatetheeffective-

nessofourloss,wedesignandtrainasimpledensedetector

wecallRetinaNet.Ourresultsshowthatwhentrainedwith

thefocalloss,RetinaNetisabletomatchthespeedofpre-

viousone-stagedetectorswhilesurpassingtheaccuracyof

allexistingstate-of-the-arttwo-stagedetectors.
50100150200250
inference time (ms)
28
30
32
34
36
38
COCO AP
BC
D
E
F
G
RetinaNet-50
RetinaNet-101
APtime
[A]
YOLOv2
y
[
26
]
21.625
[B]
SSD321[
21
]
28.061
[C]
DSSD321[
9
]
28.085
[D]
R-FCN
z
[
3
]
29.985
[E]
SSD513[
21
]
31.2125
[F]
DSSD513[
9
]
33.2156
[G]
FPN FRCN[
19
]
36.2172
RetinaNet-50-500
32.573
RetinaNet-101-500
34.490
RetinaNet-101-800
37.8198
y
Notplotted
z
Extrapolatedtime
Figure2. Speed(ms)versusaccuracy(AP)onCOCO
test-dev
.
Enabledby thefocal loss,oursimpleone-stage
RetinaNet
detec-
toroutperformsallpreviousone-stageandtwo-stagedetectors,in-

cludingthebest reportedFasterR-CNN [
27
]systemfrom[
19
].We
showvariantsofRetinaNetwithResNet-50-FPN(bluecircles)and

ResNet-101-FPN(orangediamonds)atvescales(400-800pix-

els).Ignoringthelow-accuracyregime(AP
<
25),RetinaNetforms
anupperenvelope ofallcurrentdetectors,andavarianttrainedfor

longer(notshown)achieves39.1 AP. Detailsaregiven in
x
5
.
1.Introduction
Currentstate-of-the-artobjectdetectorsarebasedon
atwo-stage,proposal-drivenmechanism.Aspopularized

intheR-CNNframework[
11
],therststagegeneratesa
sparse
setofcandidateobjectlocationsandthesecondstage
classieseachcandidatelocationasoneoftheforeground

classesorasbackgroundusingaconvolutionalneuralnet-

work.Throughasequenceofadvances[
10
,
27
,
19
,
13
],this
two-stageframeworkconsistentlyachievestopaccuracyon

thechallengingCOCObenchmark[
20
].
Despitethesuccessoftwo-stagedetectors,anatural
questiontoaskis:couldasimpleone-stagedetectorachieve

similaraccuracy?Onestagedetectorsareappliedovera

regular,
dense
samplingofobjectlocations,scales,andas-
pectratios. Recentworkonone-stagedetectors,suchas

YOLO[
25
,
26
]andSSD[
21
,
9
],demonstratespromising
results,yieldingfasterdetectorswithaccuracywithin10-

40%relativetostate-of-the-arttwo-stagemethods.
Thispaperpushestheenvelopfurther:wepresentaone-
stage objectdetectorthat,forthersttime,matchesthe
1
2980

state-of-the-artCOCOAPofmorecomplextwo-stagede-

tectors,suchastheFeaturePyramidNetwork(FPN)[
19
]
orMaskR-CNN[
13
]variantsof FasterR-CNN[
27
].To
achievethisresult,weidentifyclassimbalanceduring train-

ingasthemainobstacleimpedingone-stagedetectorfrom

achievingstate-of-the-artaccuracyandproposeanewloss

functionthateliminatesthisbarrier.
Classimbalanceis addressedinR-CNN-likedetectors
byatwo-stagecascadeandsampling heuristics.Thepro-

posalstage(
e.g
.,SelectiveSearch[
34
],EdgeBoxes[
37
],
DeepMask[
23
,
24
],RPN[
27
])rapidlynarrowsdownthe
numberofcandidateobjectlocationstoasmallnumber

(e.g
.,1-2k),lteringoutmostbackgroundsamples.Inthe
secondclassicationstage,samplingheuristics, suchasa

xedforeground-to-backgroundratio(1:3),oronlinehard

examplemining(OHEM)[
30
],areperformedtomaintaina
manageablebalancebetweenforegroundandbackground.
Incontrast,aone-stagedetectormustprocessamuch
largersetofcandidateobjectlocations regularlysampled

acrossanimage.Inpracticethisoftenamountsto enumer-

atingË˜
100klocationsthatdenselycoverspatialpositions,
scales,andaspectratios. While similarsamplingheuris-

ticsmay alsobeapplied,theyareinefcientasthetraining

procedureisstilldominatedbyeasilyclassiedbackground

examples.Thisinefciencyisaclassicprobleminobject

detectionthatistypicallyaddressedviatechniquessuchas

bootstrapping[
32
,
28
]orhardexamplemining[
36
,
8
,
30
].
Inthispaper,weproposeanew lossfunctionthatacts
asamoreeffectivealternativetopreviousapproachesfor

dealingwithclassimbalance.Thelossfunctionisady-

namicallyscaledcrossentropyloss,wherethe scalingfactor

decaystozeroascondenceinthecorrectclassincreases,

seeFigure
1
. Intuitively,thisscaling factorcanautomati-
callydown-weightthecontributionofeasyexamplesduring

trainingandrapidlyfocusthemodelonhardexamples.Ex-

perimentsshowthatourproposed
FocalLoss
enablesusto
trainahigh-accuracy,one-stagedetectorthatsignicantly

outperformsthealternativesoftrainingwiththesampling

heuristicsorhardexamplemining, thepreviousstate-of-

the-arttechniquesfortrainingone-stage detectors.Finally,

wenotethattheexactformofthefocallossisnotcrucial,

and weshowotherinstantiationscanachievesimilarresults.
Todemonstratetheeffectivenessoftheproposedfocal
loss,wedesignasimple one-stageobjectdetectorcalled

RetinaNet,namedforits densesamplingofobjectlocations
inaninputimage.Itsdesignfeaturesanefcientin-network

featurepyramidanduseofanchorboxes.Itdrawsona va-

rietyofrecentideasfrom[
21
,
6
,
27
,
19
].RetinaNetisef-
cientandaccurate;ourbestmodel,basedonaResNet-101-

FPNbackbone,achievesaCOCO
test-dev
AP of39.1
whilerunning at5fps,surpassingthepreviouslybestpub-

lishedsingle-modelresultsfrombothoneandtwo-stagede-

tectors,see Figure
2
.
2.RelatedWork

ClassicObjectDetectors:
Thesliding-windowparadigm,
inwhichaclassierisappliedonadenseimagegrid,has

alongandrichhistory.Oneoftheearliestsuccessesisthe

classicworkofLeCun
etal
. whoappliedconvolutionalneu-
ralnetworkstohandwrittendigitrecognition[
18
,
35
].Vi-
olaandJones [
36
] usedboostedobjectdetectorsforface
detection,leadingtowidespreadadoptionofsuchmodels.

TheintroductionofHOG [
4
]andintegralchannel features
[
5
]gaverisetoeffectivemethodsforpedestriandetection.
DPMs[
8
]helped extenddensedetectorstomoregeneral
object categoriesandhadtopresultsonPASCAL[
7
]for
manyyears.Whilethesliding-windowapproachwasthe

leading detectionparadigminclassiccomputervision, with

theresurgenceofdeeplearning[
17
],two-stagedetectors,
describednext,quicklycametodominateobjectdetection.

Two-stageDetectors:
Thedominantparadigminmodern
objectdetectionisbasedonatwo-stageapproach.Aspio-

neeredintheSelectiveSearchwork[
34
],therststagegen-
eratesasparse setofcandidateproposalsthatshouldcon-

tainallobjectswhilelteringoutthemajorityofnegative

locations,andthesecondstageclassiestheproposalsinto

foregroundclasses/background.R-CNN[
11
]upgradedthe
second-stageclassiertoaconvolutionalnetworkyielding

largegainsinaccuracyandusheringinthemoderneraof

objectdetection.R-CNNwasimprovedovertheyears,both

in termsofspeed[
14
,
10
]andbyusinglearnedobjectpro-
posals[
6
,
23
,
27
]. RegionProposalNetworks(RPN)inte-
gratedproposalgenerationwiththesecond-stageclassier

intoasingleconvolutionnetwork,formingtheFasterR-

CNNframework[
27
].Numerousextensionstothisframe-
workhavebeenproposed,
e.g
.[
19
,
30
,
31
,
15
,
13
].
One-stageDetectors:
OverFeat[
29
]wasoneoftherst
modernone-stageobjectdetector basedon deepnetworks.

MorerecentlySSD [
21
,
9
]andYOLO[
25
,
26
]havere-
newedinterestin one-stagemethods.Thesedetectorshave

beentunedforspeedbuttheiraccuracytrailsthatoftwo-

stagemethods.SSDhasa10-20%lowerAP,whileYOLO

focusesonanevenmoreextremespeed/accuracytrade-off.

SeeFigure
2
.Recentworkshowedthattwo-stagedetectors
canbemadefastsimplybyreducinginputimageresolution

andthenumberofproposals,butone-stagemethodstrailed

inaccuracyevenwithalargercomputebudget[
16
].Incon-
trast,theaimofthisworkistounderstandifone-stagede-

tectorscanmatchorsurpassthe accuracyoftwo-stage de-

tectorswhilerunningatsimilarorfasterspeeds.
ThedesignofourRetinaNetdetectorsharesmanysimi-
laritieswithpreviousdensedetectors,inparticularthecon-

cept of`anchors' introducedbyRPN[
27
]anduseoffea-
turespyramidsasinSSD[
21
]andFPN[
19
].Weempha-
sizethatoursimpledetectorachievestopresultsnotbased

oninnovationsinnetworkdesignbutduetoournovelloss.
2
2981

Class Imbalance:
Bothclassicone-stageobjectdetection
methods,likeboosteddetectors[
36
,
5
]andDPMs[
8
],and
morerecentmethods,likeSSD[
21
],facealargeclass
imbalanceduringtraining.Thesedetectors evaluate
10
4
-
10
5
candidatelocationsperimagebutonly afewloca-
tionscontainobjects.Thisimbalancecausestwoproblems:

(1)trainingisinefcientasmostlocationsareeasynega-

tivesthatcontributenousefullearningsignal;(2)enmasse,

theeasynegativescanoverwhelmtrainingandleadtode-

generatemodels.A commonsolutionistoperformsome

formofhardnegativemining[
32
,
36
,
8
,
30
,
21
]thatsam-
pleshardexamplesduring trainingormorecomplex sam-

pling/reweighingschemes[
2
].Incontrast,weshowthatour
proposedfocallossnaturallyhandlestheclassimbalance

facedbyaone-stagedetectorandallowsustoefciently

trainonallexampleswithoutsamplingandwithouteasy

negativesoverwhelmingthelossandcomputedgradients.

RobustEstimation:
Therehasbeen muchinterestinde-
signingrobustlossfunctions(
e.g
.,Huberloss[
12
])that re-
ducethecontributionof
outliers
bydown-weightingtheloss
ofexampleswithlargeerrors(hardexamples).Incontrast,

ratherthanaddressingoutliers,ourfocallossisdesigned

toaddressclassimbalancebydown-weighting
inliers
(easy
examples)such thattheir contributionto thetotallossis

smalleveniftheirnumberislarge.Inotherwords,thefocal

lossperformsthe
opposite
roleofarobustloss:itfocuses
trainingonasparsesetofhardexamples.

3.FocalLoss
The
Focal Loss
isdesignedto addresstheone-stage ob-
jectdetectionscenario inwhichthereisanextremeim-

balancebetweenforegroundandbackgroundclassesduring

training(
e.g
.,1:1000).Weintroducethefocallossstarting
fromthecrossentropy(CE)lossforbinaryclassication
1
:
CE
(
p;y
)=
(

log(
p
)
if
y
=1

log(1

p
)
otherwise.
(1)
Intheabove
y
2f
1
g
speciestheground-truthclassand
p
2
[0
;
1]
isthemodel'sestimated probabilityfortheclass
withlabel
y
=1
.Fornotationalconvenience,we dene
p
t
:
p
t
=
(
p
if
y
=1
1

p
otherwise,
(2)
andrewriteCE
(
p;y
)=
CE
(
p
t
)=

log(
p
t
)
.
TheCElosscanbeseenastheblue(top)curveinFig-
ure
1
.Onenotablepropertyofthisloss,whichcanbeeasily
seen initsplot,isthatevenexamplesthatareeasilyclas-

sied(
p
t
Ë›
:
5
)incuralosswithnon-trivialmagnitude.
Whensummedoveralarge numberofeasyexamples,these

smalllossvaluescanoverwhelmtherareclass.
1
Extendingthefocallosstothemulti-classcaseisstraightforwardand
workswell;forsimplicitywefocusonthebinarylossinthiswork.
3.1.BalancedCrossEntropy
Acommonmethod foraddressing class imbalanceisto
introduceaweightingfactor

2
[0
;
1]
forclass
1
and
1


forclass

1
.Inpractice

maybesetbyinverseclassfre-
quency ortreatedasahyperparameter tosetbycrossvalida-

tion.Fornotationalconvenience,wedene

t
analogously
tohowwe dened
p
t
.Wewritethe

-balancedCElossas:
CE
(
p
t
)=


t
log(
p
t
)
:
(3)
ThislossisasimpleextensiontoCEthatweconsiderasan

experimentalbaselineforourproposedfocalloss.

3.2.Focal LossDenition
Asourexperimentswillshow,thelargeclassimbalance
encounteredduringtrainingofdensedetectorsoverwhelms

thecrossentropyloss.Easilyclassiednegativescomprise

themajorityofthelossand dominatethegradient.While


balancestheimportanceofpositive/negativeexamples,it
doesnotdifferentiatebetweeneasy/hardexamples.Instead,

weproposetoreshapethelossfunctiontodown-weight

easyexamplesandthusfocustrainingonhardnegatives.
Moreformally,wepropose toaddamodulatingfactor
(1

p
t
)

tothecrossentropyloss,withtunable
focusing
parameter


0
.Wedenethefocallossas:
FL
(
p
t
)=

(1

p
t
)

log(
p
t
)
:
(4)
Thefocallossisvisualizedforseveralvaluesof

2
[0
;
5]
inFigure
1
.Wenotetwopropertiesofthefocalloss.
(1)Whenan exampleismisclassiedand
p
t
issmall,the
modulatingfactorisnear
1
and thelossisunaffected.As
p
t
!
1
,thefactorgoes to0andthelossforwell-classied
examplesis down-weighted. (2)Thefocusingparameter

smoothlyadjuststherateatwhicheasyexamplesaredown-

weighted.When

=0
,FLisequivalenttoCE,andas

is
increasedtheeffectofthemodulatingfactorislikewisein-

creased(wefound

=2
toworkbestinourexperiments).
Intuitively,themodulatingfactorreducesthelosscontri-
butionfromeasyexamplesandextendstherangeinwhich

anexamplereceiveslowloss.Forinstance,with

=2
,an
exampleclassiedwith
p
t
=0
:
9
wouldhave
100

lower
losscomparedwithCEandwith
p
t
Ë‡
0
:
968
itwouldhave
1000

lowerloss.Thisinturn increasestheimportance
ofcorrectingmisclassiedexamples(whoselossisscaled

downbyatmost
4

for
p
t

:
5
and

=2
).
Inpracticeweuse an

-balancedvariantofthefocalloss:
FL
(
p
t
)=


t
(1

p
t
)

log(
p
t
)
:
(5)
Weadoptthisforminourexperimentsasityieldsslightly

improvedaccuracyoverthenon-

-balancedform.Finally,
wenotethattheimplementationofthelosslayercombines

thesigmoidoperationforcomputing
p
with theloss com-
putation,resultingingreaternumericalstability.
3
2982

Whileinourmainexperimentalresultsweusethefocal
lossdenitionabove,itspreciseformisnotcrucial.Inthe

onlineappendixweconsiderotherinstantiationsofthe focal

lossanddemonstratethatthesecanbeequallyeffective.

3.3.ClassImbalanceand ModelInitialization
Binaryclassicationmodelsarebydefaultinitializedto
haveequalprobabilityofoutputtingeither
y
=

1
or
1
.
Undersuchaninitialization,inthepresenceofclassimbal-

ance,theloss duetothefrequentclasscandominatetotal

lossandcauseinstabilityin earlytraining. Tocounterthis,

weintroducetheconceptofa`prior'forthevalueof
p
es-
timatedbythemodelfortherareclass(foreground)
atthe
startoftraining
.Wedenotethepriorby
Ë‡
andsetitsothat
themodel's estimated
p
forexamplesoftherareclassislow,
e.g
.
0
:
01
.Wenotethatthisisachangeinmodelinitializa-
tion(see
x
4.1
)and
not
ofthe lossfunction.Wefoundthis
toimprovetraining stabilityforboththecrossentropyand

focallossinthecaseofheavyclassimbalance.

3.4.ClassImbalanceand Tw Detectors
Two-stagedetectorsareoften trainedwiththecross en-
tropylosswithoutuseof

-balancingorourproposedloss.
Instead,theyaddressclassimbalancethroughtwomech-

anisms:(1)atwo-stagecascadeand(2)biasedminibatch

sampling.The rstcascadestageisanobjectproposal

mechanism[
34
,
23
,
27
]thatreducesthe nearlyinniteset
ofpossibleobjectlocationsdowntoone ortwothousand.

Importantly,theselectedproposalsarenotrandom,but are

likelytocorrespondtotrueobjectlocations,whichremoves

thevastmajorityofeasynegatives.Whentrainingthesec-

ondstage,biasedsamplingistypicallyusedtoconstruct

minibatchesthatcontain,forinstance,a1:3ratioofposi-

tivetonegativeexamples.Thisratioislikeanimplicit

-
balancingfactorthatisimplementedviasampling.Ourpro-

posedfocallossisdesignedtoaddressthesemechanismsin

aone-stagedetectionsystemdirectlyviathelossfunction.

4.RetinaNetDetector
RetinaNet isasingle,uniednetworkcomposed ofa
backbone
networkandtwotask-specic
subnetworks
.The
backboneisresponsibleforcomputingaconvolutionalfea-

turemapoveranentireinputimageandisanoff-the-self

convolutionalnetwork.Therstsubnetperformsconvo-

lutionalobjectclassicationonthebackbone'soutput; the

secondsubnetperformsconvolutional boundingboxregres-

sion.Thetwosubnetworksfeatureasimpledesignthatwe

proposespecicallyforone-stage,densedetection, seeFig-

ure3
.Whiletherearemanypossible choicesfor thedetails
ofthesecomponents,mostdesign parametersarenotpartic-

ularlysensitivetoexactvaluesasshownintheexperiments.

WedescribeeachcomponentofRetinaNetnext.
FeaturePyramidNetworkBackbone:
Weadopt theFea-
turePyramidNetwork(FPN)from [
19
]asthebackbone
networkforRetinaNet. Inbrief,FPNaugmentsastan-

dardconvolutionalnetworkwithatop-downpathwayand

lateralconnections sothenetworkefcientlyconstructsa

rich,multi-scale featurepyramidfromasingleresolution

inputimage,seeFigure
3
(a)-(b).Eachlevelofthepyramid
canbeusedfordetectingobjectsatadifferentscale.FPN

improvesmulti-scalepredictionsfromfullyconvolutional

networks(FCN)[
22
],asshownbyitsgainsforRPN[
27
]
andDeepMask-styleproposals[
23
],aswellattwo-stage
detectorssuchasFastR-CNN[
10
]orMaskR-CNN[
13
].
Following[
19
],webuildFPNontopoftheResNetar-
chitecture[
15
].Weconstruct apyramidwith levels
P
3
through
P
7
,where
l
indicatespyramidlevel(
P
l
hasreso-
lution
2
l
lowerthantheinput).Asin[
19
]allpyramidlevels
have
C
=256
channels. Detailsofthepyramidgenerally
follow[
19
]withafewmodestdifferences.
2
Whilemany
designchoicesarenotcrucial,weemphasizetheuseofthe

FPNbackboneis;preliminaryexperimentsusingfeatures

fromonlythenalResNetlayeryieldedlowAP.

Anchors:Weusetranslation-invariantanchorboxessimi-
lartothoseintheRPNvariantin[
19
].Theanchorshave
areasof
32
2
to
512
2
onpyramidlevels
P
3
to
P
7
,respec-
tively.Asin[
19
],ateachpyramidlevelweuseanchors at
threeaspectratios
f
1
:
2
;
1
:
1
,
2
:
1
g
.Fordenserscalecover-
agethan in[
19
],ateach levelweaddanchorsofsizes
f
2
0
,
2
1
=
3
,
2
2
=
3
g
oftheoriginalsetof3aspectratioanchors.This
improveAPinoursetting.Intotalthereare
A
=9
anchors
perleveland acrosslevelstheycoverthescalerange32-

813pixelswithrespecttothenetwork'sinputimage.
Eachanchorisassigneda length
K
one-hotvectorof
classicationtargets,where
K
isthenumberofobject
classes, anda4-vector of boxregressiontargets.Weuse

theassignmentrulefromRPN[
27
]butmodiedformulti-
classdetectionandwith adjustedthresholds.Specically,

anchorsareassignedto ground-truthobjectboxesusingan

intersection-over-union(IoU) thresholdof 0.5;andtoback-

groundiftheirIoUisin[0,0.4).Aseachanchorisassigned

toatmostoneobjectbox,wesetthecorrespondingentry

initslength
K
labelvectorto
1
and allotherentriesto
0
.
Ifananchorisunassigned,whichmayhappenwithoverlap

in[0.4,0.5),itisignoredduringtraining.Boxregression

targetsarecomputedastheoffsetbetweeneachanchorand

itsassignedobjectbox,oromittedifthereisnoassignment.
2
RetinaNet usesfeature pyramid levels
P
3
to
P
7
,where
P
3
to
P
5
are
computedfromtheoutputofthecorrespondingResNetresidualstage(
C
3
through
C
5
)usingtop-downandlateralconnectionsjustasin[
19
],
P
6
is
obtainedviaa3

3stride-2convon
C
5
,and
P
7
iscomputedbyapply-
ingReLUfollowedbya3

3stride-2convon
P
6
.Thisdiffersslightly
from[
19
]:(1)wedon'tusethehigh-resolutionpyramidlevel
P
2
forcom-
putationalreasons,(2)
P
6
iscomputedbystrided convolutioninsteadof
downsampling,and(3)weinclude
P
7
toimprove largeobjectdetection.
Theseminormodicationsimprove speedwhilemaintainingaccuracy.
4
2983

class+box
 subnets
class
 subnet
b ox
 subnet
WÃ—H
Ã—256
WÃ—H
Ã—256
WÃ—H
Ã—4A
WÃ—H
Ã—256
WÃ—H
Ã—256
WÃ—H
Ã—KA
Ã—4
Ã—4
+
+
class+box
 subnets
class+box
 subnets
(a) ResNet (b) feature pyramid net(c) class subnet (top)(d) box subnet (bottom)
Figure3.Theone-stage
RetinaNet
networkarchitectureuses aFeaturePyramidNetwork(FPN)[
19
]backboneontopofafeedforward
ResNetarchitecture[
15
](a)togeneratearich,multi-scaleconvolutionalfeaturepyramid(b).Tothis backboneRetinaNetattachestwo
subnetworks,oneforclassifyinganchorboxes(c)andoneforregressingfromanchorboxestoground-truthobjectboxes(d).Thenetwork

designisintentionallysimple,whichenablesthisworktofocusona novelfocallossfunction thateliminatestheaccuracygapbetweenour

one-stagedetectorandstate-of-the-arttwo-stagedetectorslikeFasterR-CNNwithFPN[
19
]whilerunningatfaster speeds.
ClassicationSubnet:
Theclassicationsubnetpredicts
theprobabilityofobjectpresenceateachspatialposition

foreachofthe
A
anchorsand
K
objectclasses.Thissubnet
isasmallFCNattachedtoeachFPNlevel;parametersof

thissubnetaresharedacrossall pyramidlevels.Its design

issimple.Takinganinputfeaturemapwith
C
channels
fromagivenpyramidlevel,thesubnetappliesfour3

3
convlayers,eachwith
C
ltersandeachfollowed byReLU
activations,followedbya3

3convlayerwith
KA
lters.
Finallysigmoidactivationsareattachedtooutputthe
KA
binarypredictionsperspatiallocation,seeFigure
3
(c).We
use
C
=256
and
A
=9
inmostexperiments.
Incontrastto RPN [
27
],ourobjectclassicationsubnet
isdeeper,usesonly3

3convs,anddoes notshareparam-
eterswiththeboxregressionsubnet(describednext).We

foundthesehigher-leveldesigndecisionstobemoreim-

portantthanspecicvaluesofhyperparameters.

BoxRegressionSubnet:
Inparallelwiththeobjectclassi-
cationsubnet,weattachanothersmallFCNto eachpyra-

midlevelforthepurposeofregressingtheoffsetfromeach

anchorboxtoanearbyground-truthobject,ifoneexists.

Thedesignoftheboxregressionsubnet isidenticaltothe

classicationsubnetexceptthatitterminatesin
4
A
linear
outputsperspatiallocation,seeFigure
3
(d).Foreach
ofthe
A
anchorsperspatiallocation,these
4
outputspre-
dicttherelativeoffsetbetweentheanchorandtheground-

truthbox(weusethestandardboxparameterizationfromR-

CNN[
11
]).Wenotethatunlikemostrecentwork,weusea
class-agnosticboundingboxregressorwhichusesfewerpa-

rameters andwefoundtobeequallyeffective.Theobject

classicationsubnetandtheboxregressionsubnet,though

sharingacommonstructure,useseparate parameters.

4.1.Inferenceand Training

Inference:
RetinaNetformsasingle FCNcomprisedofa
ResNet-FPNbackbone,aclassicationsubnet,andabox
regressionsubnet,seeFigure
3
.Assuch,inferenceinvolves
simplyforwardinganimagethroughthenetwork.Toim-

provespeed,weonlydecodeboxpredictionsfrom atmost

1ktop-scoringpredictionsperFPNlevel,afterthreshold-

ingdetectorcondenceat0.05.Thetoppredictionsfrom

alllevelsaremergedandnon-maximumsuppressionwitha

thresholdof0.5isappliedtoyieldthenaldetections.

FocalLoss:
Weusethefocallossintroducedinthiswork
asthelossontheoutputoftheclassicationsubnet.Aswe

willshowin
x
5
,wendthat

=2
workswellinpractice
andtheRetinaNetisrelativelyrobustto

2
[0
:
5
;
5]
. We
emphasizethatwhentrainingRetinaNet,thefocallossis

appliedto
all
Ë˜
100kanchors in each sampledimage.This
standsincontrasttocommonpracticeofusingheuristic

sampling(RPN)orhardexamplemining(OHEM,SSD)to

selecta smallsetofanchors(
e.g
.,256)foreachminibatch.
Thetotalfocallossofanimageiscomputedasthesum

ofthefocallossoverall
Ë˜
100kanchors,
normalizedbythe
numberofanchorsassignedtoaground-truthbox
.Weper-
formthenormalizationbythenumberofassignedanchors,

nottotalanchors,sincethevastmajorityofanchorsareeasy

negativesandreceivenegligiblelossvaluesunderthefocal

loss.Finallywenotethat

,theweightassignedtotherare
class,alsohasastablerange, butitinteractswith

mak-
ingitnecessarytoselectthetwotogether(see Tables
1a
and
1b
).Ingeneral

shouldbedecreasedslightlyas

is
increased(for

=2
,

=0
:
25
worksbest).
Initialization:
WeexperimentwithResNet-50-FPNand
ResNet-101-FPNbackbones[
19
].ThebaseResNet-50and
ResNet-101modelsarepre-trainedonImageNet1k;weuse

themodelsreleasedby[
15
].NewlayersaddedforFPNare
initializedasin[
19
].Allnewconv layersexceptthenal
oneintheRetinaNetsubnetsareinitializedwithbias
b
=0
andaGaussianweightllwith
Ë™
=0
:
01
.Forthenalconv
layeroftheclassicationsubnet,wesetthe biasinitializa-

tionto
b
=

log((1

Ë‡
)
=Ë‡
)
,where
Ë‡
speciesthatat
5
2984


APAP
50
AP
75
.10
0.0 0.0 0.0
.25
10.8 16.0 11.7
.50
30.2 46.7 32.8
.75
31.1 49.4 33.0
.90
30.8 49.7 32.3
.99
28.7 47.4 29.9
.999
25.1 41.7 26.1
(a)
Varying

forCEloss
(

=0
)

APAP
50
AP
75
0.75
31.1 49.4 33.0
0.1.75
31.4 49.9 33.1
0.2.75
31.9 50.7 33.4
0.5.50
32.9 51.7 35.2
1.0.25
33.7 52.0 36.2
2.0.25
34.0 52.5 36.5
5.0.25
32.2 49.6 34.8
(b)
Varying

forFL
(w.optimal

)
#sc#ar
APAP
50
AP
75
1 1
30.3 49.0 31.8
2 1
31.9 50.0 34.0
3 1
31.8 49.4 33.7
1 3
32.4 52.3 33.9
2 3
34.2 53.1 36.5
3 3
34.0 52.5
36.5
4 3
33.8 52.1 36.2
(c)
Varyinganchorscalesandaspects
method
batchnms
APAP
50
AP
75
size thr
OHEM
128.7
31.1 47.2 33.2
OHEM
256.7
31.8 48.8 33.9
OHEM
512.7
30.6 47.0 32.6
OHEM
128.5
32.8 50.3 35.1
OHEM
256.5
31.0 47.4 33.0
OHEM
512.5
27.6 42.0 29.2
OHEM1:3
128.5
31.1 47.2 33.2
OHEM1:3
256.5
28.3 42.4 30.3
OHEM1:3
512.5
24.0 35.5 25.8
FL
n/an/a
36.0 54.9 38.7
(d)
FL
vs
.OHEM
baselines(withResNet-101-FPN)
depthscale
APAP
50
AP
75
AP
S
AP
M
AP
L
time
50400
30.547.832.7
11.2 33.8 46.1
64
50 500
32.550.934.8
13.9 35.8 46.7
72
50 600
34.353.236.9
16.2 37.4 47.4
98
50 700
35.154.237.7
18.0 39.3 46.4
121
50800
35.755.038.5
18.9 38.9 46.3
153
101400
31.949.534.1
11.6 35.8 48.5
81
101500
34.453.136.8
14.7 38.5 49.1
90
101600
36.055.238.7
17.4 39.6 49.7
122
101700
37.156.639.8
19.1 40.6 49.4
154
101800
37.857.540.8
20.2 41.1 49.2
198
(e)
Accuracy/speedtrade-off
RetinaNet(on
test-dev
)
Table1.
AblationexperimentsforRetinaNetandFocalLoss(FL).
Allmodelsaretrainedon
trainval35k
andtestedon
minival
unlessnoted.Ifnotspecied,defaultvaluesare:

=2
;anchors for3scalesand3aspectratios;ResNet-50-FPNbackbone;anda600
pixeltrainandtestimagescale.(a)RetinaNetwith

-balancedCEachievesatmost31.1AP.(b)Incontrast,usingFLwiththesameexact
networkgivesa2.9APgainandisfairlyrobusttoexact

/

settings.(c)Using2-3scaleand 3aspectratioanchorsyieldsgoodresults
afterwhichpointperformance saturates.(d)FLoutperformsthebestvariantsofonlinehardexamplemining(OHEM)[
30
,
21
]byover3
points AP. (e)Accuracy/Speedtrade-offofRetinaNeton
test-dev
forvariousnetworkdepthsand image scales(seealsoFigure
2
).
thestartoftrainingeveryanchorshouldbelabeledasfore-

groundwithcondenceof
Ë˜
Ë‡
.Weuse
Ë‡
=
:
01
inallex-
periments,althoughresultsarerobusttotheexact value.As

explainedin
x
3.4
,thisinitializationpreventsthelargenum-
berofbackgroundanchorsfromgeneratingalarge, desta-

bilizinglossvalueintherstiterationoftraining.

Optimization:RetinaNetistrainedwithstochasticgradi-
entdescent(SGD).WeusesynchronizedSGDover8GPUs

withatotalof16imagesperminibatch(2imagesperGPU).

Unlessotherwisespecied,allmodelsaretrainedfor90kit-

erationswithaninitiallearningrateof0.01,whichisthen

dividedby10at60kandagainat80kiterations.Weuse

horizontalimageippingastheonlyformofdataaugmen-

tationunlessotherwisenoted.Weightdecayof0.0001and

momentumof0.9areused.Thetraininglossisthesum

thefocallossandthestandardsmooth
L
1
lossusedfor box
regression[
10
].Trainingtimerangesbetween10and35
hoursforthemodelsinTable
1e
.
5.Experiments
Wepresentexperimentalresultsontheboundingbox
detectiontrackofthe challengingCOCObenchmark[
20
].
Fortraining, wefollowcommon practice [
1
,
19
] anduse
theCOCO
trainval35k
split(unionof80kimagesfrom
train
andarandom35ksubsetofimagesfromthe40kim-
age
val
split).Wereportlesionandsensitivitystudiesby
evaluating onthe
minival
split(theremaining5kimages
from
val
).Forourmainresults,wereportCOCOAPon
the
test-dev
split,whichhasnopubliclabelsandrequires
useoftheevaluationserver.

5.1.TrainingDenseDetection
Werunnumerousexperimentstoanalyzethebehavior
ofthelossfunctionfordensedetectionalongwithvarious

optimizationstrategies. Forallexperimentsweusedepth

50or101ResNets[
15
] withaFeaturePyramidNetwork
(FPN)[
19
]constructedontop.Forallablationstudieswe
useanimagescaleof600pixelsfortrainingandtesting.

NetworkInitialization:
OurrstattempttotrainReti-
naNetuses standardcrossentropy(CE)losswithoutany

modicationstotheinitializationorlearningstrategy.This

failsquickly,withthenetworkdivergingduringtraining.

However,simplyinitializingthelastlayerofourmodelsuch

thatthepriorprobabilityofdetectinganobjectis
Ë‡
=
:
01
(see
x
4.1
)enableseffective learning.TrainingRetinaNet
withResNet-50andthisinitializationalreadyyieldsare-

spectableAPof30.2onCOCO.Resultsareinsensitiveto

theexactvalueof
Ë‡
soweuse
Ë‡
=
:
01
forallexperiments.
6
2985

0.2.4.6.81
fraction of foreground examples
0
0.2
0.4
0.6
0.8
1
cumulative normalized loss
 = 0
 = 0.5
 = 1
 = 2
0.2.4.6.81
fraction of background examples
0
0.2
0.4
0.6
0.8
1
cumulative normalized loss
 = 0
 = 0.5
 = 1
 = 2
Figure4.Cumulativedistribution functionsofthenormalizedloss for positiveandnegativesamplesfor differentvaluesof

for a
converged
model.Theeffectofchanging

onthe distributionofthelossforpositiveexamplesisminor.Fornegatives,however,increasing

heavily
concentratesthelossonhardexamples,focusing nearlyallattentionawayfromeasynegatives.

BalancedCrossEntropy:
Our nextattempttoimprove
learninginvolvedusingthe

-balancedCElossdescribed
in
x
3.1
.Resultsforvarious

areshowninTable
1a
.Set-
ting

=
:
75
givesagainof0.9pointsAP.
FocalLoss:
Resultsusingourproposedfocallossare
showninTable
1b
.Thefocallossintroducesonenewhy-
perparameter,thefocusingparameter

,thatcontrolsthe
strengthofthe modulatingterm.When

=0
,our lossis
equivalenttotheCEloss.As

increases,theshapeofthe
losschangessothat ï¬easyï¬‚exampleswithlowlossgetfur-

therdiscounted,seeFigure
1
.FLshowslargegainsover
CEas

isincreased.With

=2
,FL
yieldsa2.9APim-
provementover the

-balancedCEloss
.
FortheexperimentsinTable
1b
,forafair comparison
wendthebest

foreach

.Weobservethatlower

's
areselectedforhigher

's(aseasynegativesaredown-
weighted,lessemphasisneedstobeplacedontheposi-

tives).Overall,however,thebenetofchanging

ismuch
larger,andindeedthebest

'srangedinjust[.25,.75](we
tested

2
[
:
01
;:
999]
).Weuse

=2
:
0
with

=
:
25
forall
experimentsbut

=
:
5
worksnearlyaswell(.4APlower).
AnalysisoftheFocalLoss:
Tounderstandthefocalloss
better,weanalyzetheempiricaldistributionofthelossofa

converged
model.Forthis,wetaketakeourdefaultResNet-
101600-pixelmodeltrainedwith

=2
(whichhas36.0
AP).Weapplythismodeltoalargenumberofrandomim-

ages andsamplethepredictedprobabilityfor
Ë˜
10
7
negative
windows and
Ë˜
10
5
positivewindows.Next,separately for
positivesandnegatives,wecomputeFLforthese samples,

andnormalizethelosssuchthatitsumstoone.Giventhe

normalizedloss,we cansortthelossfromlowesttohighest

andplotitscumulativedistributionfunction(CDF)forboth

positiveandnegativesamplesandfordifferentsettingsfor


(eventhoughmodelwastrainedwith

=2
).
Cumulativedistributionfunctions forpositiveandnega-
tivesamplesareshowninFigure
4
.Ifweobservethepos-
itivesamples,weseethatthe CDFlooksfairlysimilarfor

differentvaluesof

.Forexample,approximately20%of
thehardestpositivesamplesaccountforroughlyhalfofthe
positiveloss,as

increases moreoftheloss getsconcen-
tratedinthetop20%ofexamples,buttheeffectisminor.
Theeffectof

onnegativesamplesisdramaticallydif-
ferent.For

=0
,thepositiveandnegativeCDFsarequite
similar.However,as

increases,substantiallymoreweight
becomesconcentratedonthehardnegativeexamples.In

fact,with

=2
(ourdefaultsetting),thevastmajorityof
thelosscomesfroma smallfractionofsamples.Ascan be

seen,FLcaneffectivelydiscounttheeffectofeasynega-

tives,focusingallattentiononthehardnegativeexamples.

OnlineHardExampleMining(OHEM):
[
30
]proposed
toimprovetrainingof two-stagedetectorsbyconstruct-

ingminibatchesusinghigh-lossexamples.Specically,in

OHEMeachexampleisscored byitsloss,non-maximum

suppression(nms)isthenapplied,andaminibatchiscon-

structedwiththehighest-lossexamples.Thenmsthreshold

andbatchsizearetunableparameters.Likethefocalloss,

OHEMputsmoreemphasis onmisclassiedexamples,but

unlikeFL,OHEMcompletelydiscardseasyexamples.We

alsoimplementavariantofOHEMusedinSSD[
21
]: after
applyingnmstoallexamples,theminibatchisconstructed

to enforcea1:3ratio betweenpositivesandnegativesto

helpensureeachminibatchhasenoughpositives.
WetestbothOHEMvariantsinoursettingofone-stage
detectionwhichhas largeclassimbalance.Resultsforthe

originalOHEMstrategyand the`OHEM1:3'strategyfor

selectedbatchsizesandnmsthresholdsareshowninTa-

ble1d
.TheseresultsuseResNet-101,ourbaselinetrained
withFLachieves36.0APforthissetting.Incontrast,the

bestsettingforOHEM(no1:3ratio,batchsize128,nmsof

.5)achieves32.8AP.Thisisagapof3.2AP,showingFL

ismoreeffectivethanOHEMfortrainingdensedetectors.

Wenotethatwetriedotherparametersettingandvariants

for OHEMbutdidnotachievebetterresults.

Hinge Loss:
Finally,inearlyexperiments,weattempted
totrainwiththehingeloss[
12
]on
p
t
,whichsetslossto0
aboveacertainvalueof
p
t
.However,thiswasunstableand
wedidnot managetoobtainmeaningfulresults.Results

exploringalternatelossfunctionsareintheonlineappendix.
7
2986

backbone
APAP
50
AP
75
AP
S
AP
M
AP
L
Two-stage methods
FasterR-CNN+++[
15
]
ResNet-101-C4
34.9 55.7 37.4
15.6 38.7 50.9
FasterR-CNN wFPN[
19
]
ResNet-101-FPN
36.2 59.1 39.0
18.2 39.0 48.2
FasterR-CNN byG-RMI[
16
]
Inception-ResNet-v2[
33
]
34.7 55.5 36.7
13.5 38.1 52.0
FasterR-CNN wTDM[
31
]
Inception-ResNet-v2-TDM
36.8 57.7 39.2
16.2 39.8
52.1
One-stage methods
YOLOv2[
26
]
DarkNet-19[
26
]
21.6 44.0 19.2
5.022.4 35.5
SSD513 [
21
,
9
]
ResNet-101-SSD
31.2 50.4 33.3
10.2 34.5 49.8
DSSD513[
9
]
ResNet-101-DSSD
33.2 53.3 35.2
13.0 35.4 51.1
RetinaNet
(ours)
ResNet-101-FPN
39.1 59.1 42.3
21.8 42.7
50.2
Table2.
Objectdetection
single-model
results(boundingboxAP),
vs
.state-of-the-art onCOCO
test-dev
.Weshowresultsforour
RetinaNet-101-800model,trainedwithscale jitterandfor1.5

longerthanthesamemodelfromTable
1e
.Ourmodel achievestopresults,
outperformingbothone-stageandtwo-stagemodels.ForadetailedbreakdownofspeedversusaccuracyseeTable
1e
and Figure
2
.
5.2.ModelArchitecture Design

AnchorDensity:
Oneofthemostimportantdesignfac-
torsinaone-stagedetectionsystemishowdenselyitcovers

thespaceofpossible imageboxes.Two-stagedetectorscan

classifyboxesatanyposition,scale,andaspectratio using

aregionpooling operation[
10
].Incontrast,asone-stage
detectorsuseaxedsamplinggrid,apopularapproachfor

achievinghighcoverageofboxesin theseapproachesis to

usemultiple`anchors'[
27
]ateachspatialpositiontocover
boxesofvariousscalesandaspectratios.
Wesweepoverthenumberofscaleandaspectratioan-
chorsusedateachspatial positionandeachpyramidlevelin

FPN.Weconsidercasesfromasinglesquareanchorat each

locationto12anchorsperlocationspanning4sub-octave

scales(
2
k=
4
,for
k

3
)and3aspectratios[0.5,1,2].Re-
sultsusingResNet-50areshowninTable
1c
.Asurprisingly
goodAP (30.3)isachievedusingjustonesquareanchor.

However,theAPcanbeimprovedbynearly4points(to

34.0)when using 3scalesand3aspectratiosperlocation.

Weusedthissettingforallotherexperiments inthiswork.
Finally,wenotethatincreasingbeyond6-9anchorsdid
notshownfurthergains.Thuswhiletwo-stagesystemscan

classifyarbitraryboxesinanimage,thesaturationofper-

formancew.r.t.density impliesthehigherpotentialdensity

oftwo-stagesystemsmaynotofferanadvantage.

SpeedversusAccuracy:
Largerbackbone networksyield
higheraccuracy,butalsoslowerinferencespeeds.Likewise

forinputimagescale(denedbytheshorterimageside).

WeshowtheimpactofthesetwofactorsinTable
1e
.In
Figure
2
weplotthespeed/accuracytrade-offcurveforReti-
naNetandcompareitto recentmethodsusingpublicnum-

bersonCOCO
test-dev
.TheplotrevealsthatRetinaNet,
enabledbyourfocalloss,formsanupperenvelopeover

allexistingmethods,discountingthelow-accuracyregime.

Remarkably,RetinaNetwithResNet-101-FPNanda600

pixelimagescale(whichwedenotebyRetinaNet-101-600

forsimplicity)matchestheaccuracyoftherecentlypub-

lishedResNet-101-FPNFasterR-CNN[
19
],whilerunning
in122msperimagecomparedto172ms(bothmeasuredon

anNvidiaM40GPU).Using largerimagesizesallowsReti-

naNettosurpasstheaccuracyofalltwo-stageapproaches,

whilestillbeingfaster.Forfasterruntimes,thereisonlyone

operatingpoint(500pixelinput)atwhichusingResNet-50-

FPN improvesover ResNet-101-FPN.Addressingthehigh

framerateregimewilllikelyrequirespecialnetworkdesign,

asin[
26
],ratherthanuseofanoff-the-shelfmodelandis
beyondthescopeofthiswork.

5.3.ComparisontoStateoftheArt
WeevaluateRetinaNetonthebounding boxdetec-
tiontaskofthechallengingCOCOdatasetandcompare

test-devresultstorecentstate-of-the-artmethodsinclud-
ingbothone-stageandtwo-stagemodels.Resultsarepre-

sentedinTable
2
forourRetinaNet-101-800modeltrained
usingscalejitterandfor1.5

longerthan themodelsin
Table
1e
(givinga1.3APgain).Comparedtoexistingone-
stagemethods,ourapproachachievesahealthy5.9point

APgap(39.1
vs
.33.2)withtheclosestcompetitor,DSSD
[
9
],whilealsobeingfaster,seeFigure
2
.Comparedtore-
centtwo-stagemethods, RetinaNetachievesa2.3pointgap

above thetop-performingFasterR-CNNmodelbasedon

Inception-ResNet-v2-TDM[
31
].
6.Conclusion
Inthiswork,weidentifyclassimbalanceastheprimary
obstaclepreventingone-stageobjectdetectorsfromsur-

passingtop-performing,two-stagemethods,suchasFaster

R-CNNvariants.Toaddressthis,weproposethe
focalloss
whichapplies amodulatingtermtothecrossentropylossin

ordertofocuslearningonhardexamplesanddown-weight

thenumerouseasynegatives.Our approach issimpleand

highlyeffective.Wedemonstrateitsefcacybydesigninga

fullyconvolutionalone-stagedetectorandreportextensive

experimentalanalysisshowingthatit achievesstate-of-the-

artaccuracy and runtimeonthechallengingCOCOdataset.
8
2987

References
[1]S.Bell,C.L.Zitnick,K.Bala,andR.Girshick.Inside-
outsidenet: Detectingobjectsincontextwithskip pooling

andrecurrentneuralnetworks.In
CVPR
, 2016.
6
[2]S.R. Bulo,G.Neuhold,andP.Kontschieder.Lossmax-
poolingforsemanticimagesegmentation.In
CVPR
,2017.
3
[3]J.Dai,Y.Li,K.He,andJ.Sun.R-FCN:Objectdetectionvia
region-basedfullyconvolutionalnetworks.In
NIPS
,2016.
1
[4]N.DalalandB.Triggs. Histogramsoforientedgradientsfor
humandetection.In
CVPR
, 2005.
2
[5]P.Doll
Â´
ar,Z.Tu,P.Perona,andS.Belongie.Integralchannel
features.2009.
2
,
3
[6]D.Erhan, C.Szegedy,A.Toshev,andD.Anguelov.Scalable
objectdetectionusingdeepneuralnetworks.In
CVPR
,2014.
2
[7]M.Everingham, L.VanGool,C.K.Williams,J.Winn, and
A.Zisserman.ThePASCALVisualObjectClasses(VOC)

Challenge.IJCV
, 2010.
2
[8]P.F.Felzenszwalb,R.B.Girshick,andD. McAllester.Cas-
cadeobjectdetectionwithdeformablepartmodels.In
CVPR
,
2010.
2
,
3
[9]C.-Y.Fu,W.Liu,A.Ranga,A.Tyagi,andA.C. Berg.DSSD:
Deconvolutionalsingleshotdetector.
arXiv:1701.06659
,
2016.
1
,
2
,
8
[10]R.Girshick.FastR-CNN.In
ICCV
, 2015.
1
,
2
,
4
,
6
,
8
[11]R. Girshick,J.Donahue,T.Darrell,andJ.Malik.Richfea-
turehierarchiesforaccurateobjectdetectionand semantic

segmentation.In
CVPR
, 2014.
1
,
2
,
5
[12]T.Hastie,R.Tibshirani,andJ.Friedman.
Theelementsof
statisticallearning
.SpringerseriesinstatisticsSpringer,
Berlin,2008.
3
,
7
[13]K.He,G.Gkioxari,P.Doll
Â´
ar,andR.Girshick.MaskR-
CNN.In
ICCV
, 2017.
1
,
2
,
4
[14]K.He,X.Zhang,S.Ren,andJ.Sun.Spatialpyramidpooling
indeepconvolutionalnetworksforvisual recognition.In

ECCV. 2014.
2
[15]K.He,X.Zhang,S.Ren,andJ.Sun.Deepresiduallearning
forimagerecognition.In
CVPR
, 2016.
2
,
4
,
5
,
6
,
8
[16]J.Huang,V.Rathod,C.Sun,M.Zhu,A.Korattikara,
A.Fathi,I.Fischer,Z.Wojna,Y.Song,S.Guadarrama,and

K.Murphy.Speed/accuracytrade-offsformodernconvolu-

tionalobjectdetectors.2017.
2
,
8
[17]A.Krizhevsky,I.Sutskever,andG.Hinton.ImageNetclas-
sicationwithdeepconvolutionalneuralnetworks.In
NIPS
,
2012.
2
[18]Y.LeCun,B.Boser,J.S.Denker,D.Henderson, R.E.
Howard,W.Hubbard,andL.D.Jackel.Backpropagation

appliedtohandwrittenzipcoderecognition.
Neuralcompu-
tation
, 1989.
2
[19]T.-Y.Lin,P.Doll
Â´
ar,R.Girshick,K.He,B.Hariharan,and
S.Belongie.Featurepyramidnetworksforobjectdetection.

InCVPR
, 2017.
1
,
2
,
4
,
5
,
6
,
8
[20]T.-Y.Lin,M.Maire,S.Belongie,J.Hays,P.Perona,D.Ra-
manan,P.Doll
Â´
ar,andC.L. Zitnick.MicrosoftCOCO: Com-
monobjectsincontext.In
ECCV
, 2014.
1
,
6
[21]W.Liu, D.Anguelov,D.Erhan,C.Szegedy,andS.Reed.
SSD:Singleshotmultiboxdetector.In
ECCV
,2016.
1
,
2
,
3
,
6
,
7
,
8
[22]J.Long,E.Shelhamer,andT.Darrell.Fullyconvolutional
networksforsemanticsegmentation.In
CVPR
, 2015.
4
[23]P.O.Pinheiro,R.Collobert,andP.Dollar.Learningtoseg-
mentobjectcandidates.In
NIPS
, 2015.
2
,
4
[24]P.O.Pinheiro,T.-Y.Lin,R.Collobert,andP.Doll
Â´
ar.Learn-
ingtoreneobjectsegments.In
ECCV
, 2016.
2
[25]J.Redmon,S.Divvala,R.Girshick,andA.Farhadi.You
onlylook once:Unied,real-timeobjectdetection. In

CVPR, 2016.
1
,
2
[26]J.RedmonandA.Farhadi.YOLO9000:Better,faster,
stronger.In
CVPR
, 2017.
1
,
2
,
8
[27]S.Ren,K. He,R.Girshick,andJ.Sun.FasterR-CNN:To-
wardsreal-time objectdetectionwithregionproposalnet-

works.In
NIPS
, 2015.
1
,
2
,
4
,
5
,
8
[28]H.Rowley,S.Baluja,andT.Kanade.Humanfacedetec-
tioninvisualscenes.TechnicalReportCMU-CS-95-158R,

CarnegieMellonUniversity, 1995.
2
[29]P.Sermanet,D.Eigen,X.Zhang,M.Mathieu,R.Fergus,
andY.LeCun.Overfeat:Integrated recognition,localization

anddetectionusingconvolutionalnetworks.In
ICLR
,2014.
2
[30]A.Shrivastava,A.Gupta,andR.Girshick.Trainingregion-
basedobjectdetectorswithonline hardexamplemining.In

CVPR, 2016.
2
,
3
,
6
,
7
[31]A. Shrivastava,R.Sukthankar,J.Malik,andA. Gupta.Be-
yond skipconnections:Top-downmodulationforobjectde-

tection.arXiv:1612.06851
, 2016.
2
,
8
[32]K.-K.SungandT.Poggio. LearningandExampleSelection
forObjectandPatternDetection.In
MITA.I.MemoNo.
1521
, 1994.
2
,
3
[33]C.Szegedy,S.Ioffe,andV.Vanhoucke.Inception-v4,
inception-resnetand theimpactofresidualconnectionson

learning.arXiv:1602.07261
, 2016.
8
[34]J.R.Uijlings,K.E.vandeSande,T.Gevers,andA.W.
Smeulders. Selectivesearchforobjectrecognition.
IJCV
,
2013.
2
,
4
[35]R.Vaillant,C.Monrocq,andY.LeCun.Originalapproach
forthelocalisationof objectsinimages.
IEEProc.onVision,
Image, andSignalProcessing
, 1994.
2
[36]P.ViolaandM.Jones.Rapidobjectdetectionusingaboosted
cascadeofsimplefeatures.In
CVPR
, 2001.
2
,
3
[37]C.L.ZitnickandP.Doll
Â´
ar.Edgeboxes:Locatingobject
proposalsfromedges.In
ECCV
, 2014.
2
9
2988

