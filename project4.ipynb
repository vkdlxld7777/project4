{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PdfReadWarning: Xref table not zero-indexed. ID numbers for objects will be corrected. [_reader.py:1065]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>detail</th>\n",
       "      <th>detail_tokens</th>\n",
       "      <th>title_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Primer in BERTology What We Know About How B...</td>\n",
       "      <td>APrimerinBERTology:WhatWeKnowAboutHowBERTWorks...</td>\n",
       "      <td>[aprimerinbertologywhatweknowabouthowbertwork,...</td>\n",
       "      <td>[primer, bertology, know, bert, works]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Sensitivity Analysis of (and Practitioners’ ...</td>\n",
       "      <td>A Sensitivity Analysis of (and Practitioners' ...</td>\n",
       "      <td>[sensit, analysi, and, practition, guid, convo...</td>\n",
       "      <td>[sensitivity, analysis, and, practitioners, gu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>attention based models for speech recognition</td>\n",
       "      <td>Attention-Based Models for Speech Recognition\\...</td>\n",
       "      <td>[attentionbas, model, speech, recognit, jan, c...</td>\n",
       "      <td>[attention, based, models, speech, recognition]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>attention is all you need</td>\n",
       "      <td>Attention Is All You Need\\nAshish Vaswani\\n\u0003\\n...</td>\n",
       "      <td>[attent, need, ashish, vaswani, googl, brain, ...</td>\n",
       "      <td>[attention, need]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bag of Tricks for Efficient Text Classification</td>\n",
       "      <td>arXiv:1607.01759v3  [cs.CL]  9 Aug 2016\\nBagof...</td>\n",
       "      <td>[arxivv, cscl, aug, bagoftricksforefcienttextc...</td>\n",
       "      <td>[bag, tricks, efficient, text, classification]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>big-self supervised models are strong semi sup...</td>\n",
       "      <td>Big Self-Supervised Models are\\nStrong Semi-Su...</td>\n",
       "      <td>[big, selfsupervis, model, strong, semisupervi...</td>\n",
       "      <td>[bigself, supervised, models, strong, semi, su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BIRCH an efficient data clustering method for ...</td>\n",
       "      <td>BIRCH:\\nAn\\nEfficient\\nData\\nClustering\\nMetho...</td>\n",
       "      <td>[birch, effici, data, cluster, method, larg, d...</td>\n",
       "      <td>[birch, efficient, data, clustering, method, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Character-level Convolutional Networks for Tex...</td>\n",
       "      <td>Character-level Convolutional Networks for Tex...</td>\n",
       "      <td>[characterlevel, convolut, network, text, clas...</td>\n",
       "      <td>[characterlevel, convolutional, networks, text...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Deep Residual Learning for Image Recognition</td>\n",
       "      <td>DeepResidualLearningfor ImageRecognition\\nKaim...</td>\n",
       "      <td>[deepresiduallearningfor, imagerecognit, kaimi...</td>\n",
       "      <td>[deep, residual, learning, image, recognition]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Efficient Convolutional Neural Networks for Mo...</td>\n",
       "      <td>MobileNets: Ef\u0002cient Convolutional Neural Netw...</td>\n",
       "      <td>[mobilenet, efcient, convolut, neural, network...</td>\n",
       "      <td>[efficient, convolutional, neural, networks, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Exploring the Limits of Transfer Learning with...</td>\n",
       "      <td>Journal of Machine Learning Research 21 (2020)...</td>\n",
       "      <td>[journal, machin, learn, research, subm, revis...</td>\n",
       "      <td>[exploring, limits, transfer, learning, unifie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Fast R-CNN</td>\n",
       "      <td>FastR-CNN\\nRossGirshick\\nMicrosoftResearch\\nrb...</td>\n",
       "      <td>[fastrcnn, rossgirshick, microsoftresearch, rb...</td>\n",
       "      <td>[fast, rcnn]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>faster r-cnn towards real time object detectio...</td>\n",
       "      <td>Faster R-CNN: Towards Real-Time Object Detecti...</td>\n",
       "      <td>[faster, rcnn, realtim, object, detect, region...</td>\n",
       "      <td>[faster, rcnn, real, time, object, detection, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Feature Pyramid Networks for Object Detection</td>\n",
       "      <td>FeaturePyramidNetworksforObjectDetection\\nTsun...</td>\n",
       "      <td>[featurepyramidnetworksforobjectdetect, tsungy...</td>\n",
       "      <td>[feature, pyramid, networks, object, detection]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Focal Loss for Dense Object Detection</td>\n",
       "      <td>FocalLossforDenseObjectDetection\\nTsung-YiLinP...</td>\n",
       "      <td>[focallossfordenseobjectdetect, tsungyilinpriy...</td>\n",
       "      <td>[focal, loss, dense, object, detection]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Generalized Autoregressive Pretraining for Lan...</td>\n",
       "      <td>XLNet: Generalized Autoregressive Pretraining\\...</td>\n",
       "      <td>[xlnet, gener, autoregress, pretrain, languag,...</td>\n",
       "      <td>[generalized, autoregressive, pretraining, lan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>GRAPH ATTENTION NETWORKS</td>\n",
       "      <td>Published as a conference paper at ICLR 2018\\n...</td>\n",
       "      <td>[publish, confer, paper, iclr, raph, petar, ve...</td>\n",
       "      <td>[graph, attention, networks]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Hierarchical Attention Networks for Document C...</td>\n",
       "      <td>Proceedings of NAACL-HLT 2016\\n, pages 1480Œ14...</td>\n",
       "      <td>[proceed, naaclhlt, page, san, diego, californ...</td>\n",
       "      <td>[hierarchical, attention, networks, document, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>imagenet classification with deep convolutiona...</td>\n",
       "      <td>ImageNet Classi\u0002cation with Deep Convolutional...</td>\n",
       "      <td>[imagenet, classic, deep, convolut, neural, ne...</td>\n",
       "      <td>[imagenet, classification, deep, convolutional...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Language Models are Few-Shot Learners</td>\n",
       "      <td>Language Models are Few-Shot Learners\\nTom B. ...</td>\n",
       "      <td>[languag, model, fewshot, learner, tom, brown,...</td>\n",
       "      <td>[language, models, fewshot, learners]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Language Models are Unsupervised Multitask Lea...</td>\n",
       "      <td>Language Models are Unsupervised Multitask Lea...</td>\n",
       "      <td>[languag, model, unsupervis, multitask, learne...</td>\n",
       "      <td>[language, models, unsupervised, multitask, le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Learning Pharase Representaton using RNN Encod...</td>\n",
       "      <td>Learning Phrase Representations using RNN Enco...</td>\n",
       "      <td>[learn, phrase, represent, rnn, encoderdecod, ...</td>\n",
       "      <td>[learning, pharase, representaton, rnn, encode...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Learning Transferable Visual Models From Natur...</td>\n",
       "      <td>Learning Transferable Visual Models From Natur...</td>\n",
       "      <td>[learn, transfer, visual, model, natur, langua...</td>\n",
       "      <td>[learning, transferable, visual, models, natur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Mask R-CNN</td>\n",
       "      <td>MaskR-CNN\\nKaimingHeGeorgia GkioxariPiotrDoll\\...</td>\n",
       "      <td>[maskrcnn, kaiminghegeorgia, gkioxaripiotrdol,...</td>\n",
       "      <td>[mask, rcnn]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Neural Image Caption Generation with Visual At...</td>\n",
       "      <td>Show, Attend and Tell: Neural Image Caption\\nG...</td>\n",
       "      <td>[show, attend, tell, neural, imag, caption, ge...</td>\n",
       "      <td>[neural, image, caption, generation, visual, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Non-Local Neural Networks</td>\n",
       "      <td>Non-localNeuralNetworks\\nXiaolongWang\\n1,2\\n\u0003\\...</td>\n",
       "      <td>[nonlocalneuralnetwork, xiaolongwang, rossgirs...</td>\n",
       "      <td>[nonlocal, neural, networks]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>On the Dangers of Stochastic Parrots Can Langu...</td>\n",
       "      <td>\\n \\n\\n\u0007¿\\n\\n\\n\\n\u0007¿\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n \\n ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[dangers, stochastic, parrots, language, model...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Pretraining of Deep Bidirectional Transformers...</td>\n",
       "      <td>BERT: Pre-training of Deep Bidirectional Trans...</td>\n",
       "      <td>[bert, pretrain, deep, bidirect, transform, la...</td>\n",
       "      <td>[pretraining, deep, bidirectional, transformer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Recurrent Neural Network Regularization</td>\n",
       "      <td>arXiv:1409.2329v5  [cs.NE]  19 Feb 2015\\nUnder...</td>\n",
       "      <td>[arxivv, csne, feb, underreviewasaconferencepa...</td>\n",
       "      <td>[recurrent, neural, network, regularization]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>RoBERTa A Robustly Optimized BERT Pretraining ...</td>\n",
       "      <td>arXiv:1907.11692v1  [cs.CL]  26 Jul 2019\\nRoBE...</td>\n",
       "      <td>[arxivv, cscl, jul, robertaarobustlyoptimizedb...</td>\n",
       "      <td>[roberta, robustly, optimized, bert, pretraini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>sequence to sequence learning with neural netw...</td>\n",
       "      <td>SequencetoSequenceLearning\\nwithNeuralNetworks...</td>\n",
       "      <td>[sequencetosequencelearn, withneuralnetwork, i...</td>\n",
       "      <td>[sequence, sequence, learning, neural, networks]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Squeeze and Excitation Networks</td>\n",
       "      <td>Squeeze-and-ExcitationNetworks\\nJieHu\\n1\\n\u0003\\nL...</td>\n",
       "      <td>[squeezeandexcitationnetwork, jiehu, lishen, g...</td>\n",
       "      <td>[squeeze, excitation, networks]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Transformer in Transformer</td>\n",
       "      <td>Transformer in Transformer\\nKai Han\\n1\\n;\\n2\\n...</td>\n",
       "      <td>[transform, transform, kai, han, xiao, enhua, ...</td>\n",
       "      <td>[transformer, transformer]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>YOLO9000 Better Faster Stronger</td>\n",
       "      <td>YOLO9000:\\nBetter,Faster,Stronger\\nJoseph Redm...</td>\n",
       "      <td>[yolo, betterfasterstrong, joseph, redmon, ali...</td>\n",
       "      <td>[yolo, better, faster, stronger]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>YOLOv3 An Incremental Improvement</td>\n",
       "      <td>YOLOv3: An Incremental Improvement\\nJoseph Red...</td>\n",
       "      <td>[yolov, increment, improv, joseph, redmon, ali...</td>\n",
       "      <td>[yolov, incremental, improvement]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>You Only Look Once  Unified, Real-Time Object ...</td>\n",
       "      <td>YouOnlyLookOnce:\\nUni\u0002ed,Real-TimeObjectDetect...</td>\n",
       "      <td>[youonlylookonc, uniedrealtimeobjectdetect, jo...</td>\n",
       "      <td>[look, unified, realtime, object, detection]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0   A Primer in BERTology What We Know About How B...   \n",
       "1   A Sensitivity Analysis of (and Practitioners’ ...   \n",
       "2       attention based models for speech recognition   \n",
       "3                           attention is all you need   \n",
       "4     Bag of Tricks for Efficient Text Classification   \n",
       "5   big-self supervised models are strong semi sup...   \n",
       "6   BIRCH an efficient data clustering method for ...   \n",
       "7   Character-level Convolutional Networks for Tex...   \n",
       "8        Deep Residual Learning for Image Recognition   \n",
       "9   Efficient Convolutional Neural Networks for Mo...   \n",
       "10  Exploring the Limits of Transfer Learning with...   \n",
       "11                                         Fast R-CNN   \n",
       "12  faster r-cnn towards real time object detectio...   \n",
       "13      Feature Pyramid Networks for Object Detection   \n",
       "14              Focal Loss for Dense Object Detection   \n",
       "15  Generalized Autoregressive Pretraining for Lan...   \n",
       "16                           GRAPH ATTENTION NETWORKS   \n",
       "17  Hierarchical Attention Networks for Document C...   \n",
       "18  imagenet classification with deep convolutiona...   \n",
       "19              Language Models are Few-Shot Learners   \n",
       "20  Language Models are Unsupervised Multitask Lea...   \n",
       "21  Learning Pharase Representaton using RNN Encod...   \n",
       "22  Learning Transferable Visual Models From Natur...   \n",
       "23                                         Mask R-CNN   \n",
       "24  Neural Image Caption Generation with Visual At...   \n",
       "25                          Non-Local Neural Networks   \n",
       "26  On the Dangers of Stochastic Parrots Can Langu...   \n",
       "27  Pretraining of Deep Bidirectional Transformers...   \n",
       "28            Recurrent Neural Network Regularization   \n",
       "29  RoBERTa A Robustly Optimized BERT Pretraining ...   \n",
       "30  sequence to sequence learning with neural netw...   \n",
       "31                    Squeeze and Excitation Networks   \n",
       "32                         Transformer in Transformer   \n",
       "33                    YOLO9000 Better Faster Stronger   \n",
       "34                  YOLOv3 An Incremental Improvement   \n",
       "35  You Only Look Once  Unified, Real-Time Object ...   \n",
       "\n",
       "                                               detail  \\\n",
       "0   APrimerinBERTology:WhatWeKnowAboutHowBERTWorks...   \n",
       "1   A Sensitivity Analysis of (and Practitioners' ...   \n",
       "2   Attention-Based Models for Speech Recognition\\...   \n",
       "3   Attention Is All You Need\\nAshish Vaswani\\n\u0003\\n...   \n",
       "4   arXiv:1607.01759v3  [cs.CL]  9 Aug 2016\\nBagof...   \n",
       "5   Big Self-Supervised Models are\\nStrong Semi-Su...   \n",
       "6   BIRCH:\\nAn\\nEfficient\\nData\\nClustering\\nMetho...   \n",
       "7   Character-level Convolutional Networks for Tex...   \n",
       "8   DeepResidualLearningfor ImageRecognition\\nKaim...   \n",
       "9   MobileNets: Ef\u0002cient Convolutional Neural Netw...   \n",
       "10  Journal of Machine Learning Research 21 (2020)...   \n",
       "11  FastR-CNN\\nRossGirshick\\nMicrosoftResearch\\nrb...   \n",
       "12  Faster R-CNN: Towards Real-Time Object Detecti...   \n",
       "13  FeaturePyramidNetworksforObjectDetection\\nTsun...   \n",
       "14  FocalLossforDenseObjectDetection\\nTsung-YiLinP...   \n",
       "15  XLNet: Generalized Autoregressive Pretraining\\...   \n",
       "16  Published as a conference paper at ICLR 2018\\n...   \n",
       "17  Proceedings of NAACL-HLT 2016\\n, pages 1480Œ14...   \n",
       "18  ImageNet Classi\u0002cation with Deep Convolutional...   \n",
       "19  Language Models are Few-Shot Learners\\nTom B. ...   \n",
       "20  Language Models are Unsupervised Multitask Lea...   \n",
       "21  Learning Phrase Representations using RNN Enco...   \n",
       "22  Learning Transferable Visual Models From Natur...   \n",
       "23  MaskR-CNN\\nKaimingHeGeorgia GkioxariPiotrDoll\\...   \n",
       "24  Show, Attend and Tell: Neural Image Caption\\nG...   \n",
       "25  Non-localNeuralNetworks\\nXiaolongWang\\n1,2\\n\u0003\\...   \n",
       "26  \\n \\n\\n\u0007¿\\n\\n\\n\\n\u0007¿\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n \\n ...   \n",
       "27  BERT: Pre-training of Deep Bidirectional Trans...   \n",
       "28  arXiv:1409.2329v5  [cs.NE]  19 Feb 2015\\nUnder...   \n",
       "29  arXiv:1907.11692v1  [cs.CL]  26 Jul 2019\\nRoBE...   \n",
       "30  SequencetoSequenceLearning\\nwithNeuralNetworks...   \n",
       "31  Squeeze-and-ExcitationNetworks\\nJieHu\\n1\\n\u0003\\nL...   \n",
       "32  Transformer in Transformer\\nKai Han\\n1\\n;\\n2\\n...   \n",
       "33  YOLO9000:\\nBetter,Faster,Stronger\\nJoseph Redm...   \n",
       "34  YOLOv3: An Incremental Improvement\\nJoseph Red...   \n",
       "35  YouOnlyLookOnce:\\nUni\u0002ed,Real-TimeObjectDetect...   \n",
       "\n",
       "                                        detail_tokens  \\\n",
       "0   [aprimerinbertologywhatweknowabouthowbertwork,...   \n",
       "1   [sensit, analysi, and, practition, guid, convo...   \n",
       "2   [attentionbas, model, speech, recognit, jan, c...   \n",
       "3   [attent, need, ashish, vaswani, googl, brain, ...   \n",
       "4   [arxivv, cscl, aug, bagoftricksforefcienttextc...   \n",
       "5   [big, selfsupervis, model, strong, semisupervi...   \n",
       "6   [birch, effici, data, cluster, method, larg, d...   \n",
       "7   [characterlevel, convolut, network, text, clas...   \n",
       "8   [deepresiduallearningfor, imagerecognit, kaimi...   \n",
       "9   [mobilenet, efcient, convolut, neural, network...   \n",
       "10  [journal, machin, learn, research, subm, revis...   \n",
       "11  [fastrcnn, rossgirshick, microsoftresearch, rb...   \n",
       "12  [faster, rcnn, realtim, object, detect, region...   \n",
       "13  [featurepyramidnetworksforobjectdetect, tsungy...   \n",
       "14  [focallossfordenseobjectdetect, tsungyilinpriy...   \n",
       "15  [xlnet, gener, autoregress, pretrain, languag,...   \n",
       "16  [publish, confer, paper, iclr, raph, petar, ve...   \n",
       "17  [proceed, naaclhlt, page, san, diego, californ...   \n",
       "18  [imagenet, classic, deep, convolut, neural, ne...   \n",
       "19  [languag, model, fewshot, learner, tom, brown,...   \n",
       "20  [languag, model, unsupervis, multitask, learne...   \n",
       "21  [learn, phrase, represent, rnn, encoderdecod, ...   \n",
       "22  [learn, transfer, visual, model, natur, langua...   \n",
       "23  [maskrcnn, kaiminghegeorgia, gkioxaripiotrdol,...   \n",
       "24  [show, attend, tell, neural, imag, caption, ge...   \n",
       "25  [nonlocalneuralnetwork, xiaolongwang, rossgirs...   \n",
       "26                                                 []   \n",
       "27  [bert, pretrain, deep, bidirect, transform, la...   \n",
       "28  [arxivv, csne, feb, underreviewasaconferencepa...   \n",
       "29  [arxivv, cscl, jul, robertaarobustlyoptimizedb...   \n",
       "30  [sequencetosequencelearn, withneuralnetwork, i...   \n",
       "31  [squeezeandexcitationnetwork, jiehu, lishen, g...   \n",
       "32  [transform, transform, kai, han, xiao, enhua, ...   \n",
       "33  [yolo, betterfasterstrong, joseph, redmon, ali...   \n",
       "34  [yolov, increment, improv, joseph, redmon, ali...   \n",
       "35  [youonlylookonc, uniedrealtimeobjectdetect, jo...   \n",
       "\n",
       "                                         title_tokens  \n",
       "0              [primer, bertology, know, bert, works]  \n",
       "1   [sensitivity, analysis, and, practitioners, gu...  \n",
       "2     [attention, based, models, speech, recognition]  \n",
       "3                                   [attention, need]  \n",
       "4      [bag, tricks, efficient, text, classification]  \n",
       "5   [bigself, supervised, models, strong, semi, su...  \n",
       "6   [birch, efficient, data, clustering, method, l...  \n",
       "7   [characterlevel, convolutional, networks, text...  \n",
       "8      [deep, residual, learning, image, recognition]  \n",
       "9   [efficient, convolutional, neural, networks, m...  \n",
       "10  [exploring, limits, transfer, learning, unifie...  \n",
       "11                                       [fast, rcnn]  \n",
       "12  [faster, rcnn, real, time, object, detection, ...  \n",
       "13    [feature, pyramid, networks, object, detection]  \n",
       "14            [focal, loss, dense, object, detection]  \n",
       "15  [generalized, autoregressive, pretraining, lan...  \n",
       "16                       [graph, attention, networks]  \n",
       "17  [hierarchical, attention, networks, document, ...  \n",
       "18  [imagenet, classification, deep, convolutional...  \n",
       "19              [language, models, fewshot, learners]  \n",
       "20  [language, models, unsupervised, multitask, le...  \n",
       "21  [learning, pharase, representaton, rnn, encode...  \n",
       "22  [learning, transferable, visual, models, natur...  \n",
       "23                                       [mask, rcnn]  \n",
       "24  [neural, image, caption, generation, visual, a...  \n",
       "25                       [nonlocal, neural, networks]  \n",
       "26  [dangers, stochastic, parrots, language, model...  \n",
       "27  [pretraining, deep, bidirectional, transformer...  \n",
       "28       [recurrent, neural, network, regularization]  \n",
       "29  [roberta, robustly, optimized, bert, pretraini...  \n",
       "30   [sequence, sequence, learning, neural, networks]  \n",
       "31                    [squeeze, excitation, networks]  \n",
       "32                         [transformer, transformer]  \n",
       "33                   [yolo, better, faster, stronger]  \n",
       "34                  [yolov, incremental, improvement]  \n",
       "35       [look, unified, realtime, object, detection]  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import project4 as pro\n",
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "import tensorflow as tf\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "data = pd.DataFrame(pro.play.start())\n",
    "data.columns  = ['title','detail']\n",
    "detail_list = [i for i in data['detail']]\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "tokenizer = Tokenizer(nlp.vocab)\n",
    "all_tokens = []\n",
    "tokens = []\n",
    "for doc in tokenizer.pipe(data['detail']):\n",
    "    tokens = []\n",
    "    for token in doc:\n",
    "        if (token.is_stop == False) & (token.is_punct == False):\n",
    "            doc_tokens = re.sub(r\"[^a-z]\", \"\", token.text.lower().strip())\n",
    "            tokens.append(ps.stem(doc_tokens))\n",
    "        \n",
    "    all_tokens.append([i for i in tokens if (i!='') and (len(i)>2)])\n",
    "\n",
    "data['detail_tokens'] = all_tokens\n",
    "\n",
    "\n",
    "all_tokens = []\n",
    "tokens = []\n",
    "for doc in tokenizer.pipe(data['title']):\n",
    "    tokens = []\n",
    "    for token in doc:\n",
    "        if (token.is_stop == False) & (token.is_punct == False):\n",
    "            doc_tokens = re.sub(r\"[^a-z]\", \"\", token.text.lower().strip())\n",
    "            tokens.append(doc_tokens)\n",
    "        \n",
    "    all_tokens.append([i for i in tokens if (i!='') and (len(i)>2)])\n",
    "\n",
    "data['title_tokens'] = all_tokens\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='rank', ylabel='cul_percent'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "\n",
    "def word_count(docs):\n",
    "    word_counts = Counter()\n",
    "    word_in_docs = Counter()\n",
    "\n",
    "    total_docs = len(docs)\n",
    "\n",
    "    for doc in docs:\n",
    "        word_counts.update(doc)\n",
    "        word_in_docs.update(set(doc))\n",
    "    temp = zip(word_counts.keys(), word_counts.values())\n",
    "\n",
    "    wc = pd.DataFrame(temp, columns = ['word', 'count'])\n",
    "\n",
    "    wc['rank'] = wc['count'].rank(method='first', ascending=False)\n",
    "    total = wc['count'].sum()\n",
    "\n",
    "    wc['percent'] = wc['count'].apply(lambda x: x / total)\n",
    "\n",
    "    wc = wc.sort_values(by='rank')\n",
    "    wc['cul_percent'] = wc['percent'].cumsum()\n",
    "\n",
    "    temp2 = zip(word_in_docs.keys(), word_in_docs.values())\n",
    "    ac = pd.DataFrame(temp2, columns=['word', 'word_in_docs'])\n",
    "    wc = ac.merge(wc, on='word')\n",
    "\n",
    "    wc['word_in_docs_percent'] = wc['word_in_docs'].apply(lambda x: x / total_docs)\n",
    "\n",
    "    return wc.sort_values(by='rank')\n",
    "\n",
    "\n",
    "wc = word_count(data['detail_tokens'])\n",
    "wc = wc[wc['word_in_docs_percent'] >= 0.01]\n",
    "wc.head(10)\n",
    "sns.lineplot(x='rank', y='cul_percent', data=wc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x240fd18d7f0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.displot(wc['count'],kind='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>detail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>primer bertology know bert works</td>\n",
       "      <td>aprimerinbertologywhatweknowabouthowbertwork a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sensitivity analysis and practitioners guide c...</td>\n",
       "      <td>sensit analysi and practition guid convolut ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>attention based models speech recognition</td>\n",
       "      <td>attentionbas model speech recognit jan chorows...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>attention need</td>\n",
       "      <td>attent need ashish vaswani googl brain avaswan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bag tricks efficient text classification</td>\n",
       "      <td>arxivv cscl aug bagoftricksforefcienttextclass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bigself supervised models strong semi supervis...</td>\n",
       "      <td>big selfsupervis model strong semisupervis lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>birch efficient data clustering method large d...</td>\n",
       "      <td>birch effici data cluster method larg databas ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>characterlevel convolutional networks text cla...</td>\n",
       "      <td>characterlevel convolut network text classic x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>deep residual learning image recognition</td>\n",
       "      <td>deepresiduallearningfor imagerecognit kaimingh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>efficient convolutional neural networks mobile...</td>\n",
       "      <td>mobilenet efcient convolut neural network mobi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>exploring limits transfer learning unified tex...</td>\n",
       "      <td>journal machin learn research subm revis publi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fast rcnn</td>\n",
       "      <td>fastrcnn rossgirshick microsoftresearch rbgmic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>faster rcnn real time object detection region ...</td>\n",
       "      <td>faster rcnn realtim object detect region propo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>feature pyramid networks object detection</td>\n",
       "      <td>featurepyramidnetworksforobjectdetect tsungyil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>focal loss dense object detection</td>\n",
       "      <td>focallossfordenseobjectdetect tsungyilinpriyag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>generalized autoregressive pretraining languag...</td>\n",
       "      <td>xlnet gener autoregress pretrain languag under...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>graph attention networks</td>\n",
       "      <td>publish confer paper iclr raph petar veli ckov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>hierarchical attention networks document class...</td>\n",
       "      <td>proceed naaclhlt page san diego california jun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>imagenet classification deep convolutional neu...</td>\n",
       "      <td>imagenet classic deep convolut neural network ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>language models fewshot learners</td>\n",
       "      <td>languag model fewshot learner tom brown benjam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>language models unsupervised multitask learners</td>\n",
       "      <td>languag model unsupervis multitask learner ale...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>learning pharase representaton rnn encoderdeco...</td>\n",
       "      <td>learn phrase represent rnn encoderdecod statis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>learning transferable visual models natural la...</td>\n",
       "      <td>learn transfer visual model natur languag supe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>mask rcnn</td>\n",
       "      <td>maskrcnn kaiminghegeorgia gkioxaripiotrdol ros...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>neural image caption generation visual attention</td>\n",
       "      <td>show attend tell neural imag caption gener vis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>nonlocal neural networks</td>\n",
       "      <td>nonlocalneuralnetwork xiaolongwang rossgirshic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>dangers stochastic parrots language models big</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>pretraining deep bidirectional transformers la...</td>\n",
       "      <td>bert pretrain deep bidirect transform languag ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>recurrent neural network regularization</td>\n",
       "      <td>arxivv csne feb underreviewasaconferencepapera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>roberta robustly optimized bert pretraining ap...</td>\n",
       "      <td>arxivv cscl jul robertaarobustlyoptimizedbertp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>sequence sequence learning neural networks</td>\n",
       "      <td>sequencetosequencelearn withneuralnetwork ilya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>squeeze excitation networks</td>\n",
       "      <td>squeezeandexcitationnetwork jiehu lishen gangs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>transformer transformer</td>\n",
       "      <td>transform transform kai han xiao enhua jianyua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>yolo better faster stronger</td>\n",
       "      <td>yolo betterfasterstrong joseph redmon alifarha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>yolov incremental improvement</td>\n",
       "      <td>yolov increment improv joseph redmon ali farha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>look unified realtime object detection</td>\n",
       "      <td>youonlylookonc uniedrealtimeobjectdetect josep...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0                    primer bertology know bert works   \n",
       "1   sensitivity analysis and practitioners guide c...   \n",
       "2           attention based models speech recognition   \n",
       "3                                      attention need   \n",
       "4            bag tricks efficient text classification   \n",
       "5   bigself supervised models strong semi supervis...   \n",
       "6   birch efficient data clustering method large d...   \n",
       "7   characterlevel convolutional networks text cla...   \n",
       "8            deep residual learning image recognition   \n",
       "9   efficient convolutional neural networks mobile...   \n",
       "10  exploring limits transfer learning unified tex...   \n",
       "11                                          fast rcnn   \n",
       "12  faster rcnn real time object detection region ...   \n",
       "13          feature pyramid networks object detection   \n",
       "14                  focal loss dense object detection   \n",
       "15  generalized autoregressive pretraining languag...   \n",
       "16                           graph attention networks   \n",
       "17  hierarchical attention networks document class...   \n",
       "18  imagenet classification deep convolutional neu...   \n",
       "19                   language models fewshot learners   \n",
       "20    language models unsupervised multitask learners   \n",
       "21  learning pharase representaton rnn encoderdeco...   \n",
       "22  learning transferable visual models natural la...   \n",
       "23                                          mask rcnn   \n",
       "24   neural image caption generation visual attention   \n",
       "25                           nonlocal neural networks   \n",
       "26     dangers stochastic parrots language models big   \n",
       "27  pretraining deep bidirectional transformers la...   \n",
       "28            recurrent neural network regularization   \n",
       "29  roberta robustly optimized bert pretraining ap...   \n",
       "30         sequence sequence learning neural networks   \n",
       "31                        squeeze excitation networks   \n",
       "32                            transformer transformer   \n",
       "33                        yolo better faster stronger   \n",
       "34                      yolov incremental improvement   \n",
       "35             look unified realtime object detection   \n",
       "\n",
       "                                               detail  \n",
       "0   aprimerinbertologywhatweknowabouthowbertwork a...  \n",
       "1   sensit analysi and practition guid convolut ne...  \n",
       "2   attentionbas model speech recognit jan chorows...  \n",
       "3   attent need ashish vaswani googl brain avaswan...  \n",
       "4   arxivv cscl aug bagoftricksforefcienttextclass...  \n",
       "5   big selfsupervis model strong semisupervis lea...  \n",
       "6   birch effici data cluster method larg databas ...  \n",
       "7   characterlevel convolut network text classic x...  \n",
       "8   deepresiduallearningfor imagerecognit kaimingh...  \n",
       "9   mobilenet efcient convolut neural network mobi...  \n",
       "10  journal machin learn research subm revis publi...  \n",
       "11  fastrcnn rossgirshick microsoftresearch rbgmic...  \n",
       "12  faster rcnn realtim object detect region propo...  \n",
       "13  featurepyramidnetworksforobjectdetect tsungyil...  \n",
       "14  focallossfordenseobjectdetect tsungyilinpriyag...  \n",
       "15  xlnet gener autoregress pretrain languag under...  \n",
       "16  publish confer paper iclr raph petar veli ckov...  \n",
       "17  proceed naaclhlt page san diego california jun...  \n",
       "18  imagenet classic deep convolut neural network ...  \n",
       "19  languag model fewshot learner tom brown benjam...  \n",
       "20  languag model unsupervis multitask learner ale...  \n",
       "21  learn phrase represent rnn encoderdecod statis...  \n",
       "22  learn transfer visual model natur languag supe...  \n",
       "23  maskrcnn kaiminghegeorgia gkioxaripiotrdol ros...  \n",
       "24  show attend tell neural imag caption gener vis...  \n",
       "25  nonlocalneuralnetwork xiaolongwang rossgirshic...  \n",
       "26                                                     \n",
       "27  bert pretrain deep bidirect transform languag ...  \n",
       "28  arxivv csne feb underreviewasaconferencepapera...  \n",
       "29  arxivv cscl jul robertaarobustlyoptimizedbertp...  \n",
       "30  sequencetosequencelearn withneuralnetwork ilya...  \n",
       "31  squeezeandexcitationnetwork jiehu lishen gangs...  \n",
       "32  transform transform kai han xiao enhua jianyua...  \n",
       "33  yolo betterfasterstrong joseph redmon alifarha...  \n",
       "34  yolov increment improv joseph redmon ali farha...  \n",
       "35  youonlylookonc uniedrealtimeobjectdetect josep...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newline = pd.DataFrame()\n",
    "detail = []\n",
    "title = []\n",
    "for line in data['detail_tokens']:\n",
    "    detail.append(' '.join(word for word in line))\n",
    "for line in data['title_tokens']:\n",
    "    title.append(' '.join(word for word in line))\n",
    "data['detail'] = detail\n",
    "data['title'] = title\n",
    "\n",
    "data = data.drop(['detail_tokens','title_tokens'],axis=1)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트의 최소 길이 : 0\n",
      "텍스트의 최대 길이 : 17043\n",
      "텍스트의 평균 길이 : 3091.3055555555557\n",
      "요약의 최소 길이 : 2\n",
      "요약의 최대 길이 : 10\n",
      "요약의 평균 길이 : 5.111111111111111\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_len = [len(s.split()) for s in data['detail']]\n",
    "summary_len = [len(s.split()) for s in data['title']]\n",
    "\n",
    "print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
    "print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
    "print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
    "print('요약의 최소 길이 : {}'.format(np.min(summary_len)))\n",
    "print('요약의 최대 길이 : {}'.format(np.max(summary_len)))\n",
    "print('요약의 평균 길이 : {}'.format(np.mean(summary_len)))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(summary_len)\n",
    "plt.title('title')\n",
    "plt.subplot(1,2,2)\n",
    "plt.boxplot(text_len)\n",
    "plt.title('detail')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.title('title')\n",
    "plt.hist(summary_len, bins=40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('detail')\n",
    "plt.hist(text_len, bins=40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "text_max_len = int(np.mean(text_len))\n",
    "summary_max_len = int(np.mean(summary_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>detail</th>\n",
       "      <th>decoder_input</th>\n",
       "      <th>decoder_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>primer bertology know bert works</td>\n",
       "      <td>aprimerinbertologywhatweknowabouthowbertwork a...</td>\n",
       "      <td>sostoken primer bertology know bert works</td>\n",
       "      <td>primer bertology know bert works eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sensitivity analysis and practitioners guide c...</td>\n",
       "      <td>sensit analysi and practition guid convolut ne...</td>\n",
       "      <td>sostoken sensitivity analysis and practitioner...</td>\n",
       "      <td>sensitivity analysis and practitioners guide c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>attention based models speech recognition</td>\n",
       "      <td>attentionbas model speech recognit jan chorows...</td>\n",
       "      <td>sostoken attention based models speech recogni...</td>\n",
       "      <td>attention based models speech recognition eost...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>attention need</td>\n",
       "      <td>attent need ashish vaswani googl brain avaswan...</td>\n",
       "      <td>sostoken attention need</td>\n",
       "      <td>attention need eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bag tricks efficient text classification</td>\n",
       "      <td>arxivv cscl aug bagoftricksforefcienttextclass...</td>\n",
       "      <td>sostoken bag tricks efficient text classification</td>\n",
       "      <td>bag tricks efficient text classification eostoken</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                   primer bertology know bert works   \n",
       "1  sensitivity analysis and practitioners guide c...   \n",
       "2          attention based models speech recognition   \n",
       "3                                     attention need   \n",
       "4           bag tricks efficient text classification   \n",
       "\n",
       "                                              detail  \\\n",
       "0  aprimerinbertologywhatweknowabouthowbertwork a...   \n",
       "1  sensit analysi and practition guid convolut ne...   \n",
       "2  attentionbas model speech recognit jan chorows...   \n",
       "3  attent need ashish vaswani googl brain avaswan...   \n",
       "4  arxivv cscl aug bagoftricksforefcienttextclass...   \n",
       "\n",
       "                                       decoder_input  \\\n",
       "0          sostoken primer bertology know bert works   \n",
       "1  sostoken sensitivity analysis and practitioner...   \n",
       "2  sostoken attention based models speech recogni...   \n",
       "3                            sostoken attention need   \n",
       "4  sostoken bag tricks efficient text classification   \n",
       "\n",
       "                                      decoder_target  \n",
       "0          primer bertology know bert works eostoken  \n",
       "1  sensitivity analysis and practitioners guide c...  \n",
       "2  attention based models speech recognition eost...  \n",
       "3                            attention need eostoken  \n",
       "4  bag tricks efficient text classification eostoken  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['decoder_input'] = data['title'].apply(lambda x : 'sostoken '+ x)\n",
    "data['decoder_target'] = data['title'].apply(lambda x : x + ' eostoken')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = np.array(data['detail'])\n",
    "decoder_input = np.array(data['decoder_input'])\n",
    "decoder_target = np.array(data['decoder_target'])\n",
    "\n",
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "n_of_val = int(len(encoder_input)*0.2)\n",
    "\n",
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 21194\n",
      "등장 빈도가 3번 이하인 희귀 단어의 수: 18578\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 2616\n",
      "단어 집합에서 희귀 단어의 비율: 87.65688402378031\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 28.184036879689057\n"
     ]
    }
   ],
   "source": [
    "# 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "src_tokenizer = Tokenizer()\n",
    "src_tokenizer.fit_on_texts(encoder_input_train)\n",
    "\n",
    "threshold = 4\n",
    "total_cnt = len(src_tokenizer.word_index)\n",
    "rare_cnt = 0 \n",
    "total_freq = 0\n",
    "rare_freq = 0\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in src_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab = 8000\n",
    "src_tokenizer = Tokenizer(num_words = src_vocab) \n",
    "src_tokenizer.fit_on_texts(encoder_input_train)\n",
    "\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train) \n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "\n",
    "tar_vocab = 2000\n",
    "tar_tokenizer = Tokenizer(num_words = tar_vocab) \n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "tar_tokenizer.fit_on_texts(decoder_target_train)\n",
    "\n",
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제할 훈련 데이터의 개수 : 0\n",
      "삭제할 테스트 데이터의 개수 : 0\n"
     ]
    }
   ],
   "source": [
    "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
    "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
    "print('삭제할 훈련 데이터의 개수 :',len(drop_train))\n",
    "print('삭제할 테스트 데이터의 개수 :',len(drop_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수 : 29\n",
      "훈련 레이블의 개수 : 29\n",
      "테스트 데이터의 개수 : 7\n",
      "테스트 레이블의 개수 : 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray. [function_base.py:5030]\n"
     ]
    }
   ],
   "source": [
    "encoder_input_train = np.delete(encoder_input_train, drop_train, axis=0)\n",
    "decoder_input_train = np.delete(decoder_input_train, drop_train, axis=0)\n",
    "decoder_target_train = np.delete(decoder_target_train, drop_train, axis=0)\n",
    "\n",
    "encoder_input_test = np.delete(encoder_input_test, drop_test, axis=0)\n",
    "decoder_input_test = np.delete(decoder_input_test, drop_test, axis=0)\n",
    "decoder_target_test = np.delete(decoder_target_test, drop_test, axis=0)\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :',len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :',len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :',len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "encoder_input_train = pad_sequences(encoder_input_train, maxlen = text_max_len, padding='post')\n",
    "encoder_input_test = pad_sequences(encoder_input_test, maxlen = text_max_len, padding='post')\n",
    "decoder_input_train = pad_sequences(decoder_input_train, maxlen = summary_max_len, padding='post')\n",
    "decoder_target_train = pad_sequences(decoder_target_train, maxlen = summary_max_len, padding='post')\n",
    "decoder_input_test = pad_sequences(decoder_input_test, maxlen = summary_max_len, padding='post')\n",
    "decoder_target_test = pad_sequences(decoder_target_test, maxlen = summary_max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from attention import AttentionLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 128\n",
    "hidden_size = 256\n",
    "\n",
    "# 인코더\n",
    "encoder_inputs = Input(shape=(text_max_len,))\n",
    "\n",
    "# 인코더의 임베딩 층\n",
    "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
    "\n",
    "# 인코더의 LSTM 1\n",
    "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4, recurrent_dropout = 0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "# 인코더의 LSTM 2\n",
    "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "# 인코더의 LSTM 3\n",
    "encoder_lstm3 = LSTM(hidden_size, return_state=True, return_sequences=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "# 디코더의 임베딩 층\n",
    "dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 디코더의 LSTM\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences = True, return_state = True, dropout = 0.4, recurrent_dropout=0.2)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state = [state_h, state_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 3091)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 3091, 128)    1024000     ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 3091, 256),  394240      ['embedding[0][0]']              \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, 3091, 256),  525312      ['lstm[0][0]']                   \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, None, 128)    256000      ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  [(None, 3091, 256),  525312      ['lstm_1[0][0]']                 \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)                  [(None, None, 256),  394240      ['embedding_1[0][0]',            \n",
      "                                 (None, 256),                     'lstm_2[0][1]',                 \n",
      "                                 (None, 256)]                     'lstm_2[0][2]']                 \n",
      "                                                                                                  \n",
      " attention_layer (AttentionLaye  ((None, None, 256),  131328     ['lstm_2[0][0]',                 \n",
      " r)                              (None, None, 3091)               'lstm_3[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concat_layer (Concatenate)     (None, None, 512)    0           ['lstm_3[0][0]',                 \n",
      "                                                                  'attention_layer[0][0]']        \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, None, 2000)   1026000     ['concat_layer[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,276,432\n",
      "Trainable params: 4,276,432\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 어텐션 층(어텐션 함수)\n",
    "attn_layer = AttentionLayer(name='attention_layer')\n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "# 어텐션의 결과와 디코더의 hidden state들을 연결\n",
    "decoder_concat_input = Concatenate(axis = -1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 1581s 1581s/step - loss: 7.6009 - val_loss: 7.5370\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 2022s 2022s/step - loss: 7.5367 - val_loss: 5.5397\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 2158s 2158s/step - loss: 5.7083 - val_loss: 4.0712\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 2171s 2171s/step - loss: 4.2027 - val_loss: 3.4404\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 2661s 2661s/step - loss: 3.7845 - val_loss: 3.4201\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 2724s 2724s/step - loss: 3.7058 - val_loss: 3.4265\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 2545s 2545s/step - loss: 3.7526 - val_loss: 3.1664\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 2885s 2885s/step - loss: 3.5561 - val_loss: 3.3097\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 3052s 3052s/step - loss: 3.5001 - val_loss: 3.1474\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 2953s 2953s/step - loss: 3.4928 - val_loss: 3.3683\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 3109s 3109s/step - loss: 3.4763 - val_loss: 3.0740\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 3125s 3125s/step - loss: 3.4966 - val_loss: 3.3150\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 3352s 3352s/step - loss: 3.3728 - val_loss: 3.0619\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 2827s 2827s/step - loss: 3.3519 - val_loss: 3.2843\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 2497s 2497s/step - loss: 3.2982 - val_loss: 3.0538\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 2558s 2558s/step - loss: 3.3083 - val_loss: 3.3019\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 2669s 2669s/step - loss: 3.2547 - val_loss: 3.0170\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 2678s 2678s/step - loss: 3.2758 - val_loss: 3.3195\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 2753s 2753s/step - loss: 3.2123 - val_loss: 3.0479\n",
      "Epoch 19: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 2)\n",
    "history = model.fit(x = [encoder_input_train, decoder_input_train], y = decoder_target_train, \\\n",
    "          validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "          batch_size = 256, callbacks=[es], epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_index_to_word = src_tokenizer.index_word # 원문 단어 집합에서 정수 -> 단어를 얻음\n",
    "tar_word_to_index = tar_tokenizer.word_index # 요약 단어 집합에서 단어 -> 정수를 얻음\n",
    "tar_index_to_word = tar_tokenizer.index_word # 요약 단어 집합에서 정수 -> 단어를 얻음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n",
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(hidden_size,))\n",
    "decoder_state_input_c = Input(shape=(hidden_size,))\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "# 어텐션 함수\n",
    "decoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_inf_concat) \n",
    "\n",
    "# 최종 디코더 모델\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "    \n",
    "     # <SOS>에 해당하는 토큰 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tar_word_to_index['sostoken']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition: # stop_condition이 True가 될 때까지 루프 반복\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = tar_index_to_word[sampled_token_index]\n",
    "\n",
    "        if(sampled_token!='eostoken'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        #  <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_token == 'eostoken'  or len(decoded_sentence.split()) >= (summary_max_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 길이가 1인 타겟 시퀀스를 업데이트\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 상태를 업데이트 합니다.\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2text(input_seq):\n",
    "    sentence=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            sentence = sentence + src_index_to_word[i]+' '\n",
    "    return sentence\n",
    "\n",
    "# 요약문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2summary(input_seq):\n",
    "    sentence=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=tar_word_to_index['sostoken']) and i!=tar_word_to_index['eostoken']):\n",
    "            sentence = sentence + tar_index_to_word[i] + ' '\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문 :  given exist translat model qualit analysi show rnn encoderdecod better captur lin guistic regular phrase tabl explain quantit improv overal translat perform anal ysi model rnn encod decod learn continu space represent phrase preserv semant syntact structur phrase arxivv cscl sep rnn encoderdecod preliminari recurr neural network recurr neural network rnn neural net work consist hidden state option output oper variabl length sequenc time step hidden state rnn updat nonlinear activ func tion simpl element logist sigmoid function com long shortterm memori lstm unit hochreit schmidhub rnn learn probabl distribut sequenc train predict symbol sequenc case output condit distribut exampl multinomi distribut code output softmax activ function exp exp possibl symbol row weight matrix combin probabl comput iti sequenc learn distribut ward sampl new sequenc iter sam symbol time step rnn encoderdecod paper propos novel neural network architectur learn encod variablelength sequenc xedlength vector represent decod given xedlength vector rep resent variablelength sequenc probabilist perspect new model gener method learn condit tribut variablelength sequenc tion variablelength sequenc figur illustr propos rnn encoderdecod note input output sequenc length differ encod rnn read symbol input sequenc sequenti read symbol hidden state rnn chang accord read end sequenc mark endofsequ sym bol hidden state rnn summari input sequenc decod propos model rnn train gener output predict symbol given hidden state howev unlik rnn scribe sec con dition summari input sequenc henc hidden state decod time comput similarli condit distribut symbol given activ function the produc valid probabl soft max fig graphic depict pro pose model architectur compon propos rnn encoderdecod jointli train maxim condit loglikelihood max log set model paramet input sequenc output pair train set case output decod start put use gradientbas algorithm estim model paramet rnn encoderdecod train model way way use model gener target sequenc given input sequenc hand model score given pair input output sequenc score simpli probabl hidden unit adapt rememb forget addit novel model architectur propos new type hidden unit motiv lstm unit simpler comput implement fig show graphic depict propos den unit let describ activ hidden unit comput first gate comput logist sigmoid function denot element vector input previou hidden state tive weight matric learn similarli updat gate comput actual activ propos unit comput formul gate close hidden state forc ignor pre hidden state current input lstm unit shown impress result applic speech recognit ori cell gate unit adapt control format insid unit compar gate unit propos hidden unit detail lstm net work see grave figur illustr propos hidden activ function updat gate select hidden state updat new hidden state gate decid previou hidden state ignor detail equat onli effect allow hidden state drop inform found irrelev later futur thu allow compact represent hand updat gate control inform previou hidden state carri current hidden state act similarli memori cell lstm network help rnn rememb long term inform furthermor con sider adapt variant unit bengio hidden unit separ date gate hidden unit learn captur depend differ time scale unit learn captur shortterm depend tend gate frequent tive captur updat gate activ preliminari experi found crucial use new unit gate unit abl meaning result tanh unit gate statist machin translat commonli statist machin translat system goal system decod specic translat given sourc sentenc maxim rst term right hand call translat model languag model see koehn practic howev system model log log linear model addit featur corr weight log log featur weight respect normal constant depend weight weight optim maxim bleu score develop set framework introduc koehn marcu translat model log factor translat probabl match phrase sourc target sentenc probabl consid addit featur loglinear model see weight maxim bleu score neural net languag model pro pose bengio neural network wide system case neural network translat hypothes best list see schwenk recent howev interest train neural network score translat sentenc phrase pair represent sourc sentenc addit input see schwenk son zou score phrase pair rnn encoderdecod propos train rnn encod decod see sec tabl phrase pair use score addit featur log linear model tune coder train rnn encoderdecod ignor normal frequenc phrase pair origin corpora measur taken order reduc comput randomli select phrase pair larg phrase tabl accord normal ensur rnn encod decod simpli learn rank phrase pair accord number underli reason choic exist translat probabl phrase ble reect frequenc phrase loss gener refer phrase pair translat model pair origin corpu xed capac rnn encoderdecod tri ensur capac model focus learn linguist regular guish plausibl tran lation learn manifold region prob abil concentr plausibl translat rnn encoderdecod train add new score phrase pair exist ing phrase tabl allow new score ter exist tune algorithm minim addit comput schwenk point schwenk possibl complet replac exist phrase tabl propos rnn encod decod case given sourc phrase rnn encoderdecod need gener list good target phrase requir how ever expens sampl procedur per form repeatedli paper thu consid phrase pair phrase tabl relat approach neural network machin translat present empir result discuss number recent work propos use neural network context schwenk schwenk propos simi lar approach score phrase pair instead neural network feedforward neural network xedsiz input word case zeropad shorter phrase xedsiz output word target lan guag specic score phrase system maximum phrase length chosen small howev length phrase increas appli neural network variablelength sequenc data import neural network han dle variablelength input output pro pose rnn encoderdecod wellsuit applic similar schwenk devlin devlin propos use ward neural network model translat model howev predict word target phrase time report impress improv ment approach requir length input phrase context word xed exactli neural network train author zou propos learn embed use learn embed comput distanc pair phrase addit score phrase pair system feedforward neural network train learn map bagofword represent input phrase output phrase close relat propos rnn encoderdecod model propos schwenk represent phrase bagofword similar approach bagofword repr sentat propos gao well earlier similar encoderdecod model ing recurs neural network propos socher model monolingu set model reconstruct input sentenc recent encoderdecod model rnn propos auli coder condit represent sourc sentenc sourc context import differ pro pose rnn encoderdecod approach zou order word sourc phrase taken account rnn encoderdecod natur distinguish sequenc word differ ent order aforement approach effect ignor order inform closest approach relat propos rnn encoderdecod recurr contin translat model model propos kalchbrenn blunsom per propos similar model consist encod decod differ model convolut gram model encod hybrid invers recurr neural network decod they howev evalu model best list propos convent system comput per plexiti standard translat experi evalu approach translat task wmt workshop data baselin system larg amount resourc avail build system framework wmt translat task corpora includ word news com crawl corpora word respect corpora noisi train french languag model word crawl materi avail addi tion target word count refer french word token commonli acknowledg train model concaten data necessarili lead optim per formanc result extrem larg mod difcult handl instead focu relev subset data given task appli data select method propos moor lewi extens text mean select subset word word languag model subset word train ing rnn encoderdecod test set data select weight tune test set set thousand word singl refer enc translat train neural network includ propos rnn encoderdecod limit sourc target vocabulari frequent word english french cover approxim dataset word map special token unk baselin system built default set tem achiev bleu score develop test set respect see ble rnn encoderdecod rnn encoderdecod experi ment hidden unit propos gate encod decod matrix input symbol hidden unit approxim matric output matrix approxim model bleu dev test baselin rnn rnn rnn tabl bleu score comput develop ment test set differ combin approach denot word penalti number unknown word neural network similarli rank matric equival learn embed dimens word activ function hyperbol tangent function com putat hidden state decod output implement deep neural net work pascanu singl layer have maxout unit pool input goodfellow weight paramet rnn encod decod initi sampl zeromean white gaussian distribut standard deviat xed recurr weight paramet current weight matric rst sampl white gaussian distribut left lar vector matrix follow adadelta stochast gradient descent train rnn encoderdecod hyperparamet zeiler updat randomli select phrase pair phrase ble which creat word model train approxim day detail architectur experi ment explain depth materi neural languag model order assess effect score phrase pair propos rnn encod decod tri tradit approach neural network learn target languag model schwenk comparison system propos approach phrase score rnn encoderdecod clarifi contribut multipl neural network differ part tem add redund train model gram target corpu input word project embed space concaten form dimension vector concaten vector fed recti layer size glorot output layer simpl softmax layer see weight paramet initi uniformli model train valid perplex improv epoch train languag model achiev perplex valid set random select corpu model score partial translat dur ing decod process gener lead higher gain bleu score list ing vaswani address comput complex decod buffer aggreg ngram stack search perform decod buffer full stack prune ngram score allow perform fast matrix matrix multipl gpu theano bergstra bastien figur visual phrase pair accord ing score logprob rnn encoderdecod translat model quantit analysi tri follow combin baselin congur baselin rnn baselin rnn baselin rnn word penalti sourc translat model rnn encoderdecod end ann sup rst time pour pour pour pour pour pour que unit state uni que que que que plu plu plu long frequent sourc phrase sourc translat model rnn encoderdecod minist tran commun tran commun commun tran commun respect respect part world gion con consid past day petit text jour jour jour jour jour satur day long rare sourc phrase tabl score target phrase small set sourc phrase accord translat model direct translat probabl rnn encoderdecod sourc phrase randomli select phrase word denot partial charact letter result present tabl pect featur comput neural net work consist improv perform baselin perform best perform achiev phrase score rnn encoderdecod suggest contribut rnn encod decod correl expect better result improv method depend furthermor tri number word unknown neural network word short list simpli number unknown word addit featur log linear model howev case understand effect penalti consid set word larg word replac special token unk score neural network henc condit probabl actual given model unk abl achiev better perform test set develop set qualit analysi order understand perform come from analyz phrase pair score comput rnn encoderdecod correspond tran lation model exist translat model reli sole statist phrase pair corpu expect score better mate frequent phrase estim rare phrase also mention earlier sec expect rnn encod decod train frequenc inform score phrase pair base linguist regular statist corpu focu pair sourc phrase long more word sourc phrase result probabl word overestim possibl address issu back exist model contain word see schwenk paper howev introduc word penalti instead word probabl overestim sourc sampl rnn encoderdecod end rst time pour pour que unit state dan que que unk plu une plu long frequent sourc phrase sourc sampl rnn encoderdecod minist tion commun respect respect part world art art past day quelqu jour jour jour long rare sourc phrase tabl sampl gener rnn encoderdecod sourc phrase tabl top target phrase sampl sort rnn encoderdecod score figur embed learn word represent left show embed space right show view region plot supplementari materi frequent sourc phrase look target phrase score high translat probabl rnn encoderdecod similarli per form procedur pair sourc phrase long rare corpu tabl list top target phrase sourc phrase favor translat model rnn encoderdecod sourc phrase randomli chosen long one have word case choic target phrase rnn encoderdecod closer liter translat observ rnn encoderdecod prefer shorter phrase gener phrase pair score similarli translat model rnn encoderdecod phrase pair score dif ferent see fig aris propos approach train rnn encod decod set uniqu phrase pair age rnn encoderdecod learn simpli frequenc phrase pair corpu explain earlier furthermor tabl sourc phrase tabl gener sam ple rnn encoderdecod sourc phrase gener sampl phrase score rnn encoderdecod abl propos target phrase with look actual phrase tabl gener phrase overlap complet target phrase phrase tabl encourag investig possibl replac phrase tabl figur embed learn phrase represent left show represen tation space randomli select point gure view specic region propos rnn encoderdecod futur word phrase represent propos rnn encoderdecod specic design task machin translat briey look properti train model known time continu space languag model neural network abl learn meaning embed see bengio mikolov propos rnn encoderdecod project map sequenc word continu space vector expect similar properti propos model well left plot fig show embed word word embed matrix learn rnn encoderdecod pro recent propos van der maaten clearli semant similar word cluster see plot fig propos rnn encoderdecod natur gener represent phrase represent fig case dimension vector similarli word represent visual representa tion phrase consist word fig visual clear rnn encoderdecod captur semant syn tactic structur phrase instanc plot phrase time phrase syntact similar cluster togeth plot show cluster phrase semant similar countri region hand plot show phrase syntact similar conclus paper propos new neural network architectur call rnn encoderdecod abl learn map sequenc arbitrari length sequenc differ set arbitrari length propos rnn encoderdecod abl score pair sequenc term condit probabl gener target sequenc given sourc sequenc new architectur propos novel hidden unit includ set gate updat gate adapt control hidden unit rememb forget sequenc evalu propos model task statist machin translat rnn encoderdecod score phrase pair phrase tabl qualit abl new model abl cap ture linguist regular phrase pair rnn encoderdecod abl propos target phrase score rnn encoderdecod found improv overal translat perfor manc term bleu score also found contribut rnn encod decod exist proach neural network tem improv perfor manc use instanc rnn encod decod neural net languag model qualit analysi train model show captur linguist multipl level word level phrase level suggest natur languag relat applic benet propos rnn encod decod propos architectur larg potenti improv analysi proach investig place phrase tabl let rnn encoderdecod propos target phrase also note propos model limit written languag import futur research appli propos architectur applic speech acknowledg like thank nserc calcul ebec comput canada canada research chair cifar partial fund european sion project project refer auli michael auli michel chri geoffrey joint languag translat model recurr neural net work proceed acl confer empir method natur languag process emnlp page xiaodong jianfeng gao domain adapt pseudo indomain data select proceed acl confer empir method natu ral languag process emnlp page bastien eric bastien pascal lamblin razvan pascanu jame bergstra ian goodfellow nicola yoshua bengio theano new featur speed deep learn unsupervis fea ture learn nip workshop bengio yoshua bengio ejean ducharm pascal vincent christian janvin neu ral probabilist languag model mach learn march bengio bengio pascanu advanc optim recurr network proceed intern confer acoust speech signal process icassp may bergstra jame bergstra olivi breuleux eric bastien pascal lamblin razvan pascanu guillaum desjardin joseph david ward yoshua bengio theano cpu gpu math express compil proceed python scientic comput confer scipi june present hugo larochel vika approach learn word repr sentat arxiv cscl ari dahl dahl dong deng alex pre train deep neural network larg vocabulari speech recognit ieee transact audio speech languag process devlin jacob devlin huang thoma richard schwartz john fast robust neural network joint model statist machin translat proceed acl confer acl page gao jianfeng gao xiaodong deng learn semant repr sentat phrase translat model cal report microsoft research glorot glorot bord ben gio deep spars rectier neural network aistat goodfellow ian goodfellow david wardefarley mehdi mirza aaron courvil yoshua bengio maxout network icml grave alex grave supervis label recurr neural network studi comput intellig springer hochreit schmidhub hochreit schmidhub long shortterm memori neural comput kalchbrenn blunsom nal kalchbrenn phil blunsom recurr continu translat model proceed acl con ferenc empir method natur languag process emnlp page koehn koehn daniel marcu statist translat proceed confer north american chapter associ comput linguist human languag technolog volum page koehn koehn parallel cor statist machin translat machin translat page land krizhevski alex krizhevski ilya sutskev geoffrey hinton genet classic deep convolut neural network advanc neural inform process system nip marcu daniel marcu william joint probabl model statist machin translat pro ceed acl confer empir method natur languag process volum emnlp page mikolov toma mikolov ilya sutskev kai chen greg corrado jeff dean tribut represent word phrase composition advanc neural infor mation process system page moor lewi robert moor william lewi intellig select languag model train data proceed acl confer short paper page usa pascanu pascanu gulcehr cho bengio construct deep recur neural network proceed second intern confer learn representa tion iclr april andrew jame land exact solut nonlinear dynam learn deep lin ear neural network proceed second intern confer learn representa tion iclr april schwenk schwenk continu space languag model task page schwenk schwenk continu space languag model comput speech lang juli schwenk schwenk continu space translat model cal machin translat martin chri tian editor proceed inter nation confer comput linguist colin page socher richard socher eric huang pennington andrew christoph man dynam pool recurs autoencod detect advanc neural inform process system son son alexandr franc continu space tion model neural network proceed confer north american ter associ comput linguist human languag technolog page usa van der maaten lauren van der maaten proceed inter nation confer learn represent iclr may vaswani ashish vaswani zhao david code largescal neural languag model prove translat proceed confer empir method natur languag pro cess page zeiler matthew zeiler adadelta adapt learn rate method technic report arxiv zou zou richard socher daniel christoph man word emb ding machin translat proceed acl confer empir method natur languag process emnlp page rnn encoderdecod document describ detail architectur rnn encoderdecod exper iment let denot sourc phrase target phrase phrase sequenc dimension onehot vector element vector index activ element indic word repres vector encod word sourc phrase embed dimension vector space sec visual word hidden state encod consist hidden unit time comput tanh logist sigmoid function elementwis multipl respect equat omit bias initi hidden state xed hidden state step the end sourc phrase comput represent sourc phrase tanh decod decod start initi hidden state tanh use distinguish paramet decod encod hidden state time decod comput tanh allzero vector similarli case encod embed target word unlik encod simpli encod sourc phrase decod learn gener target phrase time decod comput probabl gener word exp exp element max short maxout unit comput efcienc instead output weight use product matric word phrase represent here enlarg plot word phrase represent fig figur embed learn word represent left show embed space gure view specic region figur embed learn phrase represent left show represent space randomli select point gure view specic region \n",
      "실제 요약문 : learning \n",
      "예측 요약문 :  models networks\n",
      "\n",
      "\n",
      "원문 :  news cess exampl ection provid exampl data set con cola origin sentenc john master pro cess input cola sentenc john master origin target pro cess target accept rte origin sentenc smaller proport nation sentenc pro cess input rte sentenc smaller proport nation sentenc origin target pro cess target mnli origin won lose mean origin lose team pro cess input mnli hypothesi won lose mean origin lose team raffel shazeer robert lee narang matena zhou liu origin target pro cess target contradict mrpc origin sentenc act saw exist evid new light experi septemb said sentenc act saw exist evid new light experi septemb pro cess input mrpc sentenc act saw exist evid new light experi septemb said sentenc act saw exist evid new light experi septemb origin target pro cess target equival qnli origin question die sentenc recal soon die road pro cess input qnli question die sentenc recal soon die road origin target pro cess target entail qqp origin question attribut highli desir question compani pro cess input qqp question attribut highli desir question compani explor limit transfer learn origin target pro cess target sst origin sentenc art technic servic insight pro cess input sst sentenc art technic servic insight origin target pro cess target posit stsb origin sentenc repres immedi reach comment sentenc repres locat comment suit pro cess input stsb sentenc repres immedi reach comment sentenc repres locat comment suit origin target pro cess target origin help couldnt choos portion titan think help pro cess input hypothesi help couldnt choos portion titan think help origin target pro cess target contradict raffel shazeer robert lee narang matena zhou liu copa origin question effect nation choic citizen choic citizen took pro cess input copa choic citizen choic citizen took nation question effect origin target pro cess target true multi origin answer tradit food paragraph time name love outsid play jimmi play game togeth bone day jimmi went juli earli food couldnt find ate jimmi went way saw friend jack water sun out jimmi got water start got jimmi favorit blue shirt red green ate food went question surpris pro cess input multirc question surpris answer tradit food paragraph time name love outsid play jimmi play game togeth bone day jimmi went explor limit transfer learn juli earli food couldnt find ate jimmi went way saw friend jack water sun out jimmi got water start got jimmi favorit blue shirt red green ate food went origin target pro cess target true wic origin sentenc deliber act sentenc deliber word deliber pro cess input wic sentenc deliber act sentenc deliber word deliber origin target pro cess target fals wsc origin span text span text stabl span index span index text stabl good larg window open pro cess input wsc stabl good larg window open raffel shazeer robert lee narang matena zhou liu origin target pro cess target stabl mail origin continu world best mate unit post pictur night ahead game pose middl friend look like fail receiv theme night premier pose friend floor unit good friend unit run celebr goal friend effect background add theori mind later pose floor friend unit reason song hit form releas howev leav manag van continu spot van celebr unit fan receiv word unit manag van friend floor ahead game pro cess input summar continu world best mate unit post pictur night ahead game pose middl friend look like fail receiv theme night premier pose friend floor unit good friend unit run celebr goal friend effect background add theori mind later pose floor friend unit reason song hit form releas howev leav manag van continu spot van celebr unit fan receiv word explor limit transfer learn unit manag van friend floor ahead game origin target took floor night friend unit face premier red look second away win seven van current sit point clear fourth pro cess target took floor night friend unit face premier red look second away win seven van current sit point clear fourth squad origin question increas concentr context use special increas partial and need medic the treat increas concentr help group caus increas partial help kill them occur quickli dive result bubbl form increas soon possibl treatment pro cess input question increas concentr context use special increas partial and need medic the treat increas concentr help group caus increas partial help kill them occur quickli dive result bubbl form increas soon possibl treatment raffel shazeer robert lee narang matena zhou liu origin target pro cess target wmt english german origin said want end wrote pro cess input translat english german said want end wrote origin target oft die pro cess target oft die wmt english french origin imag section record show famili gener star oldest star seen blue dot identifi star room pro cess input translat english french imag section record show famili gener star oldest star seen blue dot identifi star room origin target dune prise par montr plu bleu point rose plu identifi dan pro cess target dune prise par montr plu bleu point rose plu identifi dan wmt english origin bell said plan add locat pro cess input translat english bell said plan add locat origin target bell intent explor limit transfer learn pro cess target bell intent raffel shazeer robert lee narang matena zhou liu score task exp tabl list score achiev task exp describ section glue sup wmt score cola sst mrpc mrpc stsb stsb qqp qqp mnli mnli qnli rte squad score copa multirc multirc record record rte wic wsc end enro tabl exp averag acc acc acc acc acc acc acc averag acc acc acc acc acc acc bleu bleu bleu baselin averag baselin standard deviat pretrain denois share denois layer denois languag del denois denois share layer languag del languag devlin devlin song replac corrupt span drop corrupt token corrupt rate corrupt rate corrupt rate corrupt rate baselin averag span length averag span length averag span length averag span length unlter data set rep rep rep rep paramet adapt layer adapt layer adapt layer adapt layer baselin pretrainnetun equal unsup pretrain netun multitask train multitask pretrain netun multitask train sup multitask pretrain baselin size train step size batch size size train step size train step ensembl ensembl netun tabl score achiev task consid exp rst column list tabl condens result present given exp main text row mark denot baselin del section raffel shazeer robert lee narang matena zhou liu refer rami alrfou cho noah constant llion jone characterlevel languag deep selfattent proceed aaai confer artici gupta koren adapt optim largescal learn arxiv preprint arxiv firat john son maxim chen yuan colin cherri multi neural machin translat wild find challeng arxiv preprint arxiv jimmi lei jami ryan kiro hinton layer normal arxiv preprint arxiv alexei sergey edunov yinhan liu luke zettlemoy michael auli cloze driven pretrain selfattent network arxiv preprint arxiv dzmitri bahdanau kyunghyun cho bengio neural machin translat jointli learn align translat intern confer learn represent firat simpl scalabl adapt neural machin translat arxiv preprint arxiv pretrain languag del scientic text proceed confer empir method natur languag process intern joint confer natur languag process emnlpijcnlp christian christian barri haddow level pavel matt post herv find workshop statist machin translat proceed workshop statist machin translat christian barri haddow chri find workshop statist machin translat proceed tenth workshop statist machin translat chri tian barri haddow antonio find con ferenc machin translat proceed confer machin translat samuel bowman luke oriol vinyal andrew dai jozefowicz sami bengio gener sentenc continu space arxiv preprint arxiv explor limit transfer learn christian van ngram count languag del common crawl rich multitask learn machin learn daniel agirr task semant textual evalu ation arxiv preprint arxiv dong mirella lapata long shortterm machin read arxiv preprint arxiv christoph clark kenton lee min chang tom michael collin kristina toutanova exp surpris natur question arxiv preprint arxiv kevin clark minhthang luong christoph man pretrain text der discrimin gener arxiv preprint arxiv conneau kiela evalu sentenc represent arxiv preprint arxiv conneau kiela schwenk bord sup vise learn univers sentenc represent natur lan guag infer data arxiv preprint arxiv oren pascal textual entail challeng machin learn chal leng workshop andrew dai sequenc learn advanc neural inform process system simon investig pro natur discours jia deng wei dong richard kai feifei imagenet largescal hierarch imag databas ieee confer comput vision pattern recognit jacob devlin mingwei kenton lee kristina toutanova bert pre train deep bidirect transform langu age understand arxiv preprint arxiv william chri automat construct corpu phrase proceed intern workshop dong yang wang wei xiao dong liu wang jianfeng gao zhou hon languag del pretrain natur languag understand gener arxiv preprint arxiv raffel shazeer robert lee narang matena zhou liu sergey edunov myle ott michael auli david grangier understand ing backtransl scale arxiv preprint arxiv grave piotr gupta joulin toma mikolov learn word vector languag arxiv preprint arxiv alex grave gener sequenc recurr neural network arxiv preprint arxiv multilingu corpu free licens proceed tenth intern confer languag resourc evalu page kaim xiangyu zhang ren jian sun deep residu learn imag recognit proceed ieee confer comput vision pattern recognit kaim ross girshick piotr dollr rethink imagenet pretrain arxiv preprint arxiv xiao dong liu weizhu chen jianfeng gao hybrid neural network del reason arxiv preprint arxiv hermann toma edward grefenstett phil blunsom machin read advanc neural inform process system hest sharan narang newsha ardalani gregori diamo jun hassan kianinejad mostofa ali patwari yang yang yanqi zhou deep learn scale predict empir arxiv preprint arxiv felix hill kyunghyun cho learn distribut represent sentenc ell data arxiv preprint arxiv hinton oriol vinyal dean distil knowledg neural network arxiv preprint arxiv neil bruna andrea gelli transfer learn nlp arxiv preprint arxiv howard sebastian ruder univers languag del netun text classi cation arxiv preprint arxiv huang ashish vaswani jakob uszkoreit ian simon noam shazeer andrew dai matthew transform gener longterm structur seventh intern confer learn represent explor limit transfer learn huang yonglong cheng chen ong lee chen train neural network parallel arxiv preprint arxiv alexei efro make imagenet transfer learn arxiv preprint arxiv shankar dataset releas question pair dataset releas question pair yangq jia shelham donahu sergey jonathan long ross girshick sergio trevor darrel convolut architectur fast featur emb proceed acm int confer xiao yin hang xin jiang xiao chen fan wang liu distil bert natur langu age understand arxiv preprint arxiv mandar joshi choi daniel luke zettlemoy triviaqa larg scale sup challeng dataset read comprehens arxiv preprint arxiv mandar joshi danqi chen yin han liu daniel luke zettlemoy omer levi improv pretrain repres predict span arxiv preprint arxiv jozefowicz oriol vinyal mike schuster noam shazeer explor limit languag arxiv preprint arxiv nal kalchbrenn edward grefenstett phil blunsom convolut neural network proceed annual meet associ comput linguist nitish keskar bryan mccann caim xiong richard con dition transform languag del control gener arxiv preprint arxiv nitish keskar bryan caim xiong richard unifi question answer text classic span extract arxiv preprint arxiv daniel michael roth shyam dan roth surfac challeng set comprehens multipl sentenc proceed north american chapter associ comput linguist raffel shazeer robert lee narang matena zhou liu ryan kiro yukun zhu ruslan salakhutdinov richard zemel raquel urtasun antonio torralba sanja fidler skipthought vector advanc neural inform process system vid thoma surprisingli robust trick winograd schema challeng arxiv preprint arxiv daniel tribut optim arxiv preprint arxiv felix peter learn strategi improv commun arxiv preprint arxiv simon kornblith jonathon shlen imagenet del transfer arxiv preprint arxiv alex krizhevski weird trick parallel convolut neural network arxiv preprint arxiv subword regular neural network translat del multipl subword ate arxiv preprint arxiv john sentencepiec simpl languag sub word token detoken neural text pro cess arxiv preprint arxiv guillaum lampl conneau languag del pretrain arxiv preprint arxiv zhenzhong lan mingda chen sebastian kevin piyush sharma radu soricut albert lite bert learn languag representa tion arxiv preprint arxiv levesqu davi win schema thirteenth intern confer principl know represent reason literatur survey domain adapt algorithm natur langu age pro cess lin roug packag automat evalu summari text summar branch peter liu mohammad saleh pot ben ryan lukasz kaiser noam shazeer gener summar long sequenc arxiv preprint arxiv peter liu yuan jie ren summa zeroshot abstract text summar length agnost der arxiv preprint arxiv explor limit transfer learn xiao dong liu jianfeng gao xiao dong deng kevin wang rep resent learn multitask deep neural network semant class inform retriev proceed confer north american chapter associ comput linguist human languag technolog xiao dong liu pengcheng weizhu chen jianfeng gao multitask deep neural network natur lan guag understand arxiv preprint arxiv yang liu finetun bert extract summar arxiv preprint arxiv yinhan liu myle ott naman goyal mandar joshi danqi chen omer levi mike lewi luke zettlemoy veselin stoyanov roberta robustli bert pretrain approach arxiv preprint arxiv honglak lee framework learn sentenc represent arxiv preprint arxiv dhruv jan ross girshick ramanathan manohar paluri bharamb lauren van der maaten explor limit weakli sup pretrain proceed european confer comput vision eccv bryan mccann nitish keskar caim xiong richard languag decathlon multitask learn question were arxiv preprint arxiv toma mikolov kai chen greg dean estim word represent vector space arxiv preprint arxiv toma mikolov ilya sutskev kai chen greg corrado dean distribut represent word phrase comp advanc neural inform process system ramesh nallapati bowen zhou santo caglar gulcehr bing xiang abstract text sequencetosequ rnn arxiv preprint arxiv maxim bottou laptev sivic learn transfer midlevel imag represent convolut neural network proceed ieee confer comput vision pattern recognit ward zhu bleu automat evalu machin translat proceed annual meet associ comput linguist comput lin guistic caim xiong richard deep reinforc del summar arxiv preprint arxiv raffel shazeer robert lee narang matena zhou liu pennington richard christoph man glove global vector word represent proceed confer empir method natur languag process emnlp matthew peter sebastian ruder noah smith tune tune adapt pretrain represent divers task arxiv preprint arxiv matthew peter mark neumann mohit iyyer matt gardner christoph clark kenton lee luke zettlemoy deep contextu word represent arxiv preprint arxiv jason hang samuel bowman sentenc der sup train intermedi lab task arxiv preprint arxiv mohammad wic exampl pair evalu rep resent arxiv preprint arxiv matt post clariti rep bleu score arxiv preprint arxiv alec radford karthik narasimhan tim saliman ilya sutskev improv languag understand gener pretrain alec radford rewon child david luan dario ilya languag del unsup multitask learner vincent resolv complex case denit pronoun winograd schema challeng proceed joint confer empir method natur languag process comput natur languag learn comput linguist pranav jian zhang konstantin perci liang squad question machin comprehens text arxiv preprint arxiv ramachandran peter liu unsup pretrain sequenc sequenc learn arxiv preprint arxiv alex jare christoph snorkel weak sup multitask learn proceed second workshop data manag endtoend machin learn andrew gordon choic plausibl altern evalu commonsens reason aaai spring symposium seri sebastian ruder overview multitask learn deep neural network arxiv preprint arxiv sebastian ruder neural transfer earn natur languag process thesi explor limit transfer learn sebastian ruder matthew peter thoma wolf transfer learn natur languag pro cess proceed confer north american chapter associ comput linguist page olga russakovski jia deng hao jonathan kraus sanjeev satheesh sean zhiheng huang andrej karpathi aditya khosla michael bernstein imagenet larg scale visual recognit challeng intern journal comput vision victor san chaumond thoma wolf distil ion bert faster arxiv preprint arxiv see peter liu christoph man summar network arxiv preprint arxiv sennrich barri haddow birch neural machin translat rare word subword unit arxiv preprint arxiv christoph lee roy dahl measur data parallel neural network train arxiv preprint arxiv peter jakob uszkoreit vaswani selfattent rel represent arxiv preprint arxiv noam shazeer mitchel adapt learn rate memori cost arxiv preprint arxiv noam shazeer andi davi hinton dean larg neural network pars gate ert layer arxiv preprint arxiv noam shazeer youlong cheng niki parmar tran ashish vaswani pen peter ong lee cli young ryan deep learn sup advanc neural inform process system jason smith herv chri adam webscal parallel text common crawl proceed annual meet associ comput linguist richard alex perelygin jean jason chuang christoph man andrew christoph pott recurs del semant comp sentiment treebank proceed confer empir method natur languag process kaitao ong tan tao qin jian feng tieyan liu mass mask sequenc sequenc pretrain languag gener arxiv preprint arxiv raffel shazeer robert lee narang matena zhou liu nitish srivastava hinton alex krizhevski ilya ruslan nov drop out simpl way prevent neural network overt journal machin learn research subramanian adam trischler yoshua bengio christoph pal learn gener distribut sentenc represent larg scale multitask learn arxiv preprint arxiv ilya sutskev oriol vinyal sequenc sequenc learn neural network advanc neural inform process system richard lesson wilson taylor cloze pro cedur new measur journal trinh simpl commonsens reason arxiv preprint arxiv adam tong wang yuan harri philip bachman machin comp ion data arxiv preprint arxiv ashish vaswani noam shazeer niki parmar jakob uszkoreit llion jone aidan gomez ukasz kaiser illia attent need advanc neural inform process system elena sennrich evolut represent tran studi machin translat languag arxiv preprint arxiv alex singh julian michael felix hill omer levi samuel bowman glue multitask analysi platform natur languag understand arxiv preprint arxiv alex wang jan patrick xia thoma mccoy kim ian huang katherin tell past sentencelevel pretrain languag proceed annual meet associ comput linguist alex wang amanpreet singh julian michael felix hill omer levi samuel bowman sup gener languag understand system arxiv preprint arxiv wei wang yan peng luo languag structur pretrain deep languag understand arxiv preprint arxiv explor limit transfer learn alex war amanpreet sin samuel bowman neural network accept arxiv preprint arxiv william bowman challeng corpu sentenc understand infer arxiv preprint arxiv ronald william david learn algorithm continu run fulli recurr neural network neural comput mike schuster chen mohammad norouzi maxim qin gao mach neural machin translat system bridg gap human machin translat arxiv preprint arxiv zhilin yang zihang dai yime yang jaim ruslan salakhutdinov xlnet gener sive pretrain languag understand arxiv preprint arxiv jason yoshua bengio transfer featur deep neural network advanc neural inform process system adam wei david min luong zhao kai chen mohammad norouzi combin cal convolut global selfattent read comprehens arxiv preprint arxiv rowan zeller ari holtzman yonatan bisk ali farhadi yejin choi neural fake news arxiv preprint arxiv sheng zhang xiao dong liu liu jianfeng gao kevin benjamin van durm record bridg gap human machin commonsens read comprehens arxiv preprint arxiv chen zhu cheng gan sun thoma liu adversari train languag understand arxiv preprint arxiv yukun zhu ryan kiro rich zemel lan salakhutdinov raquel antonio torralba sanja fidler align movi visual nation watch movi read proceed intern confer comput vision \n",
      "실제 요약문 : learning unified transformer \n",
      "예측 요약문 :  models networks\n",
      "\n",
      "\n",
      "원문 :  rossgirshick facebookairesearchfair abstract objectdetect introduct semant cnn requir semant segment given parallel simpl the ple objectdetect boundingbox detect figur mask categori decoupl relatedwork andevalu andi segment deepmask and etal com parallel etal for edg figur extract fasterrcnn were mask foreach cla approach that appli par allel box mask box binari class mask mask mask decoupl softmax sigmoid anda binari mask represent spatial fullyconnect corr rst quantiz nalli coordin where align boundari weus insteadof interpol diminish return networkarchitectur convolut backbon thenetwork head backbon etal later fea forth network head the implementationdetail train mask pixel each mask class box roi class box mask fasterrcnn fasterrcnn figur from and respect layer are relu left right low infer dataset backbon apap resnetc ohem ohem resnetc resnetfpn resnextfpn tabl instanc segment mask testdev multiscal singlemodel result mask val imag trainvalk imag miniv testdev label teststd and the tion architectur tabl resnext figur top resnetc resnetc resnetfpn resnetfpn resnextfpn bone softmax sigmoid multinomi resnetc decoupl align bilinear apap max max max layer apap resnet stride apap mlp mlp conv prove encod tabl ablat trainvalk miniv mask multinomi coupl mask sig anda binari softmax anda multinomi loss coupl one resnetc back applic tabl stride backbon fasterrcnn resnetc fasterrcnn resnetfpn fasterrcnn inceptionresnetv fasterrcnn inceptionresnetvtdm resnetfpn resnetfpn resnextfpn tabl objectdetect singlemodel stateofthearton testdev intabl boundingbox detectionresult boundingbox inceptionresnetvtdm and time infer train trainvalk train onehot wenotethat minim ture complementari implementationdetail singl test grmi tabl keypointdetect testdev our pose multiscal commun plu model trainvalk tabl tabl person mask person fasterrcnn tabl person miniv miniv testdev with miniv testdev tabl miniv testdev miniv mask refer cvpr cvpr sbellclzitnickkbalaandrgirshickinsid outsidenet detectingobjectsincontextwithskip pool andrecurrentneuralnetworksin cvpr cvpr eccv cvpr cvpr nip rgirshickfastrcnnin iccv girshickjdonahuetdarrellandjmalikrichfea turehierarchiesforaccurateobjectdetectionand semant segmentationin cvpr cvpr bhariharanparbel eccv bhariharanparbel tionin cvpr khexzhangsrenandjsunspatialpyramidpool indeepconvolutionalnetworksforvisu recognitionin eccv khexzhangsrenandjsundeepresiduallearn forimagerecognitionin cvpr pami cvpr mjaderberg nip akrizhevskyisutskeverandghintonimagenetcla sicationwithdeepconvolutionalneuralnetworksin nip ylecunbboserjsdenkerdhenderson howardwhubbardandldjackelbackpropag appliedtohandwrittenzipcoderecognit neuralcompu tation cvpr tylinpdol arrgirshickkhebhariharanand sbelongiefeaturepyramidnetworksforobjectdetect incvpr tylinmmairesbelongiejhayspperonadra mananpdol arandcl zitnickmicrosoftcoco com monobjectsincontextin eccv jlongeshelhamerandtdarrellfullyconvolut networksforsemanticsegmentationin cvpr boltzmannmachinesin icml cvpr popinheirorcollobertandpdollarlearningtoseg mentobjectcandidatesin nip popinheirotylinrcollobertandpdol arlearn ingtoreneobjectsegmentsin eccv srenk hergirshickandjsunfasterrcnnto wardsrealtim objectdetectionwithregionproposalnet worksin nip ashrivastavaaguptaandrgirshicktrainingregion basedobjectdetectorswithonlin hardexampleminingin cvpr yond cszegedysioffeandvvanhouckeinceptionv inceptionresnetand theimpactofresidualconnectionson learningin iclrworkshop jruijlingskevandesandetgeversandaw smeulder selectivesearchforobjectrecognit ijcv cvpr cvpr \n",
      "실제 요약문 : rcnn \n",
      "예측 요약문 :  models networks\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(\"원문 : \",seq2text(encoder_input_test[i]))\n",
    "    print(\"실제 요약문 :\",seq2summary(decoder_input_test[i]))\n",
    "    print(\"예측 요약문 :\",decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "33e4e08a7b7fa754f13c5b267cb1063e8854a8078d9e75eb423594d4bff0091a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tensor')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
